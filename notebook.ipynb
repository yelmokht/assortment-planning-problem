{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFO-F-424 - Combinatorial optimization - 2023-2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arfani Salah-Eddine - salah-eddine.arfani@ulb.be - 000495528\n",
    "\n",
    "### El Mokhtari Younes - younes.el.mokhtari@ulb.be - 000479836\n",
    "\n",
    "### Jeq Ismail - ismail.jeq@ulb.be - 000494718"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assortment Planning Problem (AP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gurobipy in c:\\users\\jeqis\\appdata\\roaming\\python\\python312\\site-packages (11.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install gurobipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import gurobipy as gp\n",
    "from gurobipy import GRB\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from math import exp\n",
    "from decimal import Decimal\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "medium_mu = pd.read_csv('data/medium-mu.csv', sep=';', header=None, dtype=float)\n",
    "medium_r = pd.read_csv('data/medium-r.csv', sep=';', header=None, dtype=float)\n",
    "small_mu = pd.read_csv('data/small-mu.csv', sep=';', header=None, dtype=float)\n",
    "small_r = pd.read_csv('data/small-r.csv', sep=';', header=None, dtype=float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def generate_parameters(n):\n",
    "    mu = np.random.uniform(0, 1, size = n + 1)\n",
    "    mu[0] = 0\n",
    "    r = np.random.uniform(0, 1, size = n + 1)\n",
    "    r[0] = 0\n",
    "    return mu, r\n",
    "\n",
    "def create_large_instances(m, n):\n",
    "    mu_file = 'data/large-mu.csv'\n",
    "    r_file = 'data/large-r.csv'\n",
    "    mu_data = []\n",
    "    r_data = []\n",
    "\n",
    "    for i in range(m):\n",
    "        mu, r = generate_parameters(n)\n",
    "        mu_data.append(mu)\n",
    "        r_data.append(r)\n",
    "        \n",
    "    # Takes too long to save the data\n",
    "    # mu_data = np.array(mu_data).T\n",
    "    # r_data = np.array(r_data).T\n",
    "\n",
    "    # f_mu_data = np.vectorize(lambda x: f\"{x:.18e}\")(mu_data)\n",
    "    # f_r_data = np.vectorize(lambda x: f\"{x:.18e}\")(r_data)\n",
    "\n",
    "    # mu_df = pd.DataFrame(f_mu_data)\n",
    "    # r_df = pd.DataFrame(f_r_data)\n",
    "\n",
    "    # mu_df.to_csv(mu_file, index=False, header=None, sep=';')\n",
    "    # r_df.to_csv(r_file, index=False, header=None, sep=';')\n",
    "\n",
    "    return mu_data, r_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create instance\n",
    "def create_instances(data):\n",
    "    list_instances = []\n",
    "    for j in range(0, data.shape[1]):\n",
    "        list_instances.append(data.iloc[:,j].to_list())\n",
    "\n",
    "    return list_instances\n",
    "instances_small_mu = create_instances(small_mu)\n",
    "instances_small_r = create_instances(small_r)\n",
    "instances_medium_mu = create_instances(medium_mu)\n",
    "instances_medium_r = create_instances(medium_r)\n",
    "\n",
    "large_mu, large_r = create_large_instances(100, 1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this project, we focus on the Assortment Planning Problem (AP), where a retailer wants to determine which products it has to propose to its customers in order to maximize its expected revenue. More precisely, consider a set of products $\\mathcal{I}=\\{1, \\ldots, n\\}$ that the retailer can propose to its customers, and selling product $i$ generates a net revenue of $r_{i}>0$ for him. We assume that the products are sorted in decreasing order of revenue, i.e. $r_{1}>r_{2}>\\cdots>r_{n}>0$, and that each product $i$ will be purchased according to a particular probability that depends on:\n",
    "\n",
    "- The mean utilities $\\left(\\mu_{j}\\right)_{j \\in \\mathcal{I}}$ for the customers when they buy product $j \\in \\mathcal{I}$,\n",
    "\n",
    "- The set of alternatives $\\mathcal{S}$ made available to the customers.\n",
    "\n",
    "These probabilities come from a discrete choice model called multinomial logit, and can be written as follows:\n",
    "\n",
    "$$\n",
    "P_{i}(\\mathcal{S})=\\frac{e^{\\mu_{i}}}{e^{\\mu_{0}}+\\sum_{j \\in \\mathcal{S}} e^{\\mu_{j}}}=\\frac{e^{\\mu_{i}}}{1+\\sum_{j \\in \\mathcal{S}} e^{\\mu_{j}}}, \\quad \\forall i \\in \\mathcal{I} \\cup\\{0\\}\n",
    "$$\n",
    "\n",
    "where $\\mu_{0}=0$ represents the utility - for the customers - of buying nothing. As we will see later on, it is convenient to assume that selling nothing does come with a revenue $r_{0} \\geqslant 0$ (that is, however, usually zero). With all of the above, the problem can be posed as the following combinatorial optimization problem:\n",
    "\n",
    "$$\n",
    "\\text { (AP) } \\max _{\\mathcal{S} \\subseteq \\mathcal{I}}\\left\\{r_{0} \\cdot P_{0}(\\mathcal{S})+\\sum_{i \\in \\mathcal{S}} r_{i} \\cdot P_{i}(\\mathcal{S})\\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. From combinatorial optimization to linear programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1.1 Show that AP can be rewritten as the following integer programming problem:\n",
    "\n",
    "$$\n",
    "\\text { (AP-IP) } \\max _{x \\in\\{0,1\\}^{n}} \\frac{r_{0}+\\sum_{i=1}^{n} x_{i} r_{i} e^{\\mu_{i}}}{1+\\sum_{i=1}^{n} x_{i} e^{\\mu_{i}}}\n",
    "$$\n",
    "\n",
    "#### Explain why this formulation is valid for the Assortment Planning Problem (variables, constraints, objective function), and why this formulation is nonlinear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can convert (AP) into an integer programming problem (AP-IP) by introducing binary decision variables $x_i$, where $x_i = 1$ if product $i$ is included in the assortment $\\mathcal{S}$, and $x_i = 0$ otherwise. We can rewrite the probabilities and revenues using $x_i$. For the no-purchase option, we have:\n",
    "\n",
    "$$\n",
    "P_0(\\mathcal{S}) = \\frac{1}{1 + \\sum_{i=1}^n x_i e^{\\mu_i}}\n",
    "$$\n",
    "\n",
    "For purchasing product $i$, we have:\n",
    "\n",
    "$$\n",
    "P_i(\\mathcal{S}) = \\frac{x_i e^{\\mu_i}}{1 + \\sum_{i=1}^n x_i e^{\\mu_i}}\n",
    "$$\n",
    "\n",
    "If we take the objective function of AP:\n",
    "\n",
    "$$\n",
    "r_0 \\cdot P_0(\\mathcal{S}) + \\sum_{i \\in \\mathcal{S}} r_i \\cdot P_i(\\mathcal{S})\n",
    "$$\n",
    "\n",
    "By replacing, we obtain:\n",
    "\n",
    "$$\n",
    "\\frac{r_0 + \\sum_{i=1}^n x_i r_i e^{\\mu_i}}{1 + \\sum_{i=1}^n x_i e^{\\mu_i}}\n",
    "$$\n",
    "\n",
    "This forms the objective function of (AP-IP):\n",
    "\n",
    "$$\n",
    "\\text { (AP-IP) } \\max _{x \\in\\{0,1\\}^{n}} \\frac{r_{0}+\\sum_{i=1}^{n} x_{i} r_{i} e^{\\mu_{i}}}{1+\\sum_{i=1}^{n} x_{i} e^{\\mu_{i}}}\n",
    "$$\n",
    "\n",
    "This formulation is valid because the binary decision variables $x_i$ indicate whether each product is included in the assortment, the constraints ensure these variables remain binary and the objective function maximizes the revenue based on the probability and the selected products. Since the denominator of the objective function is a polynomial, the formulation is nonlinear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1.2 Considering the following change of variables:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_{0} & :=\\frac{1}{1+\\sum_{j=1}^{n} x_{j} e^{\\mu_{j}}} \\\\\n",
    "y_{i} & :=\\frac{x_{i} e^{\\mu_{i}}}{1+\\sum_{j=1}^{n} x_{j} e^{\\mu_{j}}}, \\quad \\forall i \\in \\mathcal{I}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "#### prove that AP-IP can be rewritten as the following problem:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text { (AP-IPL) } \\max _{y, y_{0} \\geqslant 0} & r_{0} y_{0}+\\sum_{i=1}^{n} r_{i} y_{i} \\\\\n",
    "\\text { s.t. } & y_{0}+\\sum_{i=1}^{n} y_{i}=1 \\\\\n",
    "& y_{i} \\in\\left\\{0, y_{0} e^{\\mu_{i}}\\right\\},\n",
    "\\end{aligned} \\quad \\forall i \\in \\mathcal{I}\n",
    "$$\n",
    "\n",
    "#### where $y_{i} \\in\\left\\{0, y_{0} e^{\\mu_{i}}\\right\\}$ means that $y_{i}$ must take either 0 or $y_{0} e^{\\mu_{i}}$ as a value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's decompose the objective function of (AP-IP), we have:\n",
    "\n",
    "$$\n",
    "\\frac{r_0}{1 + \\sum_{j=1}^n x_j e^{\\mu_j}} + \\frac{\\sum_{j=1}^n x_j r_i e^{\\mu_j}}{1 + \\sum_{j=1}^n x_j e^{\\mu_j}}\n",
    "$$\n",
    "\n",
    "Using the change of variables, we immediately obtain the objective function of (AP-IPL):\n",
    "\n",
    "$$\n",
    "\\quad r_{0} y_{0} + \\sum_{i=1}^{n} r_{i} y_{i}\n",
    "$$\n",
    "\n",
    "Let's find the constraints now. Using the change of variables, we have:\n",
    "$$\n",
    "y_0 + \\sum_{i=1}^n y_i = \\frac{1}{1+\\sum_{j=1}^{n} x_{j} e^{\\mu_{j}}} + \\sum_{i=1}^{n} \\frac{x_{i} e^{\\mu_{i}}}{1+\\sum_{j=1}^{n} x_{j} e^{\\mu_{j}}} = \\frac{1 + \\sum_{i=1}^{n} x_{i} e^{\\mu_{i}}}{1 + \\sum_{j=1}^{n} x_{j} e^{\\mu_{j}}} = 1\n",
    "$$\n",
    "\n",
    "This gives us the first constraint:\n",
    "$$\n",
    "y_0 + \\sum_{i=1}^n y_i = 1\n",
    "$$\n",
    "\n",
    "Next, we consider the values $y_i$ can take. From the definition:\n",
    "$$\n",
    "y_i = \\frac{x_i e^{\\mu_i}}{1+\\sum_{j=1}^n x_j e^{\\mu_j}}\n",
    "$$\n",
    "\n",
    "When $x_i = 0$, we have:\n",
    "$$\n",
    "y_i = 0\n",
    "$$\n",
    "\n",
    "When $x_i = 1$, we have:\n",
    "$$\n",
    "y_i = \\frac{e^{\\mu_i}}{1+\\sum_{j=1}^n x_j e^{\\mu_j}} = y_0 e^{\\mu_i}\n",
    "$$\n",
    "\n",
    "This implies:\n",
    "$$\n",
    "y_i \\in \\{0, y_0 e^{\\mu_i}\\}, \\quad \\forall i \\in \\mathcal{I}\n",
    "$$\n",
    "\n",
    "Finally, the AP-IP problem can be rewritten as AP-IPL:\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text { (AP-IPL) } \\max _{y, y_{0} \\geqslant 0} & r_{0} y_{0}+\\sum_{i=1}^{n} r_{i} y_{i} \\\\\n",
    "\\text { s.t. } & y_{0}+\\sum_{i=1}^{n} y_{i}=1 \\\\\n",
    "& y_{i} \\in\\left\\{0, y_{0} e^{\\mu_{i}}\\right\\}, \\quad \\forall i \\in \\mathcal{I}\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 1.3 Consider the continuous relaxation of AP-IPL:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rlr}\n",
    "\\text{(AP-L)} \\quad \\max_{y, y_{0} \\geqslant 0} & r_{0} y_{0} + \\sum_{i=1}^{n} r_{i} y_{i} & \\\\\n",
    "\\text{s.t.} & y_{0} + \\sum_{i=1}^{n} y_{i} = 1 & \\\\\n",
    "& y_{i} \\leqslant y_{0} e^{\\mu_{i}} & \\forall i \\in \\mathcal{I}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "#### Prove that its linear programming dual is:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rl}\n",
    "\\text{(AP-LD)} \\quad \\min_{\\pi \\geqslant 0, \\pi_{0} \\in \\mathbb{R}} & \\pi_{0} \\\\\n",
    "\\text{s.t.} & \\pi_{0} - \\sum_{i=1}^{n} \\pi_{i} e^{\\mu_{i}} \\geqslant r_{0} \\\\\n",
    "& \\pi_{0} + \\pi_{i} \\geqslant r_{i} \\quad \\forall i \\in \\mathcal{I}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "#### and explain the relationships between dual (resp. primal) variables and primal (resp. dual) constraints.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the duality theorem to find (AP-LD). Let's reformulate the primal first, we have:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rlr}\n",
    "\\max_{y, y_{0} \\geqslant 0} & r_{0} y_{0} + \\sum_{i=1}^{n} r_{i} y_{i} & \\\\\n",
    "\\text{s.t.} & y_{0} + \\sum_{i=1}^{n} y_{i} = 1 & \\\\\n",
    "& - y_{0} e^{\\mu_{i}} + y_{i} \\leqslant 0 & \\forall i \\in \\mathcal{I}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "To formulate the dual problem, we associate dual variables with each constraint of the primal problem. Let's denote the dual variables as follows:\n",
    "\n",
    "- $\\pi_0$ for the first constraint $y_0 + \\sum_{i=1}^n y_i = 1$.\n",
    "- $\\pi_i$ for the second constraint $- y_{0} e^{\\mu_{i}} + y_{i} \\leqslant 0 $.\n",
    "\n",
    "The dual objective function is derived from the constant term in the constraints multiplied by the dual variables. So, we obtain:\n",
    "\n",
    "$$\n",
    "\\min_{\\pi_0, \\pi_i} \\quad \\pi_0\n",
    "$$\n",
    "\n",
    "\n",
    "The dual constraints can be derived from the coefficients of the primal constraints and the primal objective function, we have:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rl}\n",
    "\\pi_0 - \\sum_{i=1}^{n} \\pi_i e^{\\mu_i} \\geq r_0 \\\\\n",
    "\\pi_0 + \\pi_i \\geq r_i\n",
    "\\end{array} \\quad \\forall i \\in \\mathcal{I}\n",
    "$$\n",
    "\n",
    "Thus, the dual problem (AP-LD) is:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rl}\n",
    "\\min_{\\pi \\geqslant 0, \\pi_{0} \\in \\mathbb{R}} & \\pi_{0} \\\\\n",
    "\\text{s.t.} & \\pi_{0} - \\sum_{i=1}^{n} \\pi_{i} e^{\\mu_{i}} \\geqslant r_{0} \\\\\n",
    "& \\pi_{0} + \\pi_{i} \\geqslant r_{i} \\quad \\forall i \\in \\mathcal{I}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "\n",
    "In the primal, we had:\n",
    "\n",
    "- $y_0$ which represents the probability of a customer of buying nothing given the set of products in the assortment.\n",
    "- $y_i$ which represents the probability of a customer of buying product $i$ given the set of products in the assortment.\n",
    "\n",
    "Now in the dual, we have:\n",
    "\n",
    "- $\\pi_0$ which is associated with the first primal constraint $y_0 + \\sum_{i=1}^n y_i = 1$. It measures the importance of ensuring that the total probability of all choices adds up to 100%. \n",
    "\n",
    "- $\\pi_i$ which is associated with the second primal constraint $- y_0 e^{\\mu_i} + y_i \\leq 0$ for each product $i \\in \\mathcal{I}$. It measures the importance of ensuring that the probability of choosing product $i$ fits within its attractiveness limit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Ideal formulation and a greedy algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now show that, with the help of AP-L, we can solve AP in polynomial time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 For any $k \\in \\mathcal{I}$, consider the following solution:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_{0}^{k} & :=\\frac{1}{1+\\sum_{j=1}^{k} e^{\\mu_{j}}} \\\\\n",
    "y_{i}^{k} & :=\\left\\{\\begin{array}{ll}\n",
    "\\frac{e^{\\mu_{i}}}{1+\\sum_{j=1}^{k} e^{\\mu_{j}}} & \\text { if } i \\leqslant k \\\\\n",
    "0 & \\text { otherwise. }\n",
    "\\end{array} \\quad \\forall i \\in \\mathcal{I} .\\right.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 2.1.1 Show that $\\left(y^{k}, y_{0}^{k}\\right)$ is feasible for AP-L. What is its objective value?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show that $\\left(y^{k}, y_{0}^{k}\\right)$ is feasible for AP-L, we need to check that it satisfies the constraints of AP-L. For the constraint 1, we have:\n",
    "\n",
    "$$\n",
    "y_{0}^{k} + \\sum_{i=1}^{k} y_{i}^{k} = \\frac{1}{1+\\sum_{j=1}^{k} e^{\\mu_{j}}} + \\frac{\\sum_{i=1}^{k} e^{\\mu_{i}}}{1+\\sum_{j=1}^{k} e^{\\mu_{j}}} = \\frac{1 + \\sum_{i=1}^{k} e^{\\mu_{i}}}{1+\\sum_{j=1}^{k} e^{\\mu_{j}}} = 1\n",
    "$$\n",
    "\n",
    "Therefore, the first constraint is satisfied. For the second constraint, we have:\n",
    "\n",
    "For $ i \\leqslant k $:\n",
    "\n",
    "$$\n",
    "y_{i}^{k} = \\frac{e^{\\mu_{i}}}{1+\\sum_{j=1}^{k} e^{\\mu_{j}}} \\quad \\text{and} \\quad y_{0}^{k} e^{\\mu_{i}} = \\frac{e^{\\mu_{i}}}{1+\\sum_{j=1}^{k} e^{\\mu_{j}}}\n",
    "$$\n",
    "\n",
    "So,\n",
    "\n",
    "$$\n",
    "y_{i}^{k} = y_{0}^{k} e^{\\mu_{i}}\n",
    "$$\n",
    "\n",
    "For $ i > k $:\n",
    "\n",
    "$$\n",
    "y_{i}^{k} = 0 \\quad \\text{and} \\quad y_{0}^{k} e^{\\mu_{i}} = \\frac{e^{\\mu_{i}}}{1+\\sum_{j=1}^{k} e^{\\mu_{j}}} > 0\n",
    "$$\n",
    "\n",
    "Thus,\n",
    "\n",
    "$$\n",
    "y_{i}^{k} \\leqslant y_{0}^{k} e^{\\mu_{i}}\n",
    "$$\n",
    "\n",
    "Therefore, the second constraint is satisfied.\n",
    "\n",
    "Since both constraints are satisfied, $\\left(y^{k}, y_{0}^{k}\\right)$ is feasible for AP-L. Let's compute now the objective value for $\\left(y^{k}, y_{0}^{k}\\right)$:\n",
    "\n",
    "$$\n",
    "r_{0} y_{0}^{k} + \\sum_{i=1}^{n} r_{i} y_{i}^{k}\n",
    "$$\n",
    "\n",
    "We develop $y_0$ and $y_{0}^{k}$:\n",
    "\n",
    "$$\n",
    "\\frac{r_{0}}{1+\\sum_{j=1}^{k} e^{\\mu_{j}}} + \\sum_{i=1}^{k} \\frac{r_{i} e^{\\mu_{i}}}{1+\\sum_{j=1}^{k} e^{\\mu_{j}}}\n",
    "$$\n",
    "\n",
    "After factoring, the objective value is:\n",
    "\n",
    "$$\n",
    "\\frac{r_{0} + \\sum_{i=1}^{k} r_{i} e^{\\mu_{i}}}{1+\\sum_{j=1}^{k} e^{\\mu_{j}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 2.1.2 Using the change of variables in (1.2), prove that the associated $x^{k}$ is integer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prove that the associated $x^{k}$ is integer, we use the change of variables defined in (1.2):\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "y_{0} & := \\frac{1}{1+\\sum_{j=1}^{n} x_{j} e^{\\mu_{j}}} \\\\\n",
    "y_{i} & := \\frac{x_{i} e^{\\mu_{i}}}{1+\\sum_{j=1}^{n} x_{j} e^{\\mu_{j}}}, \\quad \\forall i \\in \\mathcal{I}\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Given:\n",
    "\n",
    "$$\n",
    "y_{0}^{k} = \\frac{1}{1+\\sum_{j=1}^{k} e^{\\mu_{j}}}\n",
    "$$\n",
    "\n",
    "and\n",
    "\n",
    "$$\n",
    "y_{i}^{k} = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "\\frac{e^{\\mu_{i}}}{1+\\sum_{j=1}^{k} e^{\\mu_{j}}} & \\text{if } i \\leqslant k \\\\\n",
    "0 & \\text{otherwise.}\n",
    "\\end{array} \\right.\n",
    "$$\n",
    "\n",
    "We want to show that the associated $x^{k}$ is integer. From the change of variables, we have:\n",
    "\n",
    "$$\n",
    "x_{i} = \\frac{y_{i} (1+\\sum_{j=1}^{n} x_{j} e^{\\mu_{j}})}{e^{\\mu_{i}}}\n",
    "$$\n",
    "\n",
    "For $i \\leq k$:\n",
    "\n",
    "$$\n",
    "x_{i}^{k} = \\frac{y_{i}^{k} (1+\\sum_{j=1}^{k} e^{\\mu_{j}})}{e^{\\mu_{i}}}\n",
    "    = \\frac{\\frac{e^{\\mu_{i}}}{1+\\sum_{j=1}^{k} e^{\\mu_{j}}} (1+\\sum_{j=1}^{k} e^{\\mu_{j}})}{e^{\\mu_{i}}} \n",
    "    = \\frac{e^{\\mu_{i}}}{1+\\sum_{j=1}^{k} e^{\\mu_{j}}} \\cdot \\frac{1+\\sum_{j=1}^{k} e^{\\mu_{j}}}{e^{\\mu_{i}}}\n",
    "    = \\frac{e^{\\mu_{i}}}{e^{\\mu_{i}}}\n",
    "    = 1\n",
    "$$\n",
    "\n",
    "For $i > k$:\n",
    "\n",
    "$$\n",
    "y_{i}^{k} = 0 \\implies x_{i}^{k} = \\frac{0 \\cdot (1+\\sum_{j=1}^{k} e^{\\mu_{j}})}{e^{\\mu_{i}}} = 0\n",
    "$$\n",
    "\n",
    "Therefore, the associated $x^{k}$ is integer, where:\n",
    "\n",
    "$$\n",
    "x_{i}^{k} = \\left\\{\n",
    "\\begin{array}{ll}\n",
    "1 & \\text{if } i \\leq k \\\\\n",
    "0 & \\text{if } i > k\n",
    "\\end{array} \\right.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 2.1.3 Show that $\\left(y^{k}, y_{0}^{k}\\right)$ is a strictly better solution than $\\left(y^{k-1}, y_{0}^{k-1}\\right)$ if and only if:\n",
    "\n",
    "$$\n",
    "r_{k}>\\frac{r_{0}+\\sum_{j=1}^{k-1} e^{\\mu_{j}} r_{j}}{1+\\sum_{j=1}^{k-1} e^{\\mu_{j}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To show this, we need to compare the objective values of $\\left(y^{k}, y_{0}^{k}\\right)$ and $\\left(y^{k-1}, y_{0}^{k-1}\\right)$.\n",
    "\n",
    "The objective value for $\\left(y^{k}, y_{0}^{k}\\right)$ is:\n",
    "\n",
    "$$\n",
    "\\frac{r_{0} + \\sum_{i=1}^{k} e^{\\mu_{i}} r_{i}}{1 + \\sum_{j=1}^{k} e^{\\mu_{j}}}\n",
    "$$\n",
    "\n",
    "The objective value for $\\left(y^{k-1}, y_{0}^{k-1}\\right)$ is:\n",
    "\n",
    "$$\n",
    "\\frac{r_{0} + \\sum_{i=1}^{k-1} e^{\\mu_{i}} r_{i}}{1 + \\sum_{j=1}^{k-1} e^{\\mu_{j}}}\n",
    "$$\n",
    "\n",
    "We need to show that:\n",
    "\n",
    "$$\n",
    "\\frac{r_{0} + \\sum_{i=1}^{k} e^{\\mu_{i}} r_{i}}{1 + \\sum_{j=1}^{k} e^{\\mu_{j}}} > \\frac{r_{0} + \\sum_{i=1}^{k-1} e^{\\mu_{i}} r_{i}}{1 + \\sum_{j=1}^{k-1} e^{\\mu_{j}}}\n",
    "$$\n",
    "\n",
    "We can cross-multiply to compare the numerators directly:\n",
    "\n",
    "$$\n",
    "(r_{0} + \\sum_{i=1}^{k} e^{\\mu_{i}} r_{i})(1 + \\sum_{j=1}^{k-1} e^{\\mu_{j}}) > (r_{0} + \\sum_{i=1}^{k-1} e^{\\mu_{i}} r_{i})(1 + \\sum_{j=1}^{k} e^{\\mu_{j}})\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\iff\n",
    "$$\n",
    "\n",
    "$$\n",
    "r_{0} + r_{0} \\sum_{j=1}^{k-1} e^{\\mu_{j}} + \\sum_{i=1}^{k} e^{\\mu_{i}} r_{i} + \\sum_{i=1}^{k} e^{\\mu_{i}} r_{i} \\sum_{j=1}^{k-1} e^{\\mu_{j}} > r_{0} + r_{0} \\sum_{j=1}^{k} e^{\\mu_{j}} + \\sum_{i=1}^{k-1} e^{\\mu_{i}} r_{i} + \\sum_{i=1}^{k-1} e^{\\mu_{i}} r_{i} \\sum_{j=1}^{k} e^{\\mu_{j}}\n",
    "$$\n",
    "\n",
    "We cancel out the common terms:\n",
    "\n",
    "$$\n",
    "r_{0} \\sum_{j=1}^{k-1} e^{\\mu_{j}} + \\sum_{i=1}^{k} e^{\\mu_{i}} r_{i} + \\sum_{i=1}^{k} e^{\\mu_{i}} r_{i} \\sum_{j=1}^{k-1} e^{\\mu_{j}} > r_{0} \\sum_{j=1}^{k} e^{\\mu_{j}} + \\sum_{i=1}^{k-1} e^{\\mu_{i}} r_{i} + \\sum_{i=1}^{k-1} e^{\\mu_{i}} r_{i} \\sum_{j=1}^{k} e^{\\mu_{j}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\iff\n",
    "$$\n",
    "\n",
    "$$\n",
    "e^{\\mu_{k}} r_{k} + e^{\\mu_{k}} r_{k} \\sum_{j=1}^{k-1} e^{\\mu_{j}} > r_{0} e^{\\mu_{k}} + e^{\\mu_{k}} \\sum_{i=1}^{k-1} e^{\\mu_{j}} r_{i}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\iff\n",
    "$$\n",
    "\n",
    "$$\n",
    "r_{k} + r_{k} \\sum_{j=1}^{k-1} e^{\\mu_{j}} > r_{0} + \\sum_{i=1}^{k-1} e^{\\mu_{j}} r_{i}\n",
    "$$\n",
    "\n",
    "\n",
    "We can factor out $r_{k}$:\n",
    "\n",
    "$$\n",
    "r_{k} (1 + \\sum_{j=1}^{k-1} e^{\\mu_{j}}) > r_{0} + \\sum_{i=1}^{k-1} e^{\\mu_{i}} r_{i}\n",
    "$$\n",
    "\n",
    "We divide both sides by $1 + \\sum_{j=1}^{k-1} e^{\\mu_{j}}$:\n",
    "\n",
    "$$\n",
    "r_{k} > \\frac{r_{0} + \\sum_{i=1}^{k-1} e^{\\mu_{i}} r_{i}}{1 + \\sum_{j=1}^{k-1} e^{\\mu_{j}}}\n",
    "$$\n",
    "\n",
    "Thus, $\\left(y^{k}, y_{0}^{k}\\right)$ is a strictly better solution than $\\left(y^{k-1}, y_{0}^{k}\\right)$ if and only if:\n",
    "\n",
    "$$\n",
    "r_{k} > \\frac{r_{0} + \\sum_{j=1}^{k-1} e^{\\mu_{j}} r_{j}}{1 + \\sum_{j=1}^{k-1} e^{\\mu_{j}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 2.1.4 Prove that there is no $k \\in \\mathcal{I}$ such that\n",
    "\n",
    "$$\n",
    "r_{k} \\leqslant \\frac{r_{0}+\\sum_{j=1}^{k-1} e^{\\mu_{j}} r_{j}}{1+\\sum_{j=1}^{k-1} e^{\\mu_{j}}} \\quad \\text { and } \\quad r_{k+1}>\\frac{r_{0}+\\sum_{j=1}^{k} e^{\\mu_{j}} r_{j}}{1+\\sum_{j=1}^{k} e^{\\mu_{j}}}\n",
    "$$\n",
    "\n",
    "##### at the same time. What does the graph of the function $k \\rightarrow r^{\\top} y^{k}$ look like?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To prove that both conditions cannot hold simultaneously, let's assume they do and show a contradiction.\n",
    "\n",
    "Suppose there exists a $k \\in \\mathcal{I}$ such that:\n",
    "\n",
    "1. $r_{k} \\leq \\frac{r_{0} + \\sum_{j=1}^{k-1} e^{\\mu_{j}} r_{j}}{1 + \\sum_{j=1}^{k-1} e^{\\mu_{j}}}$\n",
    "2. $r_{k+1} > \\frac{r_{0} + \\sum_{j=1}^{k} e^{\\mu_{j}} r_{j}}{1 + \\sum_{j=1}^{k} e^{\\mu_{j}}}$\n",
    "\n",
    "Let's denote these values as follows:\n",
    "\n",
    "- $A = \\frac{r_{0} + \\sum_{j=1}^{k-1} e^{\\mu_{j}} r_{j}}{1 + \\sum_{j=1}^{k-1} e^{\\mu_{j}}}$\n",
    "- $B = \\frac{r_{0} + \\sum_{j=1}^{k} e^{\\mu_{j}} r_{j}}{1 + \\sum_{j=1}^{k} e^{\\mu_{j}}}$\n",
    "\n",
    "So we have:\n",
    "\n",
    "$$\n",
    "r_{k} \\leq A \\quad \\text{and} \\quad r_{k+1} > B\n",
    "$$\n",
    "\n",
    "Let's compare $B$ and $A$. We can rewrite $B$ as:\n",
    "\n",
    "$$\n",
    "B = \\frac{r_{0} + \\sum_{j=1}^{k-1} e^{\\mu_{j}} r_{j} + e^{\\mu_{k}} r_{k}}{1 + \\sum_{j=1}^{k-1} e^{\\mu_{j}} + e^{\\mu_{k}}}\n",
    "$$\n",
    "\n",
    "By introducing $A$, we can rewrite $B$ in terms of $A$:\n",
    "\n",
    "$$\n",
    "B = \\frac{A \\cdot (1 + \\sum_{j=1}^{k-1} e^{\\mu_{j}}) + e^{\\mu_{k}} r_{k}}{1 + \\sum_{j=1}^{k-1} e^{\\mu_{j}} + e^{\\mu_{k}}}\n",
    "$$\n",
    "\n",
    "Since $r_k \\leq A$, we can replace $r_k$ with $A$ and we obtain that:\n",
    "\n",
    "$$\n",
    "B \\leq A\n",
    "$$\n",
    "\n",
    "This implies that $r_{k+1}$ cannot be greater than $B$ if $r_k \\leq A$ because it will mean that $r_{k+1} > r_k$, which is not possible based on our initial assumption of the problem.\n",
    "\n",
    "Therefore, it is impossible for both conditions to hold at the same time.\n",
    "\n",
    "The graph of the function $k \\rightarrow r^{\\top} y^{k}$ would show a non-increasing function because as more products are included in the assortment, the expected revenue for k products will tend to decrease or stay constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 2.1.5 Deduce that there is exactly one $k^{*} \\in \\mathcal{I}$ such that\n",
    "\n",
    "$$\n",
    "r_{1}>\\cdots>r_{k^{*}}>\\frac{r_{0}+\\sum_{j=1}^{k^{*}-1} e^{\\mu_{j}} r_{j}}{1+\\sum_{j=1}^{k^{*}-1} e^{\\mu_{j}}} \\quad \\text { and } \\quad \\frac{r_{0}+\\sum_{j=1}^{k^{*}} e^{\\mu_{j}} r_{j}}{1+\\sum_{j=1}^{k^{*}} e^{\\mu_{j}}} \\geqslant r_{k^{*}+1}>\\cdots>r_{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 2.1.3, we showed that $y^{k}$ is a better solution than $y^{k-1}$ if and only if\n",
    "\n",
    "$$\n",
    "r_{k} > \\frac{r_{0} + \\sum_{j=1}^{k-1} e^{\\mu_{j}} r_{j}}{1 + \\sum_{j=1}^{k-1} e^{\\mu_{j}}}\n",
    "$$\n",
    "\n",
    "From 2.1.4, we proved that there is no $k$ such that\n",
    "\n",
    "$$\n",
    "r_{k} \\leq \\frac{r_{0} + \\sum_{j=1}^{k-1} e^{\\mu_{j}} r_{j}}{1 + \\sum_{j=1}^{k-1} e^{\\mu_{j}}} \\quad \\text{and} \\quad r_{k+1} > \\frac{r_{0} + \\sum_{j=1}^{k} e^{\\mu_{j}} r_{j}}{1 + \\sum_{j=1}^{k} e^{\\mu_{j}}}\n",
    "$$\n",
    "\n",
    "Based on these results, there is exactly one $k^{*}$ such that:\n",
    "\n",
    "$$\n",
    "r_{1} > \\cdots > r_{k^{*}} > \\frac{r_{0} + \\sum_{j=1}^{k^{*}-1} e^{\\mu_{j}} r_{j}}{1 + \\sum_{j=1}^{k^{*}-1} e^{\\mu_{j}}} \\quad \\text{and} \\quad \\frac{r_{0} + \\sum_{j=1}^{k^{*}} e^{\\mu_{j}} r_{j}}{1 + \\sum_{j=1}^{k^{*}} e^{\\mu_{j}}} \\geq r_{k^{*}+1} > \\cdots > r_{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 2.1.6 Show that we cannot have $r_{k^{*}}<\\frac{r_{0}+\\sum_{j=1}^{k^{*}} e^{\\mu_{j}} r_{j}}{1+\\sum_{j=1}^{k *} e^{\\mu_{j}}}$, and deduce that we have\n",
    "\n",
    "$$\n",
    "r_{1}>\\cdots>r_{k^{*}} \\geqslant \\frac{r_{0}+\\sum_{j=1}^{k^{*}} e^{\\mu_{j}} r_{j}}{1+\\sum_{j=1}^{k^{*}} e^{\\mu_{j}}} \\geqslant r_{k^{*}+1}>\\cdots>r_{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From 2.1.5, we have:\n",
    "\n",
    "$$\n",
    "r_{1} > \\cdots > r_{k^{*}} > \\frac{r_{0} + \\sum_{j=1}^{k^{*}-1} e^{\\mu_{j}} r_{j}}{1 + \\sum_{j=1}^{k^{*}-1} e^{\\mu_{j}}}\n",
    "$$\n",
    "\n",
    "If $ r_{k^{*}} < \\frac{r_{0} + \\sum_{j=1}^{k^{*}} e^{\\mu_{j}} r_{j}}{1 + \\sum_{j=1}^{k^{*}} e^{\\mu_{j}}} $, it would contradict our assumption since including product $ k^{*} $ should not diminish the value.\n",
    "\n",
    "Therefore, we must have:\n",
    "\n",
    "$$\n",
    "r_{k^{*}} \\geq \\frac{r_{0} + \\sum_{j=1}^{k^{*}} e^{\\mu_{j}} r_{j}}{1 + \\sum_{j=1}^{k^{*}} e^{\\mu_{j}}}\n",
    "$$\n",
    "\n",
    "Hence, we deduce:\n",
    "\n",
    "$$\n",
    "r_{1} > \\cdots > r_{k^{*}} \\geq \\frac{r_{0} + \\sum_{j=1}^{k^{*}} e^{\\mu_{j}} r_{j}}{1 + \\sum_{j=1}^{k^{*}} e^{\\mu_{j}}} \\geq r_{k^{*}+1} > \\cdots > r_{n}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 For any $k \\in \\mathcal{I}$, consider the following solution:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\pi_{0}^{k} & :=\\frac{r_{0}+\\sum_{j=1}^{k} e^{\\mu_{j}} r_{j}}{1+\\sum_{j=1}^{k} e^{\\mu_{j}}} \\\\\n",
    "\\pi_{i}^{k} & :=\\left\\{\\begin{array}{ll}\n",
    "r_{i}-\\frac{r_{0}+\\sum_{j=1}^{k} e^{\\mu_{j}} r_{j}}{1+\\sum_{j=1}^{k} e^{\\mu_{j}}} & \\text { if } i \\leqslant k \\\\\n",
    "0 & \\text { otherwise. }\n",
    "\\end{array}, \\quad \\forall i \\in \\mathcal{I} .\\right.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 2.2.1 What is its objective value? In which conditions is $\\left(\\pi^{k}, \\pi_{0}^{k}\\right)$ feasible for AP-LD? Is there such a $k$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective value of the dual problem (AP-LD) is $\\pi_{0}$. Thus, for this solution, the objective value is:\n",
    "\n",
    "$$\n",
    "\\pi_{0}^{k} = \\frac{r_{0} + \\sum_{j=1}^{k} e^{\\mu_{j}} r_{j}}{1 + \\sum_{j=1}^{k} e^{\\mu_{j}}}\n",
    "$$\n",
    "\n",
    "\n",
    "To determine in which conditions $\\left(\\pi^{k}, \\pi_{0}^{k}\\right)$ is feasible for AP-LD, we need to check the constraints:\n",
    "\n",
    "1. $\\pi_{0} - \\sum_{i=1}^{n} \\pi_{i} e^{\\mu_{i}} \\geq r_{0}$\n",
    "2. $\\pi_{0} + \\pi_{i} \\geq r_{i} \\quad \\forall i \\in \\mathcal{I}$\n",
    "\n",
    "For the first constraint, we have for $i \\leq k$:\n",
    "\n",
    "$$\n",
    "\\pi_{0}^{k} - \\sum_{i=1}^{k} \\left(r_{i} - \\pi_{0}^{k}\\right) e^{\\mu_{i}} \\geq r_{0}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\iff\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\pi_{0}^{k} - \\sum_{i=1}^{k} r_{i} e^{\\mu_{i}} + \\pi_{0}^{k} \\sum_{i=1}^{k} e^{\\mu_{i}} \\geq r_{0}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\iff\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\pi_{0}^{k} \\left(1 + \\sum_{i=1}^{k} e^{\\mu_{i}}\\right) - \\sum_{i=1}^{k} r_{i} e^{\\mu_{i}} \\geq r_{0}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\iff\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\left(\\frac{r_{0} + \\sum_{j=1}^{k} e^{\\mu_{j}} r_{j}}{1 + \\sum_{j=1}^{k} e^{\\mu_{j}}}\\right) \\left(1 + \\sum_{i=1}^{k} e^{\\mu_{i}}\\right) - \\sum_{i=1}^{k} r_{i} e^{\\mu_{i}} \\geq r_{0}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\iff\n",
    "$$\n",
    "\n",
    "$$\n",
    "r_{0} + \\sum_{j=1}^{k} e^{\\mu_{j}} r_{j} - \\sum_{i=1}^{k} r_{i} e^{\\mu_{i}} \\geq r_{0}\n",
    "$$\n",
    "\n",
    "This is always true as the terms cancel out. For $i > k$, we have:\n",
    "\n",
    "$$\n",
    "\\pi_{0}^{k} \\geq r_{0}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\iff\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{r_{0} + \\sum_{j=1}^{k} e^{\\mu_{j}} r_{j}}{1 + \\sum_{j=1}^{k} e^{\\mu_{j}}} \\geq r_{0}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\iff\n",
    "$$\n",
    "\n",
    "$$\n",
    "r_{0} + \\sum_{j=1}^{k} e^{\\mu_{j}} r_{j} \\geq r_{0} \\left(1 + \\sum_{j=1}^{k} e^{\\mu_{j}}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\iff\n",
    "$$\n",
    "\n",
    "$$\n",
    "r_{0} + \\sum_{j=1}^{k} e^{\\mu_{j}} r_{j} \\geq r_{0} + r_{0} \\sum_{j=1}^{k} e^{\\mu_{j}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\iff\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{j=1}^{k} e^{\\mu_{j}} r_{j} \\geq r_{0} \\sum_{j=1}^{k} e^{\\mu_{j}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\iff\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\sum_{j=1}^{k} e^{\\mu_{j}} (r_{j} - r_{0}) \\geq 0\n",
    "$$\n",
    "\n",
    "Since $r_{j} > r_{0}$ for all $j \\in \\mathcal{I}$, this inequality is always satisfied.\n",
    "\n",
    "For the second constraint, for $i \\leq k$, we have:\n",
    "\n",
    "$$\n",
    "\\pi_{0}^{k} + \\pi_{i}^{k} \\geq r_{i}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\iff\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\pi_{0}^{k} + \\left(r_{i} - \\pi_{0}^{k}\\right) \\geq r_{i}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\iff\n",
    "$$\n",
    "\n",
    "$$\n",
    "r_{i} \\geq r_{i}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "This is always true.\n",
    "\n",
    "For $i > k$:\n",
    "\n",
    "$$\n",
    "\\pi_{0}^{k} \\geq r_{i}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\iff\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\frac{r_{0} + \\sum_{j=1}^{k} e^{\\mu_{j}} r_{j}}{1 + \\sum_{j=1}^{k} e^{\\mu_{j}}} \\geq r_{i}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\iff\n",
    "$$\n",
    "\n",
    "$$\n",
    "r_{0} + \\sum_{j=1}^{k} e^{\\mu_{j}} r_{j} \\geq r_{i} \\left(1 + \\sum_{j=1}^{k} e^{\\mu_{j}}\\right)\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\iff\n",
    "$$\n",
    "\n",
    "$$\n",
    "r_{0} + \\sum_{j=1}^{k} e^{\\mu_{j}} r_{j} - r_{i} \\sum_{j=1}^{k} e^{\\mu_{j}} \\geq r_{i}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\iff\n",
    "$$\n",
    "\n",
    "$$\n",
    "r_{0} + \\sum_{j=1}^{k} e^{\\mu_{j}} (r_{j} - r_{i}) \\geq r_{i}\n",
    "$$\n",
    "\n",
    "Since $r_{j} > r_{i}$ for all $j \\leq k$, each term $(r_{j} - r_{i})$ is positive. Thus, $\\sum_{j=1}^{k} e^{\\mu_{j}} (r_{j} - r_{i})$ is positive or zero, making the left-hand side of the inequality greater than or equal to $r_{i}$.\n",
    "\n",
    "This implies that there exists a $k$ such that $\\pi_{0}^{k} \\geq r_{i}$ for all $i > k$, ensuring that $\\left(\\pi^{k}, \\pi_{0}^{k}\\right)$ is feasible for AP-LD for such $k$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 2.2.2 Given $k \\in \\mathcal{I}$, if $\\left(\\pi^{k}, \\pi_{0}^{k}\\right)$ is feasible for AP-LD, prove that $\\mathcal{S}:=\\{1, \\cdots, k\\}$ is optimal for AP. Is AP-L an ideal formulation for AP ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2.1.1 and 2.2.1, we computed the objective value for (AP-L) and (AP-LD) respectively, and they have the same objective value for $k$:\n",
    "\n",
    "$$\n",
    "\\frac{r_{0} + \\sum_{i=1}^{k} r_{i} e^{\\mu_{i}}}{1+\\sum_{j=1}^{k} e^{\\mu_{j}}}\n",
    "$$\n",
    "\n",
    "And we proved that $\\left(\\pi^{k}, \\pi_{0}^{k}\\right)$ is feasible for AP-LD, it means that the dual problem (AP-LD) has an optimal solution with the objective value. Since the primal problem (AP-L) and the dual problem (AP-LD) have the same objective value, we can conclude that $\\mathcal{S} := \\{1, \\cdots, k\\}$ is optimal for AP.\n",
    "\n",
    "Since we found that $\\mathcal{S} := \\{1, \\cdots, k\\}$ is optimal for AP and it has the same objective value for (AP) and (AP-L), then we know that (AP-L) is an ideal formulation for AP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 2.2.3 Propose a polynomial time algorithm that solves AP. What is its worst-time complexity?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given that the items are already sorted by decreasing revenue, we can use the following greedy algorithm:\n",
    "\n",
    "1. Initialize an empty set $\\mathcal{S}$ and set $k = 0$.\n",
    "2. For each product $i \\in \\mathcal{I}$:\n",
    "   - Compute the objective value if product $i$ is added to $\\mathcal{S}$:\n",
    "     $$\n",
    "     \\text{new value} = \\frac{r_{0} + \\sum_{j \\in \\mathcal{S} \\cup \\{i\\}} r_{j} e^{\\mu_{j}}}{1 + \\sum_{j \\in \\mathcal{S} \\cup \\{i\\}} e^{\\mu_{j}}}\n",
    "     $$\n",
    "   - Compute the objective value without adding product $i$:\n",
    "     $$\n",
    "     \\text{current value} = \\frac{r_{0} + \\sum_{j \\in \\mathcal{S}} r_{j} e^{\\mu_{j}}}{1 + \\sum_{j \\in \\mathcal{S}} e^{\\mu_{j}}}\n",
    "     $$\n",
    "   - If $\\text{new value} > \\text{current value}$, add product $i$ to $\\mathcal{S}$ and increment $k$ by 1.\n",
    "3. The set $\\mathcal{S}$ is the optimal assortment.\n",
    "\n",
    "Since the items are already sorted by decreasing revenue, no sorting is needed. For each product, computing the new objective value involves summing up to $k$ elements, which takes $O(k)$ time. In the worst case, $k = n$, so each iteration takes $O(n)$ time. With $n$ iterations, the total time complexity is $O(n^2)$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small instance n°1\n",
      "Small instance n°2\n",
      "Small instance n°3\n",
      "Small instance n°4\n",
      "Small instance n°5\n",
      "Small instance n°6\n",
      "Small instance n°7\n",
      "Small instance n°8\n",
      "Small instance n°9\n",
      "Small instance n°10\n",
      "Small instance n°11\n",
      "Small instance n°12\n",
      "Small instance n°13\n",
      "Small instance n°14\n",
      "Small instance n°15\n",
      "Small instance n°16\n",
      "Small instance n°17\n",
      "Small instance n°18\n",
      "Small instance n°19\n",
      "Small instance n°20\n",
      "Small instance n°21\n",
      "Small instance n°22\n",
      "Small instance n°23\n",
      "Small instance n°24\n",
      "Small instance n°25\n",
      "Small instance n°26\n",
      "Small instance n°27\n",
      "Small instance n°28\n",
      "Small instance n°29\n",
      "Small instance n°30\n",
      "Small instance n°31\n",
      "Small instance n°32\n",
      "Small instance n°33\n",
      "Small instance n°34\n",
      "Small instance n°35\n",
      "Small instance n°36\n",
      "Small instance n°37\n",
      "Small instance n°38\n",
      "Small instance n°39\n",
      "Small instance n°40\n",
      "Small instance n°41\n",
      "Small instance n°42\n",
      "Small instance n°43\n",
      "Small instance n°44\n",
      "Small instance n°45\n",
      "Small instance n°46\n",
      "Small instance n°47\n",
      "Small instance n°48\n",
      "Small instance n°49\n",
      "Small instance n°50\n",
      "Small instance n°51\n",
      "Small instance n°52\n",
      "Small instance n°53\n",
      "Small instance n°54\n",
      "Small instance n°55\n",
      "Small instance n°56\n",
      "Small instance n°57\n",
      "Small instance n°58\n",
      "Small instance n°59\n",
      "Small instance n°60\n",
      "Small instance n°61\n",
      "Small instance n°62\n",
      "Small instance n°63\n",
      "Small instance n°64\n",
      "Small instance n°65\n",
      "Small instance n°66\n",
      "Small instance n°67\n",
      "Small instance n°68\n",
      "Small instance n°69\n",
      "Small instance n°70\n",
      "Small instance n°71\n",
      "Small instance n°72\n",
      "Small instance n°73\n",
      "Small instance n°74\n",
      "Small instance n°75\n",
      "Small instance n°76\n",
      "Small instance n°77\n",
      "Small instance n°78\n",
      "Small instance n°79\n",
      "Small instance n°80\n",
      "Small instance n°81\n",
      "Small instance n°82\n",
      "Small instance n°83\n",
      "Small instance n°84\n",
      "Small instance n°85\n",
      "Small instance n°86\n",
      "Small instance n°87\n",
      "Small instance n°88\n",
      "Small instance n°89\n",
      "Small instance n°90\n",
      "Small instance n°91\n",
      "Small instance n°92\n",
      "Small instance n°93\n",
      "Small instance n°94\n",
      "Small instance n°95\n",
      "Small instance n°96\n",
      "Small instance n°97\n",
      "Small instance n°98\n",
      "Small instance n°99\n",
      "Small instance n°100\n",
      "{1: 0.0009999275207519531, 2: 0.0009999275207519531, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0, 8: 0.0, 9: 0.0, 10: 0.0010001659393310547, 11: 0.0, 12: 0.0, 13: 0.0, 14: 0.0, 15: 0.0, 16: 0.0, 17: 0.0010001659393310547, 18: 0.0, 19: 0.0, 20: 0.0, 21: 0.0, 22: 0.0, 23: 0.0, 24: 0.002000093460083008, 25: 0.0009999275207519531, 26: 0.0, 27: 0.0, 28: 0.0, 29: 0.0, 30: 0.0009999275207519531, 31: 0.0, 32: 0.0, 33: 0.0, 34: 0.0009999275207519531, 35: 0.0010001659393310547, 36: 0.0, 37: 0.0, 38: 0.0, 39: 0.0, 40: 0.0, 41: 0.0, 42: 0.0, 43: 0.0009999275207519531, 44: 0.0, 45: 0.0, 46: 0.0, 47: 0.0009999275207519531, 48: 0.0009999275207519531, 49: 0.0009999275207519531, 50: 0.0, 51: 0.0, 52: 0.0, 53: 0.0009999275207519531, 54: 0.0, 55: 0.0009999275207519531, 56: 0.0, 57: 0.0009999275207519531, 58: 0.0, 59: 0.0, 60: 0.0019998550415039062, 61: 0.0, 62: 0.0009999275207519531, 63: 0.0, 64: 0.0, 65: 0.0, 66: 0.0010001659393310547, 67: 0.002000093460083008, 68: 0.0009999275207519531, 69: 0.0009999275207519531, 70: 0.0, 71: 0.0, 72: 0.0010001659393310547, 73: 0.0, 74: 0.0009999275207519531, 75: 0.0009999275207519531, 76: 0.0, 77: 0.0010001659393310547, 78: 0.0009999275207519531, 79: 0.0, 80: 0.0, 81: 0.0, 82: 0.0, 83: 0.0, 84: 0.0, 85: 0.0009999275207519531, 86: 0.0009999275207519531, 87: 0.0010001659393310547, 88: 0.0009999275207519531, 89: 0.0, 90: 0.0009999275207519531, 91: 0.0009999275207519531, 92: 0.0, 93: 0.0010001659393310547, 94: 0.0010001659393310547, 95: 0.0, 96: 0.0010001659393310547, 97: 0.0, 98: 0.0, 99: 0.0, 100: 0.0}\n",
      "{1: 0.6198641481852656, 2: 0.665778022248497, 3: 0.6339946629735003, 4: 0.5381948907172824, 5: 0.7980489581846234, 6: 0.7597182927148285, 7: 0.6923272582228941, 8: 0.7239474548707281, 9: 0.6082532031399059, 10: 0.6582189977831391, 11: 0.6979134866186782, 12: 0.6937936358040542, 13: 0.36158988455929675, 14: 0.643643829788082, 15: 0.6301191285387919, 16: 0.703063303616732, 17: 0.6529342845347634, 18: 0.5719687063811433, 19: 0.7736621239584691, 20: 0.8215100532919005, 21: 0.6039693690331019, 22: 0.5840008396636683, 23: 0.7002654382794304, 24: 0.5870423119027616, 25: 0.5639239449897495, 26: 0.6387336447048173, 27: 0.46665627380104824, 28: 0.5130263831246537, 29: 0.6861348432642971, 30: 0.47629352659105795, 31: 0.7034142605390751, 32: 0.6779967895254999, 33: 0.7268027539943671, 34: 0.4619450779463765, 35: 0.6811198277526705, 36: 0.7079042104369374, 37: 0.7061402195164916, 38: 0.6969502712354873, 39: 0.7688453773380569, 40: 0.6430490172675668, 41: 0.7597511806820524, 42: 0.27159245295649737, 43: 0.7123503086062363, 44: 0.555894647922259, 45: 0.6559557300705918, 46: 0.6744227970276669, 47: 0.55645877348104, 48: 0.6598082322462533, 49: 0.5287678504945665, 50: 0.6766075491946026, 51: 0.5686466144639117, 52: 0.5775836875834898, 53: 0.6185678851514161, 54: 0.6736624592411472, 55: 0.682132741835624, 56: 0.7001178868315409, 57: 0.6409622310065192, 58: 0.6285944561644837, 59: 0.6925459704070851, 60: 0.7085400424419916, 61: 0.4661506073154812, 62: 0.6502662431286481, 63: 0.6459262407647419, 64: 0.6334533612609957, 65: 0.5393222807815475, 66: 0.6897142768545804, 67: 0.6394986447218494, 68: 0.5099792376225571, 69: 0.6513052226167919, 70: 0.7803850302374272, 71: 0.7536008004241836, 72: 0.7304256520648239, 73: 0.3375609564419679, 74: 0.6590403091541527, 75: 0.5393826118402631, 76: 0.7104622278085393, 77: 0.7025420213449446, 78: 0.6672144402633495, 79: 0.5583537659723482, 80: 0.4819834465448475, 81: 0.37602789467798714, 82: 0.7774608632049526, 83: 0.6679041422016521, 84: 0.5662643690579006, 85: 0.6892995599013645, 86: 0.6353074222646182, 87: 0.6397066964662055, 88: 0.4396942650114388, 89: 0.6926367749002211, 90: 0.6406449025471112, 91: 0.7444865687539512, 92: 0.6208151365880067, 93: 0.517993851887793, 94: 0.6330622102055665, 95: 0.6822823466551922, 96: 0.5815540602792773, 97: 0.7655140156408617, 98: 0.6277470136105845, 99: 0.537729512568375, 100: 0.5818520131397866}\n",
      "{1: 3, 2: 1, 3: 2, 4: 3, 5: 3, 6: 3, 7: 3, 8: 3, 9: 4, 10: 2, 11: 2, 12: 2, 13: 3, 14: 10, 15: 3, 16: 4, 17: 5, 18: 2, 19: 4, 20: 6, 21: 3, 22: 4, 23: 10, 24: 5, 25: 3, 26: 4, 27: 3, 28: 3, 29: 10, 30: 3, 31: 3, 32: 3, 33: 5, 34: 3, 35: 2, 36: 4, 37: 2, 38: 4, 39: 5, 40: 3, 41: 3, 42: 2, 43: 10, 44: 4, 45: 4, 46: 3, 47: 5, 48: 3, 49: 2, 50: 10, 51: 3, 52: 4, 53: 3, 54: 4, 55: 3, 56: 10, 57: 3, 58: 3, 59: 4, 60: 10, 61: 2, 62: 3, 63: 2, 64: 2, 65: 3, 66: 10, 67: 3, 68: 3, 69: 4, 70: 4, 71: 4, 72: 3, 73: 4, 74: 10, 75: 3, 76: 2, 77: 6, 78: 3, 79: 3, 80: 10, 81: 4, 82: 10, 83: 3, 84: 3, 85: 4, 86: 4, 87: 5, 88: 2, 89: 2, 90: 3, 91: 3, 92: 3, 93: 3, 94: 3, 95: 2, 96: 3, 97: 3, 98: 3, 99: 2, 100: 4}\n"
     ]
    }
   ],
   "source": [
    "from gurobipy import Model, GRB\n",
    "\n",
    "\n",
    "def solve_with_gurobi(k, r, mu):\n",
    "    model = gp.Model(\"AP-L\")\n",
    "    model.setParam('OutputFlag', 0)\n",
    "\n",
    "    # Variables\n",
    "    y0 = model.addVar(vtype=GRB.CONTINUOUS, name=\"y0\")\n",
    "    y = model.addVars(len(mu) - 1, vtype=GRB.CONTINUOUS, name=\"y\")\n",
    "\n",
    "    # Objective function\n",
    "    model.setObjective(r[0] * y0 + gp.quicksum(r[i + 1] * y[i] for i in range(k)), GRB.MAXIMIZE)\n",
    "\n",
    "    # Constraints\n",
    "    model.addConstr(y0 + gp.quicksum(y[i] for i in range(k)) == 1, \"probability_sum\")\n",
    "    for i in range(k):\n",
    "        model.addConstr(y[i] <= y0 * np.exp(mu[i + 1]), f\"probability{i}\")\n",
    "\n",
    "    # Optimize\n",
    "    model.optimize()\n",
    "\n",
    "    if model.status == GRB.OPTIMAL:\n",
    "        y0_val = y0.X\n",
    "        y_vals = [y[i].X for i in range(k)]\n",
    "        return model\n",
    "    else:\n",
    "        return None, None, None\n",
    "    \n",
    "def greedy_algorithm_with_gurobi(r, mu):\n",
    "    n = len(r) - 1\n",
    "    best_value = -np.inf\n",
    "    best_k = 0\n",
    "    for k in range(1, n + 1):\n",
    "        model  = solve_with_gurobi(k, r, mu)\n",
    "        obj_val = model.ObjVal\n",
    "        if obj_val is not None and obj_val > best_value:\n",
    "            best_value = obj_val\n",
    "            best_k = k\n",
    "    return best_k, best_value, model.Runtime\n",
    "\n",
    "\n",
    "# Solve the AP_L for the small instances\n",
    "small_r = instances_small_r\n",
    "small_mu = instances_small_mu\n",
    "\n",
    "n = len(small_r[0]) - 1 # Number of products\n",
    "n_small_instances = len(small_r) # Number of instances\n",
    "\n",
    "small_instances_runtimes = {instance: None for instance in range(1,n_small_instances+1)}\n",
    "small_instances_k_values = {instance: None for instance in range(1,n_small_instances+1)}\n",
    "small_instances_optimal_values = {instance: None for instance in range(1,n_small_instances+1)}\n",
    "\n",
    "\n",
    "for i in range(n_small_instances):\n",
    "    print(f\"Small instance n°{i+1}\")\n",
    "    k, value, runtime = greedy_algorithm_with_gurobi(small_r[i], small_mu[i])\n",
    "    small_instances_runtimes[i+1]= runtime\n",
    "    small_instances_optimal_values[i+1] = value\n",
    "    small_instances_k_values[i+1] = k\n",
    "    \n",
    "print(small_instances_runtimes)\n",
    "print(small_instances_optimal_values)\n",
    "print(small_instances_k_values)\n",
    "\n",
    "# Solve the AP_L for the medium instances\n",
    "# medium_r = instances_medium_r\n",
    "# medium_mu = instances_medium_mu\n",
    "\n",
    "# n = len(medium_r[0]) - 1 # Number of products\n",
    "# n_medium_instances = len(medium_r) # Number of instances\n",
    "\n",
    "# medium_instances_runtimes = {instance: None for instance in range(1,n_medium_instances+1)}\n",
    "# medium_instances_optimal_values = {instance: None for instance in range(1,n_medium_instances+1)}\n",
    "# medium_instances_k_values = {instance: None for instance in range(1,n_medium_instances+1)}\n",
    "\n",
    "\n",
    "# for i in range(n_medium_instances):\n",
    "#     print(f\"medium instance n°{i+1}\")\n",
    "#     k,value,runtime = greedy_algorithm_with_gurobi(medium_r[i], medium_mu[i])\n",
    "#     medium_instances_runtimes[i+1]= runtime\n",
    "#     medium_instances_optimal_values[i+1] = value\n",
    "#     medium_instances_k_values[i+1] = k\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. A more practical model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now suppose that the retailer can only offer up to $p$ products to its customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 3.1 Starting from the AP-L formulation, explain why the new model admits the following Mixed Integer Linear Program formulation (variables, constraints, objective function):\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\max _{y, y_{0} \\geqslant 0, z \\in\\{0,1\\}^{n}} & r_{0} y_{0}+\\sum_{i=1}^{n} r_{i} y_{i} \\\\\n",
    "\\text { s.t. } \\quad & y_{0}+\\sum_{i=1}^{n} y_{i}=1 \\\\\n",
    "& y_{i} \\leqslant y_{0} e^{\\mu_{i}}, \\\\\n",
    "& y \\leqslant z, \\quad \\sum_{i=1}^{n} z_{i} \\leqslant p\n",
    "\\end{aligned} \\quad \\forall i \\in \\mathcal{I}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the MILP formulation, we can introduce binary variables $z_{i} \\in \\{0,1\\}$ to indicate whether product $i$ is included in the assortment. We will have to add two constraints:\n",
    "\n",
    "$$ y_{i} \\leq z_{i}  \\implies y \\leq z$$\n",
    "\n",
    "This ensures that $ y_{i} $ can only be positive if $ z_{i} = 1 $ and:\n",
    "\n",
    "$$ \\sum_{i=1}^{n} z_{i} \\leq p $$\n",
    "\n",
    "This ensures that no more than $p$ products are included in the assortment. The objective function and the other constratins will not change from AP-L since the two constraints we added above will limit $y_i$ to 0 if we have more than p products. So our final MILP formulation is:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\max _{y_{0}, y \\geqslant 0, z \\in\\{0,1\\}^{n}} & r_{0} y_{0}+\\sum_{i=1}^{n} r_{i} y_{i} \\\\\n",
    "\\text { s.t. } \\quad & y_{0}+\\sum_{i=1}^{n} y_{i}=1 \\\\\n",
    "& y_{i} \\leqslant y_{0} e^{\\mu_{i}}, \\\\\n",
    "& y \\leqslant z, \\quad \\sum_{i=1}^{n} z_{i} \\leqslant p\n",
    "\\end{aligned} \\quad \\forall i \\in \\mathcal{I}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### 3.2 Is the previous algorithm still working for the APC-MILP problem? Implement APC-MILP with one of the allowed solvers, and compare the results for $p \\in\\{1, n / 5, n / 2, n\\}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine if the previous algorithm is still working for the APC-MILP problem, we need to understand the modifications introduced by the MILP formulation. The original algorithm was designed to solve the AP-L formulation, which involved continuous variables. The MILP formulation introduces binary variables, making the problem more complex and requiring a different solving approach.\n",
    "\n",
    "### Implementation\n",
    "Implementing the APC-MILP involves using a solver capable of handling mixed-integer linear programs. Commonly used solvers include Gurobi, CPLEX, and CBC. Below is a generic implementation outline using Python with a solver like Gurobi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Small instance n°0\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°1\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°2\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°3\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°4\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°5\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°6\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°7\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°8\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°9\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°10\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°11\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°12\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°13\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°14\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°15\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°16\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°17\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°18\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°19\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°20\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°21\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°22\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°23\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°24\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°25\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°26\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°27\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°28\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°29\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°30\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°31\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°32\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°33\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°34\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°35\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°36\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°37\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°38\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°39\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°40\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°41\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°42\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°43\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°44\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°45\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°46\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°47\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°48\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°49\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°50\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°51\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°52\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°53\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°54\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°55\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°56\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°57\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°58\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°59\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°60\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°61\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°62\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°63\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°64\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°65\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°66\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°67\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°68\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°69\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°70\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°71\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°72\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°73\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°74\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°75\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°76\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°77\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°78\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°79\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°80\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°81\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°82\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°83\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°84\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°85\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°86\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°87\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°88\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°89\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°90\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°91\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°92\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°93\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°94\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°95\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°96\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°97\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°98\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "Small instance n°99\n",
      "p = 1\n",
      "p = 2\n",
      "p = 5\n",
      "p = 10\n",
      "{1: {1: 0.006000041961669922, 2: 0.006999969482421875, 5: 0.0009999275207519531, 10: 0.0019998550415039062}, 2: {1: 0.0009999275207519531, 2: 0.0010001659393310547, 5: 0.002000093460083008, 10: 0.002000093460083008}, 3: {1: 0.003000020980834961, 2: 0.0009999275207519531, 5: 0.0, 10: 0.002000093460083008}, 4: {1: 0.002000093460083008, 2: 0.004999876022338867, 5: 0.0010001659393310547, 10: 0.0010001659393310547}, 5: {1: 0.006000041961669922, 2: 0.004999876022338867, 5: 0.0010001659393310547, 10: 0.002000093460083008}, 6: {1: 0.00599980354309082, 2: 0.004999876022338867, 5: 0.0009999275207519531, 10: 0.0019998550415039062}, 7: {1: 0.003000020980834961, 2: 0.006000041961669922, 5: 0.0009999275207519531, 10: 0.0019998550415039062}, 8: {1: 0.003999948501586914, 2: 0.00800013542175293, 5: 0.0009999275207519531, 10: 0.0010001659393310547}, 9: {1: 0.005000114440917969, 2: 0.004999876022338867, 5: 0.0009999275207519531, 10: 0.0010001659393310547}, 10: {1: 0.003000020980834961, 2: 0.0009999275207519531, 5: 0.002000093460083008, 10: 0.0010001659393310547}, 11: {1: 0.004999876022338867, 2: 0.0009999275207519531, 5: 0.0009999275207519531, 10: 0.002000093460083008}, 12: {1: 0.004999876022338867, 2: 0.002000093460083008, 5: 0.0010001659393310547, 10: 0.003000020980834961}, 13: {1: 0.003999948501586914, 2: 0.009000062942504883, 5: 0.002000093460083008, 10: 0.002000093460083008}, 14: {1: 0.006999969482421875, 2: 0.009999990463256836, 5: 0.0019998550415039062, 10: 0.002000093460083008}, 15: {1: 0.006000041961669922, 2: 0.006999969482421875, 5: 0.0019998550415039062, 10: 0.0010001659393310547}, 16: {1: 0.0070002079010009766, 2: 0.009000062942504883, 5: 0.0009999275207519531, 10: 0.002000093460083008}, 17: {1: 0.006999969482421875, 2: 0.01100015640258789, 5: 0.002000093460083008, 10: 0.0009999275207519531}, 18: {1: 0.0019998550415039062, 2: 0.0009999275207519531, 5: 0.0009999275207519531, 10: 0.002000093460083008}, 19: {1: 0.003999948501586914, 2: 0.009999990463256836, 5: 0.0009999275207519531, 10: 0.002000093460083008}, 20: {1: 0.005000114440917969, 2: 0.009999990463256836, 5: 0.009999990463256836, 10: 0.0009999275207519531}, 21: {1: 0.005000114440917969, 2: 0.003999948501586914, 5: 0.0019998550415039062, 10: 0.0009999275207519531}, 22: {1: 0.006000041961669922, 2: 0.009000062942504883, 5: 0.0010001659393310547, 10: 0.0009999275207519531}, 23: {1: 0.006000041961669922, 2: 0.006000041961669922, 5: 0.0009999275207519531, 10: 0.0019998550415039062}, 24: {1: 0.010000228881835938, 2: 0.017999887466430664, 5: 0.0009999275207519531, 10: 0.002000093460083008}, 25: {1: 0.006000041961669922, 2: 0.006000041961669922, 5: 0.0009999275207519531, 10: 0.002000093460083008}, 26: {1: 0.005000114440917969, 2: 0.006000041961669922, 5: 0.002000093460083008, 10: 0.002000093460083008}, 27: {1: 0.004999876022338867, 2: 0.005000114440917969, 5: 0.0009999275207519531, 10: 0.0009999275207519531}, 28: {1: 0.004999876022338867, 2: 0.008999824523925781, 5: 0.002000093460083008, 10: 0.002000093460083008}, 29: {1: 0.011999845504760742, 2: 0.0009999275207519531, 5: 0.0009999275207519531, 10: 0.005000114440917969}, 30: {1: 0.004000186920166016, 2: 0.010999917984008789, 5: 0.003000020980834961, 10: 0.0009999275207519531}, 31: {1: 0.007999897003173828, 2: 0.009999990463256836, 5: 0.003000020980834961, 10: 0.003000020980834961}, 32: {1: 0.006000041961669922, 2: 0.009000062942504883, 5: 0.002000093460083008, 10: 0.003999948501586914}, 33: {1: 0.006999969482421875, 2: 0.014999866485595703, 5: 0.0019998550415039062, 10: 0.0009999275207519531}, 34: {1: 0.006000041961669922, 2: 0.004999876022338867, 5: 0.003000020980834961, 10: 0.0019998550415039062}, 35: {1: 0.003000020980834961, 2: 0.0009999275207519531, 5: 0.0010001659393310547, 10: 0.003000020980834961}, 36: {1: 0.003999948501586914, 2: 0.006999969482421875, 5: 0.0019998550415039062, 10: 0.003000020980834961}, 37: {1: 0.002000093460083008, 2: 0.002000093460083008, 5: 0.0010001659393310547, 10: 0.003000020980834961}, 38: {1: 0.009999990463256836, 2: 0.009000062942504883, 5: 0.002000093460083008, 10: 0.003000020980834961}, 39: {1: 0.006000041961669922, 2: 0.015000104904174805, 5: 0.002000093460083008, 10: 0.003000020980834961}, 40: {1: 0.00800013542175293, 2: 0.009000062942504883, 5: 0.002000093460083008, 10: 0.002000093460083008}, 41: {1: 0.009999990463256836, 2: 0.009999990463256836, 5: 0.005000114440917969, 10: 0.002000093460083008}, 42: {1: 0.004999876022338867, 2: 0.003000020980834961, 5: 0.002000093460083008, 10: 0.003000020980834961}, 43: {1: 0.00800013542175293, 2: 0.00800013542175293, 5: 0.0019998550415039062, 10: 0.003000020980834961}, 44: {1: 0.008999824523925781, 2: 0.013000011444091797, 5: 0.003000020980834961, 10: 0.002000093460083008}, 45: {1: 0.006000041961669922, 2: 0.011999845504760742, 5: 0.0029997825622558594, 10: 0.0009999275207519531}, 46: {1: 0.009999990463256836, 2: 0.00599980354309082, 5: 0.0019998550415039062, 10: 0.004000186920166016}, 47: {1: 0.013000011444091797, 2: 0.015000104904174805, 5: 0.003000020980834961, 10: 0.0019998550415039062}, 48: {1: 0.007999897003173828, 2: 0.006999969482421875, 5: 0.0019998550415039062, 10: 0.002000093460083008}, 49: {1: 0.009000062942504883, 2: 0.003000020980834961, 5: 0.002000093460083008, 10: 0.0009999275207519531}, 50: {1: 0.013000011444091797, 2: 0.01100015640258789, 5: 0.003000020980834961, 10: 0.0019998550415039062}, 51: {1: 0.006000041961669922, 2: 0.004999876022338867, 5: 0.002000093460083008, 10: 0.002000093460083008}, 52: {1: 0.0070002079010009766, 2: 0.006000041961669922, 5: 0.003000020980834961, 10: 0.0009999275207519531}, 53: {1: 0.009999990463256836, 2: 0.006000041961669922, 5: 0.002000093460083008, 10: 0.002000093460083008}, 54: {1: 0.009000062942504883, 2: 0.007999897003173828, 5: 0.004000186920166016, 10: 0.006000041961669922}, 55: {1: 0.026000022888183594, 2: 0.03500008583068848, 5: 0.005000114440917969, 10: 0.003999948501586914}, 56: {1: 0.006999969482421875, 2: 0.003000020980834961, 5: 0.0010001659393310547, 10: 0.0009999275207519531}, 57: {1: 0.006999969482421875, 2: 0.009000062942504883, 5: 0.0009999275207519531, 10: 0.0009999275207519531}, 58: {1: 0.005000114440917969, 2: 0.009999990463256836, 5: 0.0010001659393310547, 10: 0.0009999275207519531}, 59: {1: 0.009000062942504883, 2: 0.009999990463256836, 5: 0.002000093460083008, 10: 0.0009999275207519531}, 60: {1: 0.0010001659393310547, 2: 0.002000093460083008, 5: 0.003000020980834961, 10: 0.003000020980834961}, 61: {1: 0.003999948501586914, 2: 0.0009999275207519531, 5: 0.0010001659393310547, 10: 0.0009999275207519531}, 62: {1: 0.00599980354309082, 2: 0.006999969482421875, 5: 0.003000020980834961, 10: 0.003000020980834961}, 63: {1: 0.006000041961669922, 2: 0.003000020980834961, 5: 0.002000093460083008, 10: 0.0010001659393310547}, 64: {1: 0.007999897003173828, 2: 0.002000093460083008, 5: 0.0019998550415039062, 10: 0.0010001659393310547}, 65: {1: 0.013000011444091797, 2: 0.009999990463256836, 5: 0.002000093460083008, 10: 0.003999948501586914}, 66: {1: 0.00800013542175293, 2: 0.010999917984008789, 5: 0.002000093460083008, 10: 0.003999948501586914}, 67: {1: 0.004000186920166016, 2: 0.010999917984008789, 5: 0.0010001659393310547, 10: 0.0019998550415039062}, 68: {1: 0.009000062942504883, 2: 0.009999990463256836, 5: 0.0010001659393310547, 10: 0.0019998550415039062}, 69: {1: 0.006999969482421875, 2: 0.01399993896484375, 5: 0.0019998550415039062, 10: 0.0019998550415039062}, 70: {1: 0.006999969482421875, 2: 0.006999969482421875, 5: 0.0009999275207519531, 10: 0.003000020980834961}, 71: {1: 0.012000083923339844, 2: 0.015999794006347656, 5: 0.002000093460083008, 10: 0.002000093460083008}, 72: {1: 0.006000041961669922, 2: 0.008999824523925781, 5: 0.003000020980834961, 10: 0.003000020980834961}, 73: {1: 0.006999969482421875, 2: 0.012000083923339844, 5: 0.0019998550415039062, 10: 0.003000020980834961}, 74: {1: 0.006000041961669922, 2: 0.009999990463256836, 5: 0.0010001659393310547, 10: 0.0019998550415039062}, 75: {1: 0.007999897003173828, 2: 0.006000041961669922, 5: 0.0009999275207519531, 10: 0.002000093460083008}, 76: {1: 0.003000020980834961, 2: 0.0009999275207519531, 5: 0.003000020980834961, 10: 0.003000020980834961}, 77: {1: 0.006999969482421875, 2: 0.017999887466430664, 5: 0.011999845504760742, 10: 0.002000093460083008}, 78: {1: 0.009000062942504883, 2: 0.006999969482421875, 5: 0.002000093460083008, 10: 0.003000020980834961}, 79: {1: 0.003000020980834961, 2: 0.007999897003173828, 5: 0.0019998550415039062, 10: 0.0009999275207519531}, 80: {1: 0.00800013542175293, 2: 0.010999917984008789, 5: 0.002000093460083008, 10: 0.0010001659393310547}, 81: {1: 0.006000041961669922, 2: 0.008999824523925781, 5: 0.0009999275207519531, 10: 0.002000093460083008}, 82: {1: 0.003999948501586914, 2: 0.005000114440917969, 5: 0.002000093460083008, 10: 0.0010001659393310547}, 83: {1: 0.00800013542175293, 2: 0.009999990463256836, 5: 0.0009999275207519531, 10: 0.002000093460083008}, 84: {1: 0.006999969482421875, 2: 0.005000114440917969, 5: 0.0009999275207519531, 10: 0.002000093460083008}, 85: {1: 0.006000041961669922, 2: 0.012000083923339844, 5: 0.002000093460083008, 10: 0.0009999275207519531}, 86: {1: 0.006000041961669922, 2: 0.009000062942504883, 5: 0.0019998550415039062, 10: 0.003000020980834961}, 87: {1: 0.013000011444091797, 2: 0.03099989891052246, 5: 0.002000093460083008, 10: 0.0019998550415039062}, 88: {1: 0.009999990463256836, 2: 0.0019998550415039062, 5: 0.002000093460083008, 10: 0.003000020980834961}, 89: {1: 0.00599980354309082, 2: 0.0009999275207519531, 5: 0.003000020980834961, 10: 0.003000020980834961}, 90: {1: 0.004999876022338867, 2: 0.007999897003173828, 5: 0.0019998550415039062, 10: 0.002000093460083008}, 91: {1: 0.009999990463256836, 2: 0.005000114440917969, 5: 0.002000093460083008, 10: 0.003999948501586914}, 92: {1: 0.006000041961669922, 2: 0.009999990463256836, 5: 0.0009999275207519531, 10: 0.0009999275207519531}, 93: {1: 0.007999897003173828, 2: 0.006999969482421875, 5: 0.0009999275207519531, 10: 0.002000093460083008}, 94: {1: 0.006000041961669922, 2: 0.009000062942504883, 5: 0.0010001659393310547, 10: 0.002000093460083008}, 95: {1: 0.00800013542175293, 2: 0.002000093460083008, 5: 0.0009999275207519531, 10: 0.0009999275207519531}, 96: {1: 0.003999948501586914, 2: 0.003999948501586914, 5: 0.002000093460083008, 10: 0.0019998550415039062}, 97: {1: 0.006999969482421875, 2: 0.003999948501586914, 5: 0.002000093460083008, 10: 0.003000020980834961}, 98: {1: 0.0029997825622558594, 2: 0.004999876022338867, 5: 0.0009999275207519531, 10: 0.003000020980834961}, 99: {1: 0.004999876022338867, 2: 0.0019998550415039062, 5: 0.002000093460083008, 10: 0.0009999275207519531}, 100: {1: 0.008999824523925781, 2: 0.008999824523925781, 5: 0.0019998550415039062, 10: 0.0019998550415039062}}\n",
      "{1: {1: 0.5051598474010114, 2: 0.586121203824268, 5: 0.6198641481852656, 10: 0.6198641481852656}, 2: {1: 0.665778022248497, 2: 0.665778022248497, 5: 0.665778022248497, 10: 0.665778022248497}, 3: {1: 0.5860772381431256, 2: 0.6339946629735003, 5: 0.6339946629735003, 10: 0.6339946629735003}, 4: {1: 0.5002104764686907, 2: 0.5312540778442186, 5: 0.5381948907172824, 10: 0.5381948907172824}, 5: {1: 0.6368081973935169, 2: 0.7524656326428268, 5: 0.7980489581846234, 10: 0.7980489581846234}, 6: {1: 0.615711695902684, 2: 0.723571965671864, 5: 0.7597182927148285, 10: 0.7597182927148285}, 7: {1: 0.6167270302351567, 2: 0.6638133157126076, 5: 0.6923272582228941, 10: 0.6923272582228941}, 8: {1: 0.5881676473285752, 2: 0.692597066675673, 5: 0.7239474548707281, 10: 0.7239474548707281}, 9: {1: 0.48755645885707216, 2: 0.5998321405202052, 5: 0.608253203139906, 10: 0.608253203139906}, 10: {1: 0.6100996397043438, 2: 0.6582189977831391, 5: 0.6582189977831391, 10: 0.6582189977831391}, 11: {1: 0.6238934175515555, 2: 0.6979134866186782, 5: 0.6979134866186782, 10: 0.6979134866186782}, 12: {1: 0.6128781941669699, 2: 0.6937936358040542, 5: 0.6937936358040542, 10: 0.6937936358040542}, 13: {1: 0.29917068520107803, 2: 0.34438283717439266, 5: 0.36158988455929675, 10: 0.36158988455929675}, 14: {1: 0.5126429548780473, 2: 0.5967025916444167, 5: 0.6436438297880819, 10: 0.643643829788082}, 15: {1: 0.5171097916937513, 2: 0.6271872842888628, 5: 0.630119128538792, 10: 0.630119128538792}, 16: {1: 0.5634031536123149, 2: 0.6541185366621931, 5: 0.703063303616732, 10: 0.703063303616732}, 17: {1: 0.5096404334498239, 2: 0.5983650567024612, 5: 0.6529342845347634, 10: 0.6529342845347634}, 18: {1: 0.5192165501049865, 2: 0.5719687063811433, 5: 0.5719687063811434, 10: 0.5719687063811434}, 19: {1: 0.6429737470941655, 2: 0.7233616937703156, 5: 0.7736621239584691, 10: 0.7736621239584691}, 20: {1: 0.6886713967992117, 2: 0.7687711664198243, 5: 0.8186146834044977, 10: 0.8215100532919005}, 21: {1: 0.4999667916933303, 2: 0.6036603403443047, 5: 0.6039693690331019, 10: 0.6039693690331019}, 22: {1: 0.46821563862252275, 2: 0.544485953157777, 5: 0.5840008396636683, 10: 0.5840008396636683}, 23: {1: 0.568434756965498, 2: 0.6612640410199914, 5: 0.7002654382794303, 10: 0.7002654382794303}, 24: {1: 0.4611381704771727, 2: 0.5457819777950649, 5: 0.5870423119027616, 10: 0.5870423119027617}, 25: {1: 0.4624609715593937, 2: 0.5374709766208696, 5: 0.5639239449897495, 10: 0.5639239449897495}, 26: {1: 0.5504207042118355, 2: 0.625269768748903, 5: 0.6387336447048173, 10: 0.6387336447048173}, 27: {1: 0.3713707255124445, 2: 0.4568470345607166, 5: 0.46665627380104824, 10: 0.46665627380104824}, 28: {1: 0.3985818607466571, 2: 0.4756202366592778, 5: 0.5130263831246537, 10: 0.5130263831246537}, 29: {1: 0.5722708557427066, 2: 0.686134843264297, 5: 0.686134843264297, 10: 0.686134843264297}, 30: {1: 0.4586099162005257, 2: 0.4702525404785298, 5: 0.476293526591058, 10: 0.476293526591058}, 31: {1: 0.5852970225283178, 2: 0.6696113107292608, 5: 0.7034142605390751, 10: 0.7034142605390751}, 32: {1: 0.5875327959066817, 2: 0.6442670662775203, 5: 0.6779967895254999, 10: 0.6779967895254999}, 33: {1: 0.5560818730666934, 2: 0.6628087238043924, 5: 0.7268027539943671, 10: 0.7268027539943671}, 34: {1: 0.44249727979186615, 2: 0.4560447146098478, 5: 0.4619450779463765, 10: 0.4619450779463765}, 35: {1: 0.6298634415132314, 2: 0.6811198277526705, 5: 0.6811198277526705, 10: 0.6811198277526705}, 36: {1: 0.6229605602259193, 2: 0.6749750933601104, 5: 0.7079042104369374, 10: 0.7079042104369375}, 37: {1: 0.6975114820498299, 2: 0.7061402195164916, 5: 0.7061402195164916, 10: 0.7061402195164916}, 38: {1: 0.5226486324945635, 2: 0.638376686859125, 5: 0.6969502712354873, 10: 0.6969502712354873}, 39: {1: 0.6579081217391233, 2: 0.7241818414716301, 5: 0.7688453773380569, 10: 0.7688453773380569}, 40: {1: 0.5523203814098541, 2: 0.6215181021644299, 5: 0.6430490172675668, 10: 0.6430490172675668}, 41: {1: 0.5858678378893509, 2: 0.7209633299236818, 5: 0.7597511806820524, 10: 0.7597511806820524}, 42: {1: 0.2557855016505, 2: 0.27159245295649737, 5: 0.27159245295649737, 10: 0.27159245295649737}, 43: {1: 0.5815699122170171, 2: 0.6813464540830511, 5: 0.7123503086062363, 10: 0.7123503086062363}, 44: {1: 0.43204487703987104, 2: 0.5118536005808151, 5: 0.555894647922259, 10: 0.5558946479222591}, 45: {1: 0.49819406807504657, 2: 0.6055916943057549, 5: 0.6559557300705919, 10: 0.6559557300705918}, 46: {1: 0.5939364297896605, 2: 0.6675388551639945, 5: 0.6744227970276669, 10: 0.6744227970276669}, 47: {1: 0.45368943715180643, 2: 0.5300800964032737, 5: 0.55645877348104, 10: 0.55645877348104}, 48: {1: 0.5701853937774584, 2: 0.6389428192889826, 5: 0.6598082322462533, 10: 0.6598082322462533}, 49: {1: 0.4664899041719747, 2: 0.5287678504945665, 5: 0.5287678504945665, 10: 0.5287678504945665}, 50: {1: 0.5678500088457547, 2: 0.6393593511351159, 5: 0.6766075491946025, 10: 0.6766075491946025}, 51: {1: 0.4944316199992456, 2: 0.5619066852064657, 5: 0.5686466144639117, 10: 0.5686466144639117}, 52: {1: 0.46726307028245945, 2: 0.568915087030915, 5: 0.5775836875834898, 10: 0.5775836875834897}, 53: {1: 0.5400719484934353, 2: 0.6122944267069377, 5: 0.6185678851514161, 10: 0.6185678851514161}, 54: {1: 0.5811325934342193, 2: 0.654905515360739, 5: 0.6736624592411472, 10: 0.6736624592411473}, 55: {1: 0.5510048679979019, 2: 0.6715020763756667, 5: 0.682132741835624, 10: 0.682132741835624}, 56: {1: 0.611687679359684, 2: 0.7001178868315407, 5: 0.7001178868315407, 10: 0.7001178868315407}, 57: {1: 0.5353695634733238, 2: 0.6199772343703109, 5: 0.6409622310065192, 10: 0.6409622310065192}, 58: {1: 0.48018553752733756, 2: 0.5868761445687096, 5: 0.6285944561644837, 10: 0.6285944561644837}, 59: {1: 0.5530266113917623, 2: 0.6422543692702967, 5: 0.6925459704070851, 10: 0.6925459704070852}, 60: {1: 0.7085400424419916, 2: 0.7085400424419916, 5: 0.7085400424419916, 10: 0.7085400424419916}, 61: {1: 0.41794717770203077, 2: 0.4661506073154812, 5: 0.4661506073154812, 10: 0.4661506073154812}, 62: {1: 0.5741828440306019, 2: 0.6343283011524296, 5: 0.6502662431286481, 10: 0.6502662431286481}, 63: {1: 0.5540511652208987, 2: 0.6459262407647419, 5: 0.6459262407647419, 10: 0.6459262407647419}, 64: {1: 0.5976637535928131, 2: 0.6334533612609957, 5: 0.6334533612609957, 10: 0.6334533612609957}, 65: {1: 0.45789336825332805, 2: 0.5336655044010232, 5: 0.5393222807815475, 10: 0.5393222807815475}, 66: {1: 0.5867729850267434, 2: 0.6519536826197921, 5: 0.6897142768545804, 10: 0.6897142768545804}, 67: {1: 0.5788818527745545, 2: 0.6234372346794723, 5: 0.6394986447218494, 10: 0.6394986447218494}, 68: {1: 0.4059153834647778, 2: 0.4750563518250685, 5: 0.5099792376225573, 10: 0.5099792376225573}, 69: {1: 0.5784712970971391, 2: 0.6363622651634521, 5: 0.6513052226167919, 10: 0.6513052226167919}, 70: {1: 0.6277888432299321, 2: 0.7292346275067645, 5: 0.7803850302374272, 10: 0.7803850302374272}, 71: {1: 0.5545294817735436, 2: 0.6813522384743084, 5: 0.7536008004241836, 10: 0.7536008004241836}, 72: {1: 0.598888485471782, 2: 0.6932159973608956, 5: 0.7304256520648239, 10: 0.7304256520648239}, 73: {1: 0.29130576254052915, 2: 0.327096085476337, 5: 0.3375609564419679, 10: 0.3375609564419679}, 74: {1: 0.49420792821667153, 2: 0.6311047406603278, 5: 0.6590403091541527, 10: 0.6590403091541527}, 75: {1: 0.44255737013951213, 2: 0.5310041548478399, 5: 0.5393826118402631, 10: 0.5393826118402631}, 76: {1: 0.6640981787402246, 2: 0.7104622278085393, 5: 0.7104622278085393, 10: 0.7104622278085393}, 77: {1: 0.49609331349347774, 2: 0.6038282593888727, 5: 0.6943404787254448, 10: 0.7025420213449447}, 78: {1: 0.5782745179129638, 2: 0.6483736134442755, 5: 0.6672144402633495, 10: 0.6672144402633495}, 79: {1: 0.5114958477900888, 2: 0.5531464480387406, 5: 0.5583537659723482, 10: 0.5583537659723482}, 80: {1: 0.38556737182120465, 2: 0.44625874976998203, 5: 0.4819834465448474, 10: 0.4819834465448475}, 81: {1: 0.2758770905098237, 2: 0.359722136487049, 5: 0.37602789467798714, 10: 0.3760278946779871}, 82: {1: 0.6494214350907989, 2: 0.7446133777014565, 5: 0.7774608632049526, 10: 0.7774608632049526}, 83: {1: 0.5592751604916226, 2: 0.6398573044309988, 5: 0.6679041422016522, 10: 0.6679041422016522}, 84: {1: 0.44079176097952955, 2: 0.5463461184532776, 5: 0.5662643690579006, 10: 0.5662643690579006}, 85: {1: 0.562710006231181, 2: 0.6529631718190354, 5: 0.6892995599013645, 10: 0.6892995599013645}, 86: {1: 0.5496006643472087, 2: 0.6127215771519083, 5: 0.6353074222646182, 10: 0.6353074222646182}, 87: {1: 0.4507122348309681, 2: 0.568082053199975, 5: 0.6397066964662055, 10: 0.6397066964662055}, 88: {1: 0.3426531258655089, 2: 0.4396942650114388, 5: 0.4396942650114388, 10: 0.4396942650114388}, 89: {1: 0.6048218097395497, 2: 0.6926367749002211, 5: 0.6926367749002211, 10: 0.6926367749002211}, 90: {1: 0.5382793344973497, 2: 0.6361070465737029, 5: 0.6406449025471112, 10: 0.6406449025471112}, 91: {1: 0.6354089344759333, 2: 0.7351735860448615, 5: 0.7444865687539512, 10: 0.7444865687539512}, 92: {1: 0.4765568952604912, 2: 0.5813220816161206, 5: 0.6208151365880067, 10: 0.6208151365880067}, 93: {1: 0.4463184147105359, 2: 0.4987806381219162, 5: 0.517993851887793, 10: 0.517993851887793}, 94: {1: 0.5388981102219531, 2: 0.6255964830922344, 5: 0.6330622102055665, 10: 0.6330622102055665}, 95: {1: 0.6118731243199949, 2: 0.6822823466551922, 5: 0.6822823466551922, 10: 0.6822823466551922}, 96: {1: 0.5324543076401836, 2: 0.5795888686712516, 5: 0.5815540602792773, 10: 0.5815540602792773}, 97: {1: 0.6545519985628638, 2: 0.7519861856394785, 5: 0.7655140156408617, 10: 0.7655140156408617}, 98: {1: 0.5903685608845293, 2: 0.6256136663780942, 5: 0.6277470136105845, 10: 0.6277470136105845}, 99: {1: 0.4564165293113215, 2: 0.537729512568375, 5: 0.537729512568375, 10: 0.537729512568375}, 100: {1: 0.45089873809672754, 2: 0.5373127008662751, 5: 0.5818520131397867, 10: 0.5818520131397866}}\n",
      "Medium instance n°1\n",
      "p = 1\n"
     ]
    }
   ],
   "source": [
    "from gurobipy import Model, GRB\n",
    "\n",
    "def solve_apc_milp(r, mu, p, n):\n",
    "    model = Model(\"APC-MILP\")\n",
    "    \n",
    "    model.setParam('OutputFlag', 0)\n",
    "    # Variables\n",
    "    y0 = model.addVar(vtype=GRB.CONTINUOUS, name=\"y0\")\n",
    "    y = model.addVars(n, vtype=GRB.CONTINUOUS, name=\"y\")\n",
    "    z = model.addVars(n, vtype=GRB.BINARY, name=\"z\")\n",
    "\n",
    "    # Objective function\n",
    "    model.setObjective(r[0] * y0 + gp.quicksum(r[i+1] * y[i] for i in range(n)), GRB.MAXIMIZE)\n",
    "\n",
    "    # Constraints\n",
    "    model.addConstr(y0 + gp.quicksum(y[i] for i in range(n)) == 1, \"probability_sum\")\n",
    "    for i in range(n):\n",
    "        model.addConstr(y[i] <= y0 * exp(mu[i+1]), f\"probability_{i}\")\n",
    "        model.addConstr(y[i] <= z[i], f\"binary_{i}\")\n",
    "    model.addConstr(sum(z[i] for i in range(n)) <= p, \"max_products\")\n",
    "\n",
    "    # Optimize\n",
    "    model.optimize()\n",
    "    \n",
    "    return model\n",
    "    \n",
    "# Solve the APC-MILP for the small instances\n",
    "small_r = instances_small_r\n",
    "small_mu = instances_small_mu\n",
    "\n",
    "n = len(small_r[0]) - 1 # Number of products\n",
    "n_small_instances = len(small_r) # Number of instances\n",
    "p_values = [1, n // 5, n // 2, n] # Number of products to be selected\n",
    "\n",
    "small_instances_runtimes = {instance: {p: None for p in p_values} for instance in range(1,n_small_instances+1)}\n",
    "small_instances_optimal_values = {instance: {p: None for p in p_values} for instance in  range(1,n_small_instances+1)}\n",
    "\n",
    "\n",
    "for i in range(n_small_instances):\n",
    "    print(f\"Small instance n°{i}\")\n",
    "    for p in p_values:\n",
    "        print(f\"p = {p}\")\n",
    "        model = solve_apc_milp(small_r[i], small_mu[i], p, n)\n",
    "        small_instances_runtimes[i+1][p] = model.Runtime\n",
    "        small_instances_optimal_values[i+1][p] = model.ObjVal\n",
    "        \n",
    "print(small_instances_runtimes)\n",
    "print(small_instances_optimal_values)\n",
    "# Solve the APC-MILP for the medium instances\n",
    "medium_r = instances_medium_r\n",
    "medium_mu = instances_medium_mu\n",
    "\n",
    "n = len(medium_r[0]) - 1 # Number of products\n",
    "n_medium_instances = len(medium_r) # Number of instances\n",
    "p_values = [1, n // 5, n // 2, n] # Number of products to be selected\n",
    "\n",
    "medium_instances_runtimes = {instance: {p: None for p in p_values} for instance in range(1,n_medium_instances+1)}\n",
    "medium_instances_optimal_values = {instance: {p: None for p in p_values} for instance in  range(1,n_medium_instances+1)}\n",
    "\n",
    "for i in range(n_medium_instances):\n",
    "    print(f\"Medium instance n°{i+1}\")\n",
    "    for p in p_values:\n",
    "        print(f\"p = {p}\")\n",
    "        model = solve_apc_milp(medium_r[i], medium_mu[i], p, n)\n",
    "        medium_instances_runtimes[i+1][p] = model.Runtime\n",
    "        medium_instances_optimal_values[i+1][p] = model.ObjVal\n",
    "        \n",
    "print(medium_instances_runtimes)\n",
    "print(medium_instances_optimal_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solve the APC-MILP for the large instances\n",
    "# large_r = instances_large_r\n",
    "# large_mu = instances_large_mu\n",
    "\n",
    "# n = len(large_r[0]) - 1 # Number of products\n",
    "# n_large_instances = len(large_r) # Number of instances\n",
    "# p_values = [1, n // 5, n // 2, n] # Number of products to be selected\n",
    "\n",
    "# large_instances_runtimes = {instance: {p: None for p in p_values} for instance in range(1, n_large_instances)}\n",
    "# large_instances_optimal_values = {instance: {p: None for p in p_values} for instance in  range(1, n_large_instances)}\n",
    "\n",
    "# for i in range(n_large_instances):\n",
    "#     print(f\"Large instance n°{i + 1}\")\n",
    "#     for p in p_values:\n",
    "#         print(f\"p = {p}\")\n",
    "#         model = solve_apc_milp(large_r[i], large_mu[i], p, n)\n",
    "#         large_instances_runtimes[i][p] = model.Runtime\n",
    "#         large_instances_optimal_values[i][p] = model.ObjVal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3 We now propose to use a Lagrangean Relaxation framework to (approximately) solve the practical model. Coming back to AP-IP, it is easy to cast yet another version of the practical model:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\text { (APC-IP) } \\max _{x \\in\\{0,1\\}^{n}} & \\frac{r_{0}+\\sum_{i=1}^{n} x_{i} r_{i} e^{\\mu_{i}}}{1+\\sum_{i=1}^{n} x_{i} e^{\\mu_{i}}} \\\\\n",
    "\\text { s.t. } & \\sum_{i=1}^{n} x_{i} \\leqslant p,\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "#### on which we will apply a Lagrangian algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 3.3.1 Pricing: after noticing that the constraint $\\sum_{i=1}^{n} x_{i} \\leqslant p$ is equivalent to\n",
    "\n",
    "$$\n",
    "\\frac{\\sum_{i=1}^{n} x_{i}}{1+\\sum_{i=1}^{n} x_{i} e^{\\mu_{i}}} \\leqslant \\frac{p}{1+\\sum_{i=1}^{n} x_{i} e^{\\mu_{i}}}\n",
    "$$\n",
    "\n",
    "##### prove that the pricing problem with a penalization $\\lambda \\geqslant 0$ can be recast as:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rlr}\n",
    "(\\operatorname{AP}-\\mathrm{L})(\\lambda) \\quad \\omega(\\lambda):=\\max _{y, y_{0} \\geqslant 0} & r_{0}(\\lambda) y_{0}+\\sum_{i=1}^{n} r_{i}(\\lambda) y_{i} & \\\\\n",
    "\\text { s.t. } & y_{0}+\\sum_{i=1}^{n} y_{i}=1 \\\\\n",
    "& y_{i} \\leqslant y_{0} e^{\\mu_{i}} & \\forall i \\in \\mathcal{I}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "##### Specify the values of $r_{0}(\\lambda)$ and $r_{i}(\\lambda)$ in function of $r_{0}, \\lambda, p$, the revenues $r_{j}$ and the utilities $\\mu_{j}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To apply the Lagrangian relaxation, we introduce a penalization term $\\lambda \\geq 0$ for the constraint $\\sum_{i=1}^{n} x_{i} \\leq p$. The Lagrangian function for this problem is:\n",
    "\n",
    "$$\n",
    "\\mathcal{L}(x, \\lambda) = \\frac{r_{0} + \\sum_{i=1}^{n} x_{i} r_{i} e^{\\mu_{i}}}{1 + \\sum_{i=1}^{n} x_{i} e^{\\mu_{i}}} - \\lambda \\left( \\sum_{i=1}^{n} x_{i} - p \\right)\n",
    "$$\n",
    "\n",
    "This penalization can be incorporated into the objective function, leading to a new revenue term for each product.\n",
    "\n",
    "### New Objective Function\n",
    "The new objective function with the penalization term becomes:\n",
    "\n",
    "$$\n",
    "\\omega(\\lambda) = \\max_{x \\in \\{0,1\\}^{n}} \\frac{r_{0} + \\sum_{i=1}^{n} x_{i} (r_{i} e^{\\mu_{i}} - \\lambda)}{1 + \\sum_{i=1}^{n} x_{i} e^{\\mu_{i}}}\n",
    "$$\n",
    "\n",
    "### New Revenues\n",
    "To match this objective with the form given in the problem, we define new revenues $r_{0}(\\lambda)$ and $r_{i}(\\lambda)$ as follows:\n",
    "\n",
    "- For the no-purchase option:\n",
    "\n",
    "$$\n",
    "r_{0}(\\lambda) = r_{0}\n",
    "$$\n",
    "\n",
    "- For each product $i$:\n",
    "\n",
    "$$\n",
    "r_{i}(\\lambda) = r_{i} e^{\\mu_{i}} - \\lambda\n",
    "$$\n",
    "\n",
    "### Reformulated Problem\n",
    "The reformulated problem can then be written as:\n",
    "\n",
    "$$\n",
    "\\begin{array}{rlr}\n",
    "(\\operatorname{AP}-\\mathrm{L})(\\lambda) \\quad \\omega(\\lambda):=\\max _{y, y_{0} \\geqslant 0} & r_{0} y_{0} + \\sum_{i=1}^{n} (r_{i} e^{\\mu_{i}} - \\lambda) y_{i} & \\\\\n",
    "\\text { s.t. } & y_{0} + \\sum_{i=1}^{n} y_{i} = 1 \\\\\n",
    "& y_{i} \\leqslant y_{0} e^{\\mu_{i}} & \\forall i \\in \\mathcal{I}\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "Thus, the values of $r_{0}(\\lambda)$ and $r_{i}(\\lambda)$ are specified as follows:\n",
    "\n",
    "- $r_{0}(\\lambda) = r_{0}$\n",
    "- $r_{i}(\\lambda) = r_{i} e^{\\mu_{i}} - \\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 3.3.2 Recall that we want to find the best dual bound, i.e. solve the following univariate problem:\n",
    "\n",
    "$$\n",
    "\\min _{\\lambda \\geqslant 0} \\omega(\\lambda)\n",
    "$$\n",
    "\n",
    "##### and that the function $\\lambda \\rightarrow \\omega(\\lambda)$ is convex and piecewise linear. Design a binary search to find the optimal $\\lambda^{*}$. Hint: there is an optimal $\\lambda^{*}$ that is no greater than $\\max \\left\\{0, \\frac{r_{1}-r_{0}}{p}\\right\\}$ (why?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To design a binary search to find the optimal $\\lambda^{*}$, we need to exploit the convexity and piecewise linearity of the function $\\lambda \\rightarrow \\omega(\\lambda)$. The hint suggests that the optimal $\\lambda^{*}$ is no greater than $\\max \\left\\{0, \\frac{r_{1}-r_{0}}{p}\\right\\}$. This is because $\\lambda$ effectively reduces the revenue contribution of each product, and the maximum penalization that can still maintain a feasible solution is influenced by the highest revenue product and the no-purchase option.\n",
    "\n",
    "### Binary Search Algorithm\n",
    "\n",
    "1. **Initialization**:\n",
    "   - Set the lower bound of $\\lambda$: $\\lambda_{\\text{low}} = 0$\n",
    "   - Set the upper bound of $\\lambda$: $\\lambda_{\\text{high}} = \\max \\left\\{0, \\frac{r_{1} - r_{0}}{p}\\right\\}$\n",
    "\n",
    "2. **Binary Search**:\n",
    "   - While the difference between $\\lambda_{\\text{high}}$ and $\\lambda_{\\text{low}}$ is greater than a small tolerance (e.g., $\\epsilon = 10^{-6}$):\n",
    "     1. Compute the midpoint: $\\lambda_{\\text{mid}} = \\frac{\\lambda_{\\text{low}} + \\lambda_{\\text{high}}}{2}$\n",
    "     2. Evaluate $\\omega(\\lambda_{\\text{mid}})$ by solving the Lagrangian problem $(\\operatorname{AP}-\\mathrm{L})(\\lambda_{\\text{mid}})$\n",
    "     3. If the derivative of $\\omega(\\lambda)$ at $\\lambda_{\\text{mid}}$ is positive, it means we need a smaller $\\lambda$ to minimize $\\omega(\\lambda)$. Set $\\lambda_{\\text{high}} = \\lambda_{\\text{mid}}$\n",
    "     4. Otherwise, set $\\lambda_{\\text{low}} = \\lambda_{\\text{mid}}$\n",
    "\n",
    "3. **Termination**:\n",
    "   - The optimal $\\lambda^{*}$ is the midpoint when the loop terminates: $\\lambda^{*} = \\frac{\\lambda_{\\text{low}} + \\lambda_{\\text{high}}}{2}$\n",
    "\n",
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTANCE 1 - p = 1\n",
      "INSTANCE 2 - p = 1\n",
      "INSTANCE 3 - p = 1\n",
      "INSTANCE 4 - p = 1\n",
      "INSTANCE 5 - p = 1\n",
      "INSTANCE 6 - p = 1\n",
      "INSTANCE 7 - p = 1\n",
      "INSTANCE 8 - p = 1\n",
      "INSTANCE 9 - p = 1\n",
      "INSTANCE 10 - p = 1\n",
      "INSTANCE 11 - p = 1\n",
      "INSTANCE 12 - p = 1\n",
      "INSTANCE 13 - p = 1\n",
      "INSTANCE 14 - p = 1\n",
      "INSTANCE 15 - p = 1\n",
      "INSTANCE 16 - p = 1\n",
      "INSTANCE 17 - p = 1\n",
      "INSTANCE 18 - p = 1\n",
      "INSTANCE 19 - p = 1\n",
      "INSTANCE 20 - p = 1\n",
      "INSTANCE 21 - p = 1\n",
      "INSTANCE 22 - p = 1\n",
      "INSTANCE 23 - p = 1\n",
      "INSTANCE 24 - p = 1\n",
      "INSTANCE 25 - p = 1\n",
      "INSTANCE 26 - p = 1\n",
      "INSTANCE 27 - p = 1\n",
      "INSTANCE 28 - p = 1\n",
      "INSTANCE 29 - p = 1\n",
      "INSTANCE 30 - p = 1\n",
      "INSTANCE 31 - p = 1\n",
      "INSTANCE 32 - p = 1\n",
      "INSTANCE 33 - p = 1\n",
      "INSTANCE 34 - p = 1\n",
      "INSTANCE 35 - p = 1\n",
      "INSTANCE 36 - p = 1\n",
      "INSTANCE 37 - p = 1\n",
      "INSTANCE 38 - p = 1\n",
      "INSTANCE 39 - p = 1\n",
      "INSTANCE 40 - p = 1\n",
      "INSTANCE 41 - p = 1\n",
      "INSTANCE 42 - p = 1\n",
      "INSTANCE 43 - p = 1\n",
      "INSTANCE 44 - p = 1\n",
      "INSTANCE 45 - p = 1\n",
      "INSTANCE 46 - p = 1\n",
      "INSTANCE 47 - p = 1\n",
      "INSTANCE 48 - p = 1\n",
      "INSTANCE 49 - p = 1\n",
      "INSTANCE 50 - p = 1\n",
      "INSTANCE 51 - p = 1\n",
      "INSTANCE 52 - p = 1\n",
      "INSTANCE 53 - p = 1\n",
      "INSTANCE 54 - p = 1\n",
      "INSTANCE 55 - p = 1\n",
      "INSTANCE 56 - p = 1\n",
      "INSTANCE 57 - p = 1\n",
      "INSTANCE 58 - p = 1\n",
      "INSTANCE 59 - p = 1\n",
      "INSTANCE 60 - p = 1\n",
      "INSTANCE 61 - p = 1\n",
      "INSTANCE 62 - p = 1\n",
      "INSTANCE 63 - p = 1\n",
      "INSTANCE 64 - p = 1\n",
      "INSTANCE 65 - p = 1\n",
      "INSTANCE 66 - p = 1\n",
      "INSTANCE 67 - p = 1\n",
      "INSTANCE 68 - p = 1\n",
      "INSTANCE 69 - p = 1\n",
      "INSTANCE 70 - p = 1\n",
      "INSTANCE 71 - p = 1\n",
      "INSTANCE 72 - p = 1\n",
      "INSTANCE 73 - p = 1\n",
      "INSTANCE 74 - p = 1\n",
      "INSTANCE 75 - p = 1\n",
      "INSTANCE 76 - p = 1\n",
      "INSTANCE 77 - p = 1\n",
      "INSTANCE 78 - p = 1\n",
      "INSTANCE 79 - p = 1\n",
      "INSTANCE 80 - p = 1\n",
      "INSTANCE 81 - p = 1\n",
      "INSTANCE 82 - p = 1\n",
      "INSTANCE 83 - p = 1\n",
      "INSTANCE 84 - p = 1\n",
      "INSTANCE 85 - p = 1\n",
      "INSTANCE 86 - p = 1\n",
      "INSTANCE 87 - p = 1\n",
      "INSTANCE 88 - p = 1\n",
      "INSTANCE 89 - p = 1\n",
      "INSTANCE 90 - p = 1\n",
      "INSTANCE 91 - p = 1\n",
      "INSTANCE 92 - p = 1\n",
      "INSTANCE 93 - p = 1\n",
      "INSTANCE 94 - p = 1\n",
      "INSTANCE 95 - p = 1\n",
      "INSTANCE 96 - p = 1\n",
      "INSTANCE 97 - p = 1\n",
      "INSTANCE 98 - p = 1\n",
      "INSTANCE 99 - p = 1\n",
      "INSTANCE 100 - p = 1\n",
      "INSTANCE 1 - p = 2\n",
      "INSTANCE 2 - p = 2\n",
      "INSTANCE 3 - p = 2\n",
      "INSTANCE 4 - p = 2\n",
      "INSTANCE 5 - p = 2\n",
      "INSTANCE 6 - p = 2\n",
      "INSTANCE 7 - p = 2\n",
      "INSTANCE 8 - p = 2\n",
      "INSTANCE 9 - p = 2\n",
      "INSTANCE 10 - p = 2\n",
      "INSTANCE 11 - p = 2\n",
      "INSTANCE 12 - p = 2\n",
      "INSTANCE 13 - p = 2\n",
      "INSTANCE 14 - p = 2\n",
      "INSTANCE 15 - p = 2\n",
      "INSTANCE 16 - p = 2\n",
      "INSTANCE 17 - p = 2\n",
      "INSTANCE 18 - p = 2\n",
      "INSTANCE 19 - p = 2\n",
      "INSTANCE 20 - p = 2\n",
      "INSTANCE 21 - p = 2\n",
      "INSTANCE 22 - p = 2\n",
      "INSTANCE 23 - p = 2\n",
      "INSTANCE 24 - p = 2\n",
      "INSTANCE 25 - p = 2\n",
      "INSTANCE 26 - p = 2\n",
      "INSTANCE 27 - p = 2\n",
      "INSTANCE 28 - p = 2\n",
      "INSTANCE 29 - p = 2\n",
      "INSTANCE 30 - p = 2\n",
      "INSTANCE 31 - p = 2\n",
      "INSTANCE 32 - p = 2\n",
      "INSTANCE 33 - p = 2\n",
      "INSTANCE 34 - p = 2\n",
      "INSTANCE 35 - p = 2\n",
      "INSTANCE 36 - p = 2\n",
      "INSTANCE 37 - p = 2\n",
      "INSTANCE 38 - p = 2\n",
      "INSTANCE 39 - p = 2\n",
      "INSTANCE 40 - p = 2\n",
      "INSTANCE 41 - p = 2\n",
      "INSTANCE 42 - p = 2\n",
      "INSTANCE 43 - p = 2\n",
      "INSTANCE 44 - p = 2\n",
      "INSTANCE 45 - p = 2\n",
      "INSTANCE 46 - p = 2\n",
      "INSTANCE 47 - p = 2\n",
      "INSTANCE 48 - p = 2\n",
      "INSTANCE 49 - p = 2\n",
      "INSTANCE 50 - p = 2\n",
      "INSTANCE 51 - p = 2\n",
      "INSTANCE 52 - p = 2\n",
      "INSTANCE 53 - p = 2\n",
      "INSTANCE 54 - p = 2\n",
      "INSTANCE 55 - p = 2\n",
      "INSTANCE 56 - p = 2\n",
      "INSTANCE 57 - p = 2\n",
      "INSTANCE 58 - p = 2\n",
      "INSTANCE 59 - p = 2\n",
      "INSTANCE 60 - p = 2\n",
      "INSTANCE 61 - p = 2\n",
      "INSTANCE 62 - p = 2\n",
      "INSTANCE 63 - p = 2\n",
      "INSTANCE 64 - p = 2\n",
      "INSTANCE 65 - p = 2\n",
      "INSTANCE 66 - p = 2\n",
      "INSTANCE 67 - p = 2\n",
      "INSTANCE 68 - p = 2\n",
      "INSTANCE 69 - p = 2\n",
      "INSTANCE 70 - p = 2\n",
      "INSTANCE 71 - p = 2\n",
      "INSTANCE 72 - p = 2\n",
      "INSTANCE 73 - p = 2\n",
      "INSTANCE 74 - p = 2\n",
      "INSTANCE 75 - p = 2\n",
      "INSTANCE 76 - p = 2\n",
      "INSTANCE 77 - p = 2\n",
      "INSTANCE 78 - p = 2\n",
      "INSTANCE 79 - p = 2\n",
      "INSTANCE 80 - p = 2\n",
      "INSTANCE 81 - p = 2\n",
      "INSTANCE 82 - p = 2\n",
      "INSTANCE 83 - p = 2\n",
      "INSTANCE 84 - p = 2\n",
      "INSTANCE 85 - p = 2\n",
      "INSTANCE 86 - p = 2\n",
      "INSTANCE 87 - p = 2\n",
      "INSTANCE 88 - p = 2\n",
      "INSTANCE 89 - p = 2\n",
      "INSTANCE 90 - p = 2\n",
      "INSTANCE 91 - p = 2\n",
      "INSTANCE 92 - p = 2\n",
      "INSTANCE 93 - p = 2\n",
      "INSTANCE 94 - p = 2\n",
      "INSTANCE 95 - p = 2\n",
      "INSTANCE 96 - p = 2\n",
      "INSTANCE 97 - p = 2\n",
      "INSTANCE 98 - p = 2\n",
      "INSTANCE 99 - p = 2\n",
      "INSTANCE 100 - p = 2\n",
      "INSTANCE 1 - p = 5\n",
      "INSTANCE 2 - p = 5\n",
      "INSTANCE 3 - p = 5\n",
      "INSTANCE 4 - p = 5\n",
      "INSTANCE 5 - p = 5\n",
      "INSTANCE 6 - p = 5\n",
      "INSTANCE 7 - p = 5\n",
      "INSTANCE 8 - p = 5\n",
      "INSTANCE 9 - p = 5\n",
      "INSTANCE 10 - p = 5\n",
      "INSTANCE 11 - p = 5\n",
      "INSTANCE 12 - p = 5\n",
      "INSTANCE 13 - p = 5\n",
      "INSTANCE 14 - p = 5\n",
      "INSTANCE 15 - p = 5\n",
      "INSTANCE 16 - p = 5\n",
      "INSTANCE 17 - p = 5\n",
      "INSTANCE 18 - p = 5\n",
      "INSTANCE 19 - p = 5\n",
      "INSTANCE 20 - p = 5\n",
      "INSTANCE 21 - p = 5\n",
      "INSTANCE 22 - p = 5\n",
      "INSTANCE 23 - p = 5\n",
      "INSTANCE 24 - p = 5\n",
      "INSTANCE 25 - p = 5\n",
      "INSTANCE 26 - p = 5\n",
      "INSTANCE 27 - p = 5\n",
      "INSTANCE 28 - p = 5\n",
      "INSTANCE 29 - p = 5\n",
      "INSTANCE 30 - p = 5\n",
      "INSTANCE 31 - p = 5\n",
      "INSTANCE 32 - p = 5\n",
      "INSTANCE 33 - p = 5\n",
      "INSTANCE 34 - p = 5\n",
      "INSTANCE 35 - p = 5\n",
      "INSTANCE 36 - p = 5\n",
      "INSTANCE 37 - p = 5\n",
      "INSTANCE 38 - p = 5\n",
      "INSTANCE 39 - p = 5\n",
      "INSTANCE 40 - p = 5\n",
      "INSTANCE 41 - p = 5\n",
      "INSTANCE 42 - p = 5\n",
      "INSTANCE 43 - p = 5\n",
      "INSTANCE 44 - p = 5\n",
      "INSTANCE 45 - p = 5\n",
      "INSTANCE 46 - p = 5\n",
      "INSTANCE 47 - p = 5\n",
      "INSTANCE 48 - p = 5\n",
      "INSTANCE 49 - p = 5\n",
      "INSTANCE 50 - p = 5\n",
      "INSTANCE 51 - p = 5\n",
      "INSTANCE 52 - p = 5\n",
      "INSTANCE 53 - p = 5\n",
      "INSTANCE 54 - p = 5\n",
      "INSTANCE 55 - p = 5\n",
      "INSTANCE 56 - p = 5\n",
      "INSTANCE 57 - p = 5\n",
      "INSTANCE 58 - p = 5\n",
      "INSTANCE 59 - p = 5\n",
      "INSTANCE 60 - p = 5\n",
      "INSTANCE 61 - p = 5\n",
      "INSTANCE 62 - p = 5\n",
      "INSTANCE 63 - p = 5\n",
      "INSTANCE 64 - p = 5\n",
      "INSTANCE 65 - p = 5\n",
      "INSTANCE 66 - p = 5\n",
      "INSTANCE 67 - p = 5\n",
      "INSTANCE 68 - p = 5\n",
      "INSTANCE 69 - p = 5\n",
      "INSTANCE 70 - p = 5\n",
      "INSTANCE 71 - p = 5\n",
      "INSTANCE 72 - p = 5\n",
      "INSTANCE 73 - p = 5\n",
      "INSTANCE 74 - p = 5\n",
      "INSTANCE 75 - p = 5\n",
      "INSTANCE 76 - p = 5\n",
      "INSTANCE 77 - p = 5\n",
      "INSTANCE 78 - p = 5\n",
      "INSTANCE 79 - p = 5\n",
      "INSTANCE 80 - p = 5\n",
      "INSTANCE 81 - p = 5\n",
      "INSTANCE 82 - p = 5\n",
      "INSTANCE 83 - p = 5\n",
      "INSTANCE 84 - p = 5\n",
      "INSTANCE 85 - p = 5\n",
      "INSTANCE 86 - p = 5\n",
      "INSTANCE 87 - p = 5\n",
      "INSTANCE 88 - p = 5\n",
      "INSTANCE 89 - p = 5\n",
      "INSTANCE 90 - p = 5\n",
      "INSTANCE 91 - p = 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(small_r)):\n\u001b[0;32m     55\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mINSTANCE \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m - p = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 56\u001b[0m     lambda_star,runtime \u001b[38;5;241m=\u001b[39m \u001b[43mfind_optimal_lambda\u001b[49m\u001b[43m(\u001b[49m\u001b[43msmall_r\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43msmall_mu\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     57\u001b[0m     small_instances_runtimes[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m][p] \u001b[38;5;241m=\u001b[39m runtime\n\u001b[0;32m     58\u001b[0m     small_instances_lambda[i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m][p] \u001b[38;5;241m=\u001b[39m lambda_star\n",
      "Cell \u001b[1;32mIn[46], line 32\u001b[0m, in \u001b[0;36mfind_optimal_lambda\u001b[1;34m(r, mu, p)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m lambda_high \u001b[38;5;241m-\u001b[39m lambda_low \u001b[38;5;241m>\u001b[39m epsilon:\n\u001b[0;32m     31\u001b[0m     lambda_mid \u001b[38;5;241m=\u001b[39m (lambda_low \u001b[38;5;241m+\u001b[39m lambda_high) \u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m\n\u001b[1;32m---> 32\u001b[0m     mod \u001b[38;5;241m=\u001b[39m \u001b[43msolve_lagrangian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlambda_mid\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     obj_val_mid \u001b[38;5;241m=\u001b[39m mod\u001b[38;5;241m.\u001b[39mObjVal\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# We evaluate the function value at lambda_mid + epsilon to determine the direction of the search\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[46], line 21\u001b[0m, in \u001b[0;36msolve_lagrangian\u001b[1;34m(r, mu, lambda_val)\u001b[0m\n\u001b[0;32m     18\u001b[0m     model\u001b[38;5;241m.\u001b[39maddConstr(y[i] \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m y0 \u001b[38;5;241m*\u001b[39m exp(mu[i \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m]), \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprobability_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Optimize\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from gurobipy import Model, GRB\n",
    "from math import exp\n",
    "\n",
    "def solve_lagrangian(r, mu, lambda_val, n):\n",
    "    model = Model(\"Lagrangian\")\n",
    "    model.setParam('OutputFlag', 0)\n",
    "\n",
    "    # Variables\n",
    "    y0 = model.addVar(vtype=GRB.CONTINUOUS, name=\"y0\")\n",
    "    y = model.addVars(vtype=GRB.CONTINUOUS, name=\"y\")\n",
    "\n",
    "    # Objective function\n",
    "    model.setObjective(r[0] * y0 + sum((r[i + 1] * exp(mu[i + 1]) - lambda_val) * y[i] for i in range(n)), GRB.MAXIMIZE)\n",
    "\n",
    "    # Constraints\n",
    "    model.addConstr(y0 + sum(y[i] for i in range(len(y))) == 1, \"probability_sum\")\n",
    "    for i in range(len(y)):\n",
    "        model.addConstr(y[i] <= y0 * exp(mu[i + 1]), f\"probability_{i}\")\n",
    "\n",
    "    # Optimize\n",
    "    model.optimize()\n",
    "\n",
    "    return model\n",
    "\n",
    "def find_optimal_lambda(r, mu, p, n):\n",
    "    lambda_low = 0\n",
    "    lambda_high = max(0, (r[1] - r[0]) / p)\n",
    "    epsilon = 1e-6\n",
    "\n",
    "    while lambda_high - lambda_low > epsilon:\n",
    "        lambda_mid = (lambda_low + lambda_high) / 2\n",
    "        mod = solve_lagrangian(r, mu, lambda_mid, n)\n",
    "        obj_val_mid = mod.ObjVal\n",
    "\n",
    "        # We evaluate the function value at lambda_mid + epsilon to determine the direction of the search\n",
    "        if obj_val_mid < (solve_lagrangian(r, mu, lambda_mid + epsilon, n).ObjVal):\n",
    "            lambda_high = lambda_mid\n",
    "        else:\n",
    "            lambda_low = lambda_mid\n",
    "\n",
    "    return (lambda_low + lambda_high) / 2, mod.Runtime\n",
    "\n",
    "# Small instances\n",
    "small_r = instances_small_r\n",
    "small_mu = instances_small_mu\n",
    "n = len(small_r[0]) -1  # number of products\n",
    "n_small_instances = len(small_r) # Number of instances\n",
    "p_values = [1, n // 5, n // 2, n]\n",
    "\n",
    "small_instances_runtimes = {instance: {p: None for p in p_values} for instance in range(1,n_small_instances+1)}\n",
    "small_instances_lambda = {instance: {p: None for p in p_values} for instance in  range(1,n_small_instances+1)}\n",
    "\n",
    "for p in p_values:\n",
    "    for i in range(len(small_r)):\n",
    "        print(f\"INSTANCE {i+1} - p = {p}\")\n",
    "        lambda_star,runtime = find_optimal_lambda(small_r[i],small_mu[i], p, n)\n",
    "        small_instances_runtimes[i+1][p] = runtime\n",
    "        small_instances_lambda[i+1][p] = lambda_star\n",
    "        \n",
    "print(small_instances_runtimes)\n",
    "print(small_instances_lambda)\n",
    "\n",
    "# medium instances\n",
    "medium_r = instances_medium_r\n",
    "medium_mu = instances_medium_mu\n",
    "n = len(medium_r[0]) -1  # number of products\n",
    "n_medium_instances = len(medium_r) # Number of instances\n",
    "p_values = [1, n // 5, n // 2, n]\n",
    "\n",
    "medium_instances_runtimes = {instance: {p: None for p in p_values} for instance in range(1,n_medium_instances+1)}\n",
    "medium_instances_lambda = {instance: {p: None for p in p_values} for instance in  range(1,n_medium_instances+1)}\n",
    "\n",
    "for p in p_values:\n",
    "    for i in range(len(small_r)):\n",
    "        print(f\"INSTANCE {i+1} - p = {p}\")\n",
    "        lambda_star,runtime = find_optimal_lambda(medium_r[i], medium_mu[i], p, n)\n",
    "        medium_instances_runtimes[i+1][p] = runtime\n",
    "        medium_instances_lambda[i+1][p] = lambda_star\n",
    "\n",
    "print(medium_instances_runtimes)\n",
    "print(medium_instances_lambda)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 3.3.2 Heuristic: whenever some $\\lambda$ provides a feasible solution for our practical problem, we compare it with the best solution so far and keep the best one."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the context of using Lagrangian relaxation, we can employ a heuristic to improve our practical solution iteratively. Whenever a specific value of $\\lambda$ yields a feasible solution for the practical problem, we compare this solution with the best one obtained so far and retain the better one. Here’s how this can be implemented:\n",
    "\n",
    "### Heuristic Algorithm\n",
    "\n",
    "1. **Initialize**:\n",
    "   - Set the best objective value: `best_obj_val = -inf`\n",
    "   - Set the best solution: `best_solution = None`\n",
    "\n",
    "2. **Binary Search with Heuristic**:\n",
    "   - While performing the binary search to find the optimal $\\lambda$, keep track of feasible solutions.\n",
    "\n",
    "3. **Evaluation**:\n",
    "   - After solving the Lagrangian problem $(\\operatorname{AP}-\\mathrm{L})(\\lambda_{\\text{mid}})$, check if the solution is feasible for the original practical problem.\n",
    "   - If feasible, compare the objective value with the best one obtained so far.\n",
    "   - Update `best_obj_val` and `best_solution` if the current solution is better.\n",
    "\n",
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSTANCE 1 - p = 1\n",
      "lambda = 0.4553534309526569\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.6830301464289854\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7968685041671496\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8537876830362316\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8822472724707727\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8964770671880433\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9035919645466786\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9071494132259962\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.908928137565655\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9098174997354844\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9102621808203991\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9104845213628565\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9105956916340852\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9106512767696995\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9106790693375066\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9106929656214102\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.910699913763362\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9107033878343379\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9107051248698259\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9107059933875699\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 2 - p = 1\n",
      "lambda = 0.40635838571974753\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.6095375785796213\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7111271750095582\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7619219732245266\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7873193723320109\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.800018071885753\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.806367421662624\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8095420965510596\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8111294339952773\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8119231027173861\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8123199370784406\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8125183542589678\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8126175628492314\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8126671671443633\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8126919692919292\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8127043703657122\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8127105709026037\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8127136711710494\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8127152213052722\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8127159963723836\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 3 - p = 1\n",
      "lambda = 0.3875255787914747\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.5812883681872121\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.6781697628850807\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7266104602340151\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7508308089084823\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7629409832457159\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7689960704143326\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.772023613998641\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7735373857907952\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7742942716868724\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7746727146349108\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7748619361089302\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7749565468459398\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7750038522144447\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.775027504898697\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7750393312408232\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7750452444118863\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7750482009974178\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7750496792901835\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7750504184365665\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 4 - p = 1\n",
      "lambda = 0.47488223472022895\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7123233520803434\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8310439107604006\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8904041901004293\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9200843297704435\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9349243996054507\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9423444345229544\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9460544519817061\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9479094607110821\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.94883696507577\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9493007172581139\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.949532593349286\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9496485313948719\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9497065004176649\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9497354849290613\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9497499771847596\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9497572233126088\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9497608463765334\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9497626579084957\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9497635636744768\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 5 - p = 1\n",
      "lambda = 0.4618877151344487\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.6928315727016731\n",
      "y0 = 0.27316135602471475\n",
      "y = [0.0, 0.0, 0.7268386439752852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8083035014852853\n",
      "y0 = 0.27316135602471475\n",
      "y = [0.0, 0.0, 0.7268386439752852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8660394658770914\n",
      "y0 = 0.27316135602471475\n",
      "y = [0.0, 0.0, 0.7268386439752852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8949074480729944\n",
      "y0 = 0.27316135602471475\n",
      "y = [0.0, 0.0, 0.7268386439752852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9093414391709459\n",
      "y0 = 0.27316135602471475\n",
      "y = [0.0, 0.0, 0.7268386439752852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9165584347199216\n",
      "y0 = 0.27316135602471475\n",
      "y = [0.0, 0.0, 0.7268386439752852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9201669324944095\n",
      "y0 = 0.27316135602471475\n",
      "y = [0.0, 0.0, 0.7268386439752852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9219711813816535\n",
      "y0 = 0.27316135602471475\n",
      "y = [0.0, 0.0, 0.7268386439752852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9228733058252754\n",
      "y0 = 0.27316135602471475\n",
      "y = [0.0, 0.0, 0.7268386439752852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9233243680470864\n",
      "y0 = 0.27316135602471475\n",
      "y = [0.0, 0.0, 0.7268386439752852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9235498991579919\n",
      "y0 = 0.27316135602471475\n",
      "y = [0.0, 0.0, 0.7268386439752852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9236626647134447\n",
      "y0 = 0.27316135602471475\n",
      "y = [0.0, 0.0, 0.7268386439752852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9237190474911711\n",
      "y0 = 0.27316135602471475\n",
      "y = [0.0, 0.0, 0.7268386439752852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9237472388800343\n",
      "y0 = 0.27316135602471475\n",
      "y = [0.0, 0.0, 0.7268386439752852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9237613345744659\n",
      "y0 = 0.27316135602471475\n",
      "y = [0.0, 0.0, 0.7268386439752852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9237683824216816\n",
      "y0 = 0.27316135602471475\n",
      "y = [0.0, 0.0, 0.7268386439752852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9237719063452895\n",
      "y0 = 0.27316135602471475\n",
      "y = [0.0, 0.0, 0.7268386439752852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9237736683070934\n",
      "y0 = 0.27316135602471475\n",
      "y = [0.0, 0.0, 0.7268386439752852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9237745492879954\n",
      "y0 = 0.27316135602471475\n",
      "y = [0.0, 0.0, 0.7268386439752852, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 6 - p = 1\n",
      "lambda = 0.4293663793834116\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.6440495690751173\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7513911639209703\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8050619613438967\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.83189736005536\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8453150594110916\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8520239090889574\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8553783339278903\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8570555463473568\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.85789415255709\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8583134556619566\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.85852310721439\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8586279329906066\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8586803458787149\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.858706552322769\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8587196555447961\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8587262071558097\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8587294829613165\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8587311208640698\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8587319398154465\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 7 - p = 1\n",
      "lambda = 0.4572866731407624\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.6859300097111436\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8002516779963342\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8574125121389296\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8859929292102271\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.900283137745876\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9074282420137003\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9110007941476126\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9127870702145686\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9136802082480466\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9141267772647856\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9143500617731553\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.91446170402734\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9145175251544324\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9145454357179785\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9145593909997516\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9145663686406382\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9145698574610814\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.914571601871303\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.9145724740764138\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 8 - p = 1\n",
      "lambda = 0.4357673141505831\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.6536509712258747\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7625927997635205\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8170637140323433\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8442991711667548\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8579168997339606\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8647257640175634\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8681301961593648\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8698324122302655\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8706835202657159\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8711090742834411\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8713218512923037\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.871428239796735\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8714814340489506\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8715080311750585\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8715213297381124\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8715279790196393\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8715313036604028\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8715329659807844\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8715337971409753\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 9 - p = 1\n",
      "lambda = 0.43460056416631954\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.6519008462494793\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.7605509872910592\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8148760578118491\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.842038593072244\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8556198607024416\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8624104945175404\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8658058114250897\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8675034698788644\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8683522991057517\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8687767137191954\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8689889210259172\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8690950246792781\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8691480765059586\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8691746024192988\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8691878653759689\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8691944968543039\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8691978125934715\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8691994704630552\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.8692002993978472\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 1 - p = 2\n",
      "lambda = 0.22767671547632845\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.3415150732144927\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.3984342520835748\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4268938415181158\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.44112363623538636\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.44823853359402166\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4517959822733393\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4535747066129981\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4544640687828275\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4549087498677422\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.45513109041019956\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.45524226068142826\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4552978458170426\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.45532563838484974\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4553395346687533\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4553464828107051\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.455349956881681\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.45535169391716895\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.45535256243491296\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 2 - p = 2\n",
      "lambda = 0.20317919285987376\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.30476878928981066\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.3555635875047791\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.3809609866122633\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.39365968616600544\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4000090359428765\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.403183710831312\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4047710482755298\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.40556471699763863\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.40596155135869305\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4061599685392203\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4062591771294839\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4063087814246157\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.40633358357218163\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4063459846459646\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4063521851828561\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.40635528545130184\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4063568355855247\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4063576106526361\n",
      "y0 = 0.2788665636799182\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 3 - p = 2\n",
      "lambda = 0.19376278939573735\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.29064418409360604\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.33908488144254034\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.36330523011700755\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.37541540445424115\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.38147049162285795\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.3844980352071663\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.3860118069993205\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.3867686928953976\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.3871471358434362\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.3873363573174554\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.3874309680544651\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.3874782734229699\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.38750192610722234\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.3875137524493485\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.3875196656204116\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.38752262220594313\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.3875241004987089\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.38752483964509177\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 4 - p = 2\n",
      "lambda = 0.23744111736011447\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.3561616760401717\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4155219553802003\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.44520209505021463\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.46004216488522176\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.46746219980272535\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4711722172614772\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.47302722599085306\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.47395473035554103\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.474418482537885\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.47465035862905697\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.474766296674643\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.47482426569743597\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.47485325020883246\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4748677424645307\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4748749885923798\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4748786116563044\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4748804231882667\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.47488132895424784\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 5 - p = 2\n",
      "lambda = 0.23094385756722435\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.34641578635083653\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.40415175074264265\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4330197329385457\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4474537240364972\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.45467071958547295\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4582792173599608\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.46008346624720475\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.46098559069082673\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4614366529126377\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4616621840235432\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.46177494957899595\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.46183133235672236\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.46185952374558553\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.46187361944001715\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4618806672872329\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4618841912108408\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.46188595317264475\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4618868341535467\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 6 - p = 2\n",
      "lambda = 0.2146831896917058\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.3220247845375587\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.37569558196048514\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.40253098067194837\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.41594868002768\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4226575297055458\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4260119545444787\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.42768916696394516\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4285277731736784\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.428947076278545\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4291567278309783\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.429261553607195\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4293139664953033\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.42934017293935745\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4293532761613845\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.42935982777239806\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.42936310357790486\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.42936474148065823\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4293655604320349\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 7 - p = 2\n",
      "lambda = 0.2286433365703812\n",
      "y0 = 0.21112112453439222\n",
      "y = [0.31993748786276893, 0.46894138760283877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.3429650048555718\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4001258389981671\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4287062560694648\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.44299646460511355\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.450141568872938\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.45371412100685016\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4555003970738063\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4563935351072843\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4568401041240233\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4570633886323928\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4571750308865776\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.45723085201367\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4572587625772162\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.45727271785898926\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4572796954998758\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4572831843203191\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4572849287305407\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4572858009356515\n",
      "y0 = 0.3104437029926886\n",
      "y = [0.0, 0.6895562970073115, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 8 - p = 2\n",
      "lambda = 0.21788365707529156\n",
      "y0 = 0.2640925201028788\n",
      "y = [0.2924012107919587, 0.44350626910516244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.32682548561293734\n",
      "y0 = 0.2640925201028788\n",
      "y = [0.2924012107919587, 0.44350626910516244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.38129639988176023\n",
      "y0 = 0.2640925201028788\n",
      "y = [0.2924012107919587, 0.44350626910516244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4085318570161717\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4221495855833774\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4289584498669803\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4323628820087817\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4340650980796824\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.43491620611513276\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.43534176013285797\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.43555453714172054\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.43566092564615183\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4357141198983675\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4357407170244753\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.43575401558752924\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4357606648690562\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.43576398950981965\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4357656518302014\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4357664829903922\n",
      "y0 = 0.3732235330680207\n",
      "y = [0.0, 0.6267764669319792, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 9 - p = 2\n",
      "lambda = 0.21730028208315977\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.32595042312473965\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.3802754936455296\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.40743802890592457\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.421019296536122\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4278099303512208\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4312052472587702\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.43290290571254486\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4337517349394322\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.43417614955287587\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4343883568595977\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4344944605129586\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.43454751233963906\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4345740382529793\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4345873012096494\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.43459393268798446\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.43459724842715197\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.43459890629673575\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.4345997352315276\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 1 - p = 5\n",
      "lambda = 0.09107068619053138\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.13660602928579707\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.15937370083342992\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17075753660724635\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17644945449415456\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17929541343760866\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18071839290933572\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18142988264519924\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.181785627513131\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18196349994709687\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18205243616407982\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1820969042725713\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18211913832681703\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1821302553539399\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18213581386750133\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18213859312428204\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1821399827526724\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18214067756686758\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 2 - p = 5\n",
      "lambda = 0.0812716771439495\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.12190751571592426\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.14222543500191165\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.15238439464490533\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.15746387446640217\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1600036143771506\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1612734843325248\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1619084193102119\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.16222588679905547\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.16238462054347724\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.16246398741568813\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.16250367085179357\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1625235125698463\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.16253343342887266\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.16253839385838584\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.16254087407314244\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.16254211418052072\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.16254273423420987\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 3 - p = 5\n",
      "lambda = 0.07750511575829494\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.11625767363744241\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.13563395257701616\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.14532209204680302\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.15016616178169645\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.15258819664914317\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1537992140828665\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1544047227997282\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.15470747715815902\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.15485885433737445\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.15493454292698217\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.15497238722178602\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.15499130936918795\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1550007704428889\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1550055009797394\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.15500786624816465\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.15500904888237726\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.15500964019948357\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 4 - p = 5\n",
      "lambda = 0.09497644694404579\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1424646704160687\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.16620878215208013\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17808083802008584\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18401686595408873\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18698487992109014\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18846888690459085\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1892108903963412\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18958189214221638\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.189767393015154\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18986014345162278\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1899065186698572\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18992970627897438\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.189941300083533\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1899470969858123\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18994999543695196\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18995144466252178\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18995216927530667\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 5 - p = 5\n",
      "lambda = 0.09237754302688975\n",
      "y0 = 0.17752121970046944\n",
      "y = [0.35012323015262864, 0.0, 0.47235555014690195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.13856631454033463\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.16166070029705706\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1732078931754183\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1789814896145989\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18186828783418918\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18331168694398434\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1840333864988819\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1843942362763307\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1845746611650551\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1846648736094173\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1847099798315984\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18473253294268893\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1847438094982342\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18474944777600685\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18475226691489316\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18475367648433633\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1847543812690579\n",
      "y0 = 0.1775212197004694\n",
      "y = [0.3501232301526286, 0.0, 0.472355550146902, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 6 - p = 5\n",
      "lambda = 0.08587327587668232\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1288099138150235\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.15027823278419405\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.16101239226877934\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.166379472011072\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.16906301188221834\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1704047818177915\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17107566678557806\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17141110926947134\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17157883051141798\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1716626911323913\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17170462144287796\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17172558659812132\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17173606917574297\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17174131046455382\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17174393110895925\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17174524143116193\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1717458965922633\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 7 - p = 5\n",
      "lambda = 0.09145733462815248\n",
      "y0 = 0.1357709475203246\n",
      "y = [0.2057502107863407, 0.3015738792920337, 0.0, 0.0, 0.0, 0.0, 0.356904962401301, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1371860019422287\n",
      "y0 = 0.1357709475203246\n",
      "y = [0.2057502107863407, 0.3015738792920337, 0.0, 0.0, 0.0, 0.0, 0.356904962401301, 0.0, 0.0, 0.0]\n",
      "lambda = 0.16005033559926685\n",
      "y0 = 0.1357709475203246\n",
      "y = [0.2057502107863407, 0.3015738792920337, 0.0, 0.0, 0.0, 0.0, 0.356904962401301, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1714825024277859\n",
      "y0 = 0.21112112453439222\n",
      "y = [0.31993748786276893, 0.46894138760283877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17719858584204543\n",
      "y0 = 0.21112112453439222\n",
      "y = [0.31993748786276893, 0.46894138760283877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18005662754917517\n",
      "y0 = 0.21112112453439222\n",
      "y = [0.31993748786276893, 0.46894138760283877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18148564840274006\n",
      "y0 = 0.21112112453439222\n",
      "y = [0.31993748786276893, 0.46894138760283877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1822001588295225\n",
      "y0 = 0.21112112453439222\n",
      "y = [0.31993748786276893, 0.46894138760283877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18255741404291373\n",
      "y0 = 0.21112112453439222\n",
      "y = [0.31993748786276893, 0.46894138760283877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18273604164960933\n",
      "y0 = 0.21112112453439222\n",
      "y = [0.31993748786276893, 0.46894138760283877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18282535545295714\n",
      "y0 = 0.21112112453439222\n",
      "y = [0.31993748786276893, 0.46894138760283877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18287001235463105\n",
      "y0 = 0.21112112453439222\n",
      "y = [0.31993748786276893, 0.46894138760283877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.182892340805468\n",
      "y0 = 0.21112112453439222\n",
      "y = [0.31993748786276893, 0.46894138760283877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18290350503088648\n",
      "y0 = 0.21112112453439222\n",
      "y = [0.31993748786276893, 0.46894138760283877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18290908714359572\n",
      "y0 = 0.21112112453439222\n",
      "y = [0.31993748786276893, 0.46894138760283877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18291187819995033\n",
      "y0 = 0.21112112453439222\n",
      "y = [0.31993748786276893, 0.46894138760283877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.18291327372812766\n",
      "y0 = 0.21112112453439222\n",
      "y = [0.31993748786276893, 0.46894138760283877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1829139714922163\n",
      "y0 = 0.21112112453439222\n",
      "y = [0.31993748786276893, 0.46894138760283877, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 8 - p = 5\n",
      "lambda = 0.08715346283011663\n",
      "y0 = 0.19108592552799392\n",
      "y = [0.21156886975792244, 0.32090195464988364, 0.0, 0.27644325006420006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.13073019424517496\n",
      "y0 = 0.19108592552799392\n",
      "y = [0.21156886975792244, 0.32090195464988364, 0.0, 0.27644325006420006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1525185599527041\n",
      "y0 = 0.2640925201028788\n",
      "y = [0.2924012107919587, 0.44350626910516244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.16341274280646867\n",
      "y0 = 0.2640925201028788\n",
      "y = [0.2924012107919587, 0.44350626910516244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.16885983423335096\n",
      "y0 = 0.2640925201028788\n",
      "y = [0.2924012107919587, 0.44350626910516244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17158337994679213\n",
      "y0 = 0.2640925201028788\n",
      "y = [0.2924012107919587, 0.44350626910516244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1729451528035127\n",
      "y0 = 0.2640925201028788\n",
      "y = [0.2924012107919587, 0.44350626910516244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17362603923187298\n",
      "y0 = 0.2640925201028788\n",
      "y = [0.2924012107919587, 0.44350626910516244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17396648244605312\n",
      "y0 = 0.2640925201028788\n",
      "y = [0.2924012107919587, 0.44350626910516244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1741367040531432\n",
      "y0 = 0.2640925201028788\n",
      "y = [0.2924012107919587, 0.44350626910516244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17422181485668822\n",
      "y0 = 0.2640925201028788\n",
      "y = [0.2924012107919587, 0.44350626910516244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17426437025846075\n",
      "y0 = 0.2640925201028788\n",
      "y = [0.2924012107919587, 0.44350626910516244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.174285647959347\n",
      "y0 = 0.2640925201028788\n",
      "y = [0.2924012107919587, 0.44350626910516244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17429628680979015\n",
      "y0 = 0.2640925201028788\n",
      "y = [0.2924012107919587, 0.44350626910516244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1743016062350117\n",
      "y0 = 0.2640925201028788\n",
      "y = [0.2924012107919587, 0.44350626910516244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1743042659476225\n",
      "y0 = 0.2640925201028788\n",
      "y = [0.2924012107919587, 0.44350626910516244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17430559580392788\n",
      "y0 = 0.2640925201028788\n",
      "y = [0.2924012107919587, 0.44350626910516244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17430626073208055\n",
      "y0 = 0.2640925201028788\n",
      "y = [0.2924012107919587, 0.44350626910516244, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 9 - p = 5\n",
      "lambda = 0.08692011283326391\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.13038016924989587\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.15211019745821186\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.16297521156236983\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1684077186144488\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1711239721404883\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17248209890350807\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17316116228501793\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1735006939757729\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17367045982115037\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17375534274383908\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17379778420518344\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17381900493585561\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17382961530119173\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1738349204838598\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17383757307519382\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.17383889937086083\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.1738395625186943\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 1 - p = 10\n",
      "lambda = 0.04553534309526569\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.06830301464289854\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.07968685041671496\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08537876830362318\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08822472724707728\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08964770671880433\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09035919645466786\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09071494132259962\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.0908928137565655\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09098174997354844\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09102621808203991\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09104845213628565\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09105956916340852\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09106512767696995\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09106790693375066\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09106929656214102\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.0910699913763362\n",
      "y0 = 0.2689436633258639\n",
      "y = [0.731056336674136, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 2 - p = 10\n",
      "lambda = 0.04063583857197475\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.06095375785796213\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.07111271750095582\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.07619219732245266\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.07873193723320109\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.0800018071885753\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.0806367421662624\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08095420965510595\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08111294339952774\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08119231027173862\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08123199370784406\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08125183542589678\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08126175628492315\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08126671671443633\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08126919692919292\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08127043703657122\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08127105709026036\n",
      "y0 = 0.27886656367991813\n",
      "y = [0.7211334363200819, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 3 - p = 10\n",
      "lambda = 0.03875255787914747\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.058128836818721205\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.06781697628850808\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.07266104602340151\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.07508308089084823\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.07629409832457158\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.07689960704143325\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.0772023613998641\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.07735373857907951\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.07742942716868723\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.07746727146349108\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.07748619361089301\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.07749565468459398\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.07750038522144445\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.0775027504898697\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.07750393312408232\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.07750452444118863\n",
      "y0 = 0.3546097292098349\n",
      "y = [0.645390270790165, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 4 - p = 10\n",
      "lambda = 0.047488223472022896\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.07123233520803435\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08310439107604006\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08904041901004292\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09200843297704436\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09349243996054507\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09423444345229542\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.0946054451981706\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09479094607110819\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.094883696507577\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09493007172581139\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.0949532593349286\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09496485313948719\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.0949706500417665\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09497354849290615\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09497499771847598\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09497572233126089\n",
      "y0 = 0.19749189352063737\n",
      "y = [0.3695642029885961, 0.0, 0.43294390349076645, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 5 - p = 10\n",
      "lambda = 0.04618877151344487\n",
      "y0 = 0.17752121970046944\n",
      "y = [0.35012323015262864, 0.0, 0.47235555014690195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.06928315727016732\n",
      "y0 = 0.17752121970046944\n",
      "y = [0.35012323015262864, 0.0, 0.47235555014690195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08083035014852853\n",
      "y0 = 0.17752121970046944\n",
      "y = [0.35012323015262864, 0.0, 0.47235555014690195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08660394658770915\n",
      "y0 = 0.17752121970046944\n",
      "y = [0.35012323015262864, 0.0, 0.47235555014690195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08949074480729945\n",
      "y0 = 0.17752121970046944\n",
      "y = [0.35012323015262864, 0.0, 0.47235555014690195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09093414391709459\n",
      "y0 = 0.17752121970046944\n",
      "y = [0.35012323015262864, 0.0, 0.47235555014690195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09165584347199217\n",
      "y0 = 0.17752121970046944\n",
      "y = [0.35012323015262864, 0.0, 0.47235555014690195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09201669324944095\n",
      "y0 = 0.17752121970046944\n",
      "y = [0.35012323015262864, 0.0, 0.47235555014690195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09219711813816535\n",
      "y0 = 0.17752121970046944\n",
      "y = [0.35012323015262864, 0.0, 0.47235555014690195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09228733058252755\n",
      "y0 = 0.17752121970046944\n",
      "y = [0.35012323015262864, 0.0, 0.47235555014690195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09233243680470865\n",
      "y0 = 0.17752121970046944\n",
      "y = [0.35012323015262864, 0.0, 0.47235555014690195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.0923549899157992\n",
      "y0 = 0.17752121970046944\n",
      "y = [0.35012323015262864, 0.0, 0.47235555014690195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09236626647134447\n",
      "y0 = 0.17752121970046944\n",
      "y = [0.35012323015262864, 0.0, 0.47235555014690195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.0923719047491171\n",
      "y0 = 0.17752121970046944\n",
      "y = [0.35012323015262864, 0.0, 0.47235555014690195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09237472388800343\n",
      "y0 = 0.17752121970046944\n",
      "y = [0.35012323015262864, 0.0, 0.47235555014690195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09237613345744658\n",
      "y0 = 0.17752121970046944\n",
      "y = [0.35012323015262864, 0.0, 0.47235555014690195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09237683824216816\n",
      "y0 = 0.17752121970046944\n",
      "y = [0.35012323015262864, 0.0, 0.47235555014690195, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 6 - p = 10\n",
      "lambda = 0.04293663793834116\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.06440495690751175\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.07513911639209703\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08050619613438967\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.083189736005536\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08453150594110917\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08520239090889575\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08553783339278903\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08570555463473567\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08578941525570899\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08583134556619565\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08585231072143898\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08586279329906066\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08586803458787148\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08587065523227691\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08587196555447962\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08587262071558097\n",
      "y0 = 0.28181727791448996\n",
      "y = [0.71818272208551, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 7 - p = 10\n",
      "lambda = 0.04572866731407624\n",
      "y0 = 0.10741976999902214\n",
      "y = [0.16278622727156325, 0.23860035849284822, 0.0, 0.20881623085865514, 0.0, 0.0, 0.28237741337791133, 0.0, 0.0, 0.0]\n",
      "lambda = 0.06859300097111436\n",
      "y0 = 0.1357709475203246\n",
      "y = [0.2057502107863407, 0.3015738792920337, 0.0, 0.0, 0.0, 0.0, 0.356904962401301, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08002516779963342\n",
      "y0 = 0.1357709475203246\n",
      "y = [0.2057502107863407, 0.3015738792920337, 0.0, 0.0, 0.0, 0.0, 0.356904962401301, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08574125121389295\n",
      "y0 = 0.1357709475203246\n",
      "y = [0.2057502107863407, 0.3015738792920337, 0.0, 0.0, 0.0, 0.0, 0.356904962401301, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08859929292102271\n",
      "y0 = 0.1357709475203246\n",
      "y = [0.2057502107863407, 0.3015738792920337, 0.0, 0.0, 0.0, 0.0, 0.356904962401301, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09002831377458759\n",
      "y0 = 0.1357709475203246\n",
      "y = [0.2057502107863407, 0.3015738792920337, 0.0, 0.0, 0.0, 0.0, 0.356904962401301, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09074282420137003\n",
      "y0 = 0.1357709475203246\n",
      "y = [0.2057502107863407, 0.3015738792920337, 0.0, 0.0, 0.0, 0.0, 0.356904962401301, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09110007941476125\n",
      "y0 = 0.1357709475203246\n",
      "y = [0.2057502107863407, 0.3015738792920337, 0.0, 0.0, 0.0, 0.0, 0.356904962401301, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09127870702145686\n",
      "y0 = 0.1357709475203246\n",
      "y = [0.2057502107863407, 0.3015738792920337, 0.0, 0.0, 0.0, 0.0, 0.356904962401301, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09136802082480466\n",
      "y0 = 0.1357709475203246\n",
      "y = [0.2057502107863407, 0.3015738792920337, 0.0, 0.0, 0.0, 0.0, 0.356904962401301, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09141267772647857\n",
      "y0 = 0.1357709475203246\n",
      "y = [0.2057502107863407, 0.3015738792920337, 0.0, 0.0, 0.0, 0.0, 0.356904962401301, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09143500617731552\n",
      "y0 = 0.1357709475203246\n",
      "y = [0.2057502107863407, 0.3015738792920337, 0.0, 0.0, 0.0, 0.0, 0.356904962401301, 0.0, 0.0, 0.0]\n",
      "lambda = 0.091446170402734\n",
      "y0 = 0.1357709475203246\n",
      "y = [0.2057502107863407, 0.3015738792920337, 0.0, 0.0, 0.0, 0.0, 0.356904962401301, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09145175251544324\n",
      "y0 = 0.1357709475203246\n",
      "y = [0.2057502107863407, 0.3015738792920337, 0.0, 0.0, 0.0, 0.0, 0.356904962401301, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09145454357179786\n",
      "y0 = 0.1357709475203246\n",
      "y = [0.2057502107863407, 0.3015738792920337, 0.0, 0.0, 0.0, 0.0, 0.356904962401301, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09145593909997517\n",
      "y0 = 0.1357709475203246\n",
      "y = [0.2057502107863407, 0.3015738792920337, 0.0, 0.0, 0.0, 0.0, 0.356904962401301, 0.0, 0.0, 0.0]\n",
      "lambda = 0.09145663686406383\n",
      "y0 = 0.1357709475203246\n",
      "y = [0.2057502107863407, 0.3015738792920337, 0.0, 0.0, 0.0, 0.0, 0.356904962401301, 0.0, 0.0, 0.0]\n",
      "INSTANCE 8 - p = 10\n",
      "lambda = 0.043576731415058315\n",
      "y0 = 0.19108592552799392\n",
      "y = [0.21156886975792244, 0.32090195464988364, 0.0, 0.27644325006420006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.06536509712258748\n",
      "y0 = 0.19108592552799392\n",
      "y = [0.21156886975792244, 0.32090195464988364, 0.0, 0.27644325006420006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.07625927997635205\n",
      "y0 = 0.19108592552799392\n",
      "y = [0.21156886975792244, 0.32090195464988364, 0.0, 0.27644325006420006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08170637140323433\n",
      "y0 = 0.19108592552799392\n",
      "y = [0.21156886975792244, 0.32090195464988364, 0.0, 0.27644325006420006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08442991711667548\n",
      "y0 = 0.19108592552799392\n",
      "y = [0.21156886975792244, 0.32090195464988364, 0.0, 0.27644325006420006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08579168997339606\n",
      "y0 = 0.19108592552799392\n",
      "y = [0.21156886975792244, 0.32090195464988364, 0.0, 0.27644325006420006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08647257640175635\n",
      "y0 = 0.19108592552799392\n",
      "y = [0.21156886975792244, 0.32090195464988364, 0.0, 0.27644325006420006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08681301961593649\n",
      "y0 = 0.19108592552799392\n",
      "y = [0.21156886975792244, 0.32090195464988364, 0.0, 0.27644325006420006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08698324122302656\n",
      "y0 = 0.19108592552799392\n",
      "y = [0.21156886975792244, 0.32090195464988364, 0.0, 0.27644325006420006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.0870683520265716\n",
      "y0 = 0.19108592552799392\n",
      "y = [0.21156886975792244, 0.32090195464988364, 0.0, 0.27644325006420006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08711090742834411\n",
      "y0 = 0.19108592552799392\n",
      "y = [0.21156886975792244, 0.32090195464988364, 0.0, 0.27644325006420006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08713218512923038\n",
      "y0 = 0.19108592552799392\n",
      "y = [0.21156886975792244, 0.32090195464988364, 0.0, 0.27644325006420006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.0871428239796735\n",
      "y0 = 0.19108592552799392\n",
      "y = [0.21156886975792244, 0.32090195464988364, 0.0, 0.27644325006420006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08714814340489507\n",
      "y0 = 0.19108592552799392\n",
      "y = [0.21156886975792244, 0.32090195464988364, 0.0, 0.27644325006420006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08715080311750585\n",
      "y0 = 0.19108592552799392\n",
      "y = [0.21156886975792244, 0.32090195464988364, 0.0, 0.27644325006420006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08715213297381125\n",
      "y0 = 0.19108592552799392\n",
      "y = [0.21156886975792244, 0.32090195464988364, 0.0, 0.27644325006420006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08715279790196394\n",
      "y0 = 0.19108592552799392\n",
      "y = [0.21156886975792244, 0.32090195464988364, 0.0, 0.27644325006420006, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "INSTANCE 9 - p = 10\n",
      "lambda = 0.043460056416631955\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.06519008462494794\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.07605509872910593\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08148760578118491\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.0842038593072244\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08556198607024415\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08624104945175404\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08658058114250897\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08675034698788645\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08683522991057518\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08687767137191954\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08689889210259172\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08690950246792781\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08691480765059587\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.0869174602419299\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08691878653759691\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "lambda = 0.08691944968543042\n",
      "y0 = 0.29809152356408175\n",
      "y = [0.7019084764359182, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
      "{1: {1: 0.0, 2: 0.0, 5: 0.0, 10: 0.0}, 2: {1: 0.0, 2: 0.0, 5: 0.0, 10: 0.0}, 3: {1: 0.0, 2: 0.0010001659393310547, 5: 0.0, 10: 0.0009999275207519531}, 4: {1: 0.0, 2: 0.0009999275207519531, 5: 0.0, 10: 0.0}, 5: {1: 0.0, 2: 0.0, 5: 0.0, 10: 0.0}, 6: {1: 0.0, 2: 0.0009999275207519531, 5: 0.0, 10: 0.0}, 7: {1: 0.0, 2: 0.0009999275207519531, 5: 0.0, 10: 0.0009999275207519531}, 8: {1: 0.0, 2: 0.0009999275207519531, 5: 0.0009999275207519531, 10: 0.0}, 9: {1: 0.0, 2: 0.0, 5: 0.0010001659393310547, 10: 0.0019998550415039062}, 10: {1: None, 2: None, 5: None, 10: None}, 11: {1: None, 2: None, 5: None, 10: None}, 12: {1: None, 2: None, 5: None, 10: None}, 13: {1: None, 2: None, 5: None, 10: None}, 14: {1: None, 2: None, 5: None, 10: None}, 15: {1: None, 2: None, 5: None, 10: None}, 16: {1: None, 2: None, 5: None, 10: None}, 17: {1: None, 2: None, 5: None, 10: None}, 18: {1: None, 2: None, 5: None, 10: None}, 19: {1: None, 2: None, 5: None, 10: None}, 20: {1: None, 2: None, 5: None, 10: None}, 21: {1: None, 2: None, 5: None, 10: None}, 22: {1: None, 2: None, 5: None, 10: None}, 23: {1: None, 2: None, 5: None, 10: None}, 24: {1: None, 2: None, 5: None, 10: None}, 25: {1: None, 2: None, 5: None, 10: None}, 26: {1: None, 2: None, 5: None, 10: None}, 27: {1: None, 2: None, 5: None, 10: None}, 28: {1: None, 2: None, 5: None, 10: None}, 29: {1: None, 2: None, 5: None, 10: None}, 30: {1: None, 2: None, 5: None, 10: None}, 31: {1: None, 2: None, 5: None, 10: None}, 32: {1: None, 2: None, 5: None, 10: None}, 33: {1: None, 2: None, 5: None, 10: None}, 34: {1: None, 2: None, 5: None, 10: None}, 35: {1: None, 2: None, 5: None, 10: None}, 36: {1: None, 2: None, 5: None, 10: None}, 37: {1: None, 2: None, 5: None, 10: None}, 38: {1: None, 2: None, 5: None, 10: None}, 39: {1: None, 2: None, 5: None, 10: None}, 40: {1: None, 2: None, 5: None, 10: None}, 41: {1: None, 2: None, 5: None, 10: None}, 42: {1: None, 2: None, 5: None, 10: None}, 43: {1: None, 2: None, 5: None, 10: None}, 44: {1: None, 2: None, 5: None, 10: None}, 45: {1: None, 2: None, 5: None, 10: None}, 46: {1: None, 2: None, 5: None, 10: None}, 47: {1: None, 2: None, 5: None, 10: None}, 48: {1: None, 2: None, 5: None, 10: None}, 49: {1: None, 2: None, 5: None, 10: None}, 50: {1: None, 2: None, 5: None, 10: None}, 51: {1: None, 2: None, 5: None, 10: None}, 52: {1: None, 2: None, 5: None, 10: None}, 53: {1: None, 2: None, 5: None, 10: None}, 54: {1: None, 2: None, 5: None, 10: None}, 55: {1: None, 2: None, 5: None, 10: None}, 56: {1: None, 2: None, 5: None, 10: None}, 57: {1: None, 2: None, 5: None, 10: None}, 58: {1: None, 2: None, 5: None, 10: None}, 59: {1: None, 2: None, 5: None, 10: None}, 60: {1: None, 2: None, 5: None, 10: None}, 61: {1: None, 2: None, 5: None, 10: None}, 62: {1: None, 2: None, 5: None, 10: None}, 63: {1: None, 2: None, 5: None, 10: None}, 64: {1: None, 2: None, 5: None, 10: None}, 65: {1: None, 2: None, 5: None, 10: None}, 66: {1: None, 2: None, 5: None, 10: None}, 67: {1: None, 2: None, 5: None, 10: None}, 68: {1: None, 2: None, 5: None, 10: None}, 69: {1: None, 2: None, 5: None, 10: None}, 70: {1: None, 2: None, 5: None, 10: None}, 71: {1: None, 2: None, 5: None, 10: None}, 72: {1: None, 2: None, 5: None, 10: None}, 73: {1: None, 2: None, 5: None, 10: None}, 74: {1: None, 2: None, 5: None, 10: None}, 75: {1: None, 2: None, 5: None, 10: None}, 76: {1: None, 2: None, 5: None, 10: None}, 77: {1: None, 2: None, 5: None, 10: None}, 78: {1: None, 2: None, 5: None, 10: None}, 79: {1: None, 2: None, 5: None, 10: None}, 80: {1: None, 2: None, 5: None, 10: None}, 81: {1: None, 2: None, 5: None, 10: None}, 82: {1: None, 2: None, 5: None, 10: None}, 83: {1: None, 2: None, 5: None, 10: None}, 84: {1: None, 2: None, 5: None, 10: None}, 85: {1: None, 2: None, 5: None, 10: None}, 86: {1: None, 2: None, 5: None, 10: None}, 87: {1: None, 2: None, 5: None, 10: None}, 88: {1: None, 2: None, 5: None, 10: None}, 89: {1: None, 2: None, 5: None, 10: None}, 90: {1: None, 2: None, 5: None, 10: None}, 91: {1: None, 2: None, 5: None, 10: None}, 92: {1: None, 2: None, 5: None, 10: None}, 93: {1: None, 2: None, 5: None, 10: None}, 94: {1: None, 2: None, 5: None, 10: None}, 95: {1: None, 2: None, 5: None, 10: None}, 96: {1: None, 2: None, 5: None, 10: None}, 97: {1: None, 2: None, 5: None, 10: None}, 98: {1: None, 2: None, 5: None, 10: None}, 99: {1: None, 2: None, 5: None, 10: None}, 100: {1: None, 2: None, 5: None, 10: None}}\n",
      "{1: {1: 0.665778022248497, 2: 0.665778022248497, 5: 0.665778022248497, 10: 0.665778022248497}, 2: {1: 0.5860772381431256, 2: 0.5860772381431256, 5: 0.5860772381431256, 10: 0.5860772381431256}, 3: {1: 0.5002104764686905, 2: 0.5002104764686905, 5: 0.5002104764686905, 10: 0.5002104764686905}, 4: {1: -inf, 2: 0.7524656326428268, 5: 0.7524656326428268, 10: 0.7524656326428268}, 5: {1: 0.615711695902684, 2: 0.723571965671864, 5: 0.723571965671864, 10: 0.723571965671864}, 6: {1: 0.6167270302351567, 2: 0.6167270302351567, 5: 0.6167270302351567, 10: 0.6167270302351567}, 7: {1: 0.5881676473285752, 2: 0.692597066675673, 5: 0.692597066675673, 10: 0.6442926182257669}, 8: {1: 0.48755645885707205, 2: 0.5998321405202051, 5: 0.6056793393246293, 10: 0.6056793393246293}, 9: {1: 0.6100996397043438, 2: 0.6100996397043438, 5: 0.6100996397043438, 10: 0.6100996397043438}, 10: {1: None, 2: None, 5: None, 10: None}, 11: {1: None, 2: None, 5: None, 10: None}, 12: {1: None, 2: None, 5: None, 10: None}, 13: {1: None, 2: None, 5: None, 10: None}, 14: {1: None, 2: None, 5: None, 10: None}, 15: {1: None, 2: None, 5: None, 10: None}, 16: {1: None, 2: None, 5: None, 10: None}, 17: {1: None, 2: None, 5: None, 10: None}, 18: {1: None, 2: None, 5: None, 10: None}, 19: {1: None, 2: None, 5: None, 10: None}, 20: {1: None, 2: None, 5: None, 10: None}, 21: {1: None, 2: None, 5: None, 10: None}, 22: {1: None, 2: None, 5: None, 10: None}, 23: {1: None, 2: None, 5: None, 10: None}, 24: {1: None, 2: None, 5: None, 10: None}, 25: {1: None, 2: None, 5: None, 10: None}, 26: {1: None, 2: None, 5: None, 10: None}, 27: {1: None, 2: None, 5: None, 10: None}, 28: {1: None, 2: None, 5: None, 10: None}, 29: {1: None, 2: None, 5: None, 10: None}, 30: {1: None, 2: None, 5: None, 10: None}, 31: {1: None, 2: None, 5: None, 10: None}, 32: {1: None, 2: None, 5: None, 10: None}, 33: {1: None, 2: None, 5: None, 10: None}, 34: {1: None, 2: None, 5: None, 10: None}, 35: {1: None, 2: None, 5: None, 10: None}, 36: {1: None, 2: None, 5: None, 10: None}, 37: {1: None, 2: None, 5: None, 10: None}, 38: {1: None, 2: None, 5: None, 10: None}, 39: {1: None, 2: None, 5: None, 10: None}, 40: {1: None, 2: None, 5: None, 10: None}, 41: {1: None, 2: None, 5: None, 10: None}, 42: {1: None, 2: None, 5: None, 10: None}, 43: {1: None, 2: None, 5: None, 10: None}, 44: {1: None, 2: None, 5: None, 10: None}, 45: {1: None, 2: None, 5: None, 10: None}, 46: {1: None, 2: None, 5: None, 10: None}, 47: {1: None, 2: None, 5: None, 10: None}, 48: {1: None, 2: None, 5: None, 10: None}, 49: {1: None, 2: None, 5: None, 10: None}, 50: {1: None, 2: None, 5: None, 10: None}, 51: {1: None, 2: None, 5: None, 10: None}, 52: {1: None, 2: None, 5: None, 10: None}, 53: {1: None, 2: None, 5: None, 10: None}, 54: {1: None, 2: None, 5: None, 10: None}, 55: {1: None, 2: None, 5: None, 10: None}, 56: {1: None, 2: None, 5: None, 10: None}, 57: {1: None, 2: None, 5: None, 10: None}, 58: {1: None, 2: None, 5: None, 10: None}, 59: {1: None, 2: None, 5: None, 10: None}, 60: {1: None, 2: None, 5: None, 10: None}, 61: {1: None, 2: None, 5: None, 10: None}, 62: {1: None, 2: None, 5: None, 10: None}, 63: {1: None, 2: None, 5: None, 10: None}, 64: {1: None, 2: None, 5: None, 10: None}, 65: {1: None, 2: None, 5: None, 10: None}, 66: {1: None, 2: None, 5: None, 10: None}, 67: {1: None, 2: None, 5: None, 10: None}, 68: {1: None, 2: None, 5: None, 10: None}, 69: {1: None, 2: None, 5: None, 10: None}, 70: {1: None, 2: None, 5: None, 10: None}, 71: {1: None, 2: None, 5: None, 10: None}, 72: {1: None, 2: None, 5: None, 10: None}, 73: {1: None, 2: None, 5: None, 10: None}, 74: {1: None, 2: None, 5: None, 10: None}, 75: {1: None, 2: None, 5: None, 10: None}, 76: {1: None, 2: None, 5: None, 10: None}, 77: {1: None, 2: None, 5: None, 10: None}, 78: {1: None, 2: None, 5: None, 10: None}, 79: {1: None, 2: None, 5: None, 10: None}, 80: {1: None, 2: None, 5: None, 10: None}, 81: {1: None, 2: None, 5: None, 10: None}, 82: {1: None, 2: None, 5: None, 10: None}, 83: {1: None, 2: None, 5: None, 10: None}, 84: {1: None, 2: None, 5: None, 10: None}, 85: {1: None, 2: None, 5: None, 10: None}, 86: {1: None, 2: None, 5: None, 10: None}, 87: {1: None, 2: None, 5: None, 10: None}, 88: {1: None, 2: None, 5: None, 10: None}, 89: {1: None, 2: None, 5: None, 10: None}, 90: {1: None, 2: None, 5: None, 10: None}, 91: {1: None, 2: None, 5: None, 10: None}, 92: {1: None, 2: None, 5: None, 10: None}, 93: {1: None, 2: None, 5: None, 10: None}, 94: {1: None, 2: None, 5: None, 10: None}, 95: {1: None, 2: None, 5: None, 10: None}, 96: {1: None, 2: None, 5: None, 10: None}, 97: {1: None, 2: None, 5: None, 10: None}, 98: {1: None, 2: None, 5: None, 10: None}, 99: {1: None, 2: None, 5: None, 10: None}, 100: {1: None, 2: None, 5: None, 10: None}}\n",
      "{1: {1: [0.4553534309526569, 0.6830301464289854, 0.7968685041671496, 0.8537876830362316, 0.8822472724707727, 0.8964770671880433, 0.9035919645466786, 0.9071494132259962, 0.908928137565655, 0.9098174997354844, 0.9102621808203991, 0.9104845213628565, 0.9105956916340852, 0.9106512767696995, 0.9106790693375066, 0.9106929656214102, 0.910699913763362, 0.9107033878343379, 0.9107051248698259, 0.9107059933875699], 2: [0.22767671547632845, 0.3415150732144927, 0.3984342520835748, 0.4268938415181158, 0.44112363623538636, 0.44823853359402166, 0.4517959822733393, 0.4535747066129981, 0.4544640687828275, 0.4549087498677422, 0.45513109041019956, 0.45524226068142826, 0.4552978458170426, 0.45532563838484974, 0.4553395346687533, 0.4553464828107051, 0.455349956881681, 0.45535169391716895, 0.45535256243491296], 5: [0.09107068619053138, 0.13660602928579707, 0.15937370083342992, 0.17075753660724635, 0.17644945449415456, 0.17929541343760866, 0.18071839290933572, 0.18142988264519924, 0.181785627513131, 0.18196349994709687, 0.18205243616407982, 0.1820969042725713, 0.18211913832681703, 0.1821302553539399, 0.18213581386750133, 0.18213859312428204, 0.1821399827526724, 0.18214067756686758], 10: [0.04553534309526569, 0.06830301464289854, 0.07968685041671496, 0.08537876830362318, 0.08822472724707728, 0.08964770671880433, 0.09035919645466786, 0.09071494132259962, 0.0908928137565655, 0.09098174997354844, 0.09102621808203991, 0.09104845213628565, 0.09105956916340852, 0.09106512767696995, 0.09106790693375066, 0.09106929656214102, 0.0910699913763362]}, 2: {1: [0.40635838571974753, 0.6095375785796213, 0.7111271750095582, 0.7619219732245266, 0.7873193723320109, 0.800018071885753, 0.806367421662624, 0.8095420965510596, 0.8111294339952773, 0.8119231027173861, 0.8123199370784406, 0.8125183542589678, 0.8126175628492314, 0.8126671671443633, 0.8126919692919292, 0.8127043703657122, 0.8127105709026037, 0.8127136711710494, 0.8127152213052722, 0.8127159963723836], 2: [0.20317919285987376, 0.30476878928981066, 0.3555635875047791, 0.3809609866122633, 0.39365968616600544, 0.4000090359428765, 0.403183710831312, 0.4047710482755298, 0.40556471699763863, 0.40596155135869305, 0.4061599685392203, 0.4062591771294839, 0.4063087814246157, 0.40633358357218163, 0.4063459846459646, 0.4063521851828561, 0.40635528545130184, 0.4063568355855247, 0.4063576106526361], 5: [0.0812716771439495, 0.12190751571592426, 0.14222543500191165, 0.15238439464490533, 0.15746387446640217, 0.1600036143771506, 0.1612734843325248, 0.1619084193102119, 0.16222588679905547, 0.16238462054347724, 0.16246398741568813, 0.16250367085179357, 0.1625235125698463, 0.16253343342887266, 0.16253839385838584, 0.16254087407314244, 0.16254211418052072, 0.16254273423420987], 10: [0.04063583857197475, 0.06095375785796213, 0.07111271750095582, 0.07619219732245266, 0.07873193723320109, 0.0800018071885753, 0.0806367421662624, 0.08095420965510595, 0.08111294339952774, 0.08119231027173862, 0.08123199370784406, 0.08125183542589678, 0.08126175628492315, 0.08126671671443633, 0.08126919692919292, 0.08127043703657122, 0.08127105709026036]}, 3: {1: [0.3875255787914747, 0.5812883681872121, 0.6781697628850807, 0.7266104602340151, 0.7508308089084823, 0.7629409832457159, 0.7689960704143326, 0.772023613998641, 0.7735373857907952, 0.7742942716868724, 0.7746727146349108, 0.7748619361089302, 0.7749565468459398, 0.7750038522144447, 0.775027504898697, 0.7750393312408232, 0.7750452444118863, 0.7750482009974178, 0.7750496792901835, 0.7750504184365665], 2: [0.19376278939573735, 0.29064418409360604, 0.33908488144254034, 0.36330523011700755, 0.37541540445424115, 0.38147049162285795, 0.3844980352071663, 0.3860118069993205, 0.3867686928953976, 0.3871471358434362, 0.3873363573174554, 0.3874309680544651, 0.3874782734229699, 0.38750192610722234, 0.3875137524493485, 0.3875196656204116, 0.38752262220594313, 0.3875241004987089, 0.38752483964509177], 5: [0.07750511575829494, 0.11625767363744241, 0.13563395257701616, 0.14532209204680302, 0.15016616178169645, 0.15258819664914317, 0.1537992140828665, 0.1544047227997282, 0.15470747715815902, 0.15485885433737445, 0.15493454292698217, 0.15497238722178602, 0.15499130936918795, 0.1550007704428889, 0.1550055009797394, 0.15500786624816465, 0.15500904888237726, 0.15500964019948357], 10: [0.03875255787914747, 0.058128836818721205, 0.06781697628850808, 0.07266104602340151, 0.07508308089084823, 0.07629409832457158, 0.07689960704143325, 0.0772023613998641, 0.07735373857907951, 0.07742942716868723, 0.07746727146349108, 0.07748619361089301, 0.07749565468459398, 0.07750038522144445, 0.0775027504898697, 0.07750393312408232, 0.07750452444118863]}, 4: {1: [0.47488223472022895, 0.7123233520803434, 0.8310439107604006, 0.8904041901004293, 0.9200843297704435, 0.9349243996054507, 0.9423444345229544, 0.9460544519817061, 0.9479094607110821, 0.94883696507577, 0.9493007172581139, 0.949532593349286, 0.9496485313948719, 0.9497065004176649, 0.9497354849290613, 0.9497499771847596, 0.9497572233126088, 0.9497608463765334, 0.9497626579084957, 0.9497635636744768], 2: [0.23744111736011447, 0.3561616760401717, 0.4155219553802003, 0.44520209505021463, 0.46004216488522176, 0.46746219980272535, 0.4711722172614772, 0.47302722599085306, 0.47395473035554103, 0.474418482537885, 0.47465035862905697, 0.474766296674643, 0.47482426569743597, 0.47485325020883246, 0.4748677424645307, 0.4748749885923798, 0.4748786116563044, 0.4748804231882667, 0.47488132895424784], 5: [0.09497644694404579, 0.1424646704160687, 0.16620878215208013, 0.17808083802008584, 0.18401686595408873, 0.18698487992109014, 0.18846888690459085, 0.1892108903963412, 0.18958189214221638, 0.189767393015154, 0.18986014345162278, 0.1899065186698572, 0.18992970627897438, 0.189941300083533, 0.1899470969858123, 0.18994999543695196, 0.18995144466252178, 0.18995216927530667], 10: [0.047488223472022896, 0.07123233520803435, 0.08310439107604006, 0.08904041901004292, 0.09200843297704436, 0.09349243996054507, 0.09423444345229542, 0.0946054451981706, 0.09479094607110819, 0.094883696507577, 0.09493007172581139, 0.0949532593349286, 0.09496485313948719, 0.0949706500417665, 0.09497354849290615, 0.09497499771847598, 0.09497572233126089]}, 5: {1: [0.4618877151344487, 0.6928315727016731, 0.8083035014852853, 0.8660394658770914, 0.8949074480729944, 0.9093414391709459, 0.9165584347199216, 0.9201669324944095, 0.9219711813816535, 0.9228733058252754, 0.9233243680470864, 0.9235498991579919, 0.9236626647134447, 0.9237190474911711, 0.9237472388800343, 0.9237613345744659, 0.9237683824216816, 0.9237719063452895, 0.9237736683070934, 0.9237745492879954], 2: [0.23094385756722435, 0.34641578635083653, 0.40415175074264265, 0.4330197329385457, 0.4474537240364972, 0.45467071958547295, 0.4582792173599608, 0.46008346624720475, 0.46098559069082673, 0.4614366529126377, 0.4616621840235432, 0.46177494957899595, 0.46183133235672236, 0.46185952374558553, 0.46187361944001715, 0.4618806672872329, 0.4618841912108408, 0.46188595317264475, 0.4618868341535467], 5: [0.09237754302688975, 0.13856631454033463, 0.16166070029705706, 0.1732078931754183, 0.1789814896145989, 0.18186828783418918, 0.18331168694398434, 0.1840333864988819, 0.1843942362763307, 0.1845746611650551, 0.1846648736094173, 0.1847099798315984, 0.18473253294268893, 0.1847438094982342, 0.18474944777600685, 0.18475226691489316, 0.18475367648433633, 0.1847543812690579], 10: [0.04618877151344487, 0.06928315727016732, 0.08083035014852853, 0.08660394658770915, 0.08949074480729945, 0.09093414391709459, 0.09165584347199217, 0.09201669324944095, 0.09219711813816535, 0.09228733058252755, 0.09233243680470865, 0.0923549899157992, 0.09236626647134447, 0.0923719047491171, 0.09237472388800343, 0.09237613345744658, 0.09237683824216816]}, 6: {1: [0.4293663793834116, 0.6440495690751173, 0.7513911639209703, 0.8050619613438967, 0.83189736005536, 0.8453150594110916, 0.8520239090889574, 0.8553783339278903, 0.8570555463473568, 0.85789415255709, 0.8583134556619566, 0.85852310721439, 0.8586279329906066, 0.8586803458787149, 0.858706552322769, 0.8587196555447961, 0.8587262071558097, 0.8587294829613165, 0.8587311208640698, 0.8587319398154465], 2: [0.2146831896917058, 0.3220247845375587, 0.37569558196048514, 0.40253098067194837, 0.41594868002768, 0.4226575297055458, 0.4260119545444787, 0.42768916696394516, 0.4285277731736784, 0.428947076278545, 0.4291567278309783, 0.429261553607195, 0.4293139664953033, 0.42934017293935745, 0.4293532761613845, 0.42935982777239806, 0.42936310357790486, 0.42936474148065823, 0.4293655604320349], 5: [0.08587327587668232, 0.1288099138150235, 0.15027823278419405, 0.16101239226877934, 0.166379472011072, 0.16906301188221834, 0.1704047818177915, 0.17107566678557806, 0.17141110926947134, 0.17157883051141798, 0.1716626911323913, 0.17170462144287796, 0.17172558659812132, 0.17173606917574297, 0.17174131046455382, 0.17174393110895925, 0.17174524143116193, 0.1717458965922633], 10: [0.04293663793834116, 0.06440495690751175, 0.07513911639209703, 0.08050619613438967, 0.083189736005536, 0.08453150594110917, 0.08520239090889575, 0.08553783339278903, 0.08570555463473567, 0.08578941525570899, 0.08583134556619565, 0.08585231072143898, 0.08586279329906066, 0.08586803458787148, 0.08587065523227691, 0.08587196555447962, 0.08587262071558097]}, 7: {1: [0.4572866731407624, 0.6859300097111436, 0.8002516779963342, 0.8574125121389296, 0.8859929292102271, 0.900283137745876, 0.9074282420137003, 0.9110007941476126, 0.9127870702145686, 0.9136802082480466, 0.9141267772647856, 0.9143500617731553, 0.91446170402734, 0.9145175251544324, 0.9145454357179785, 0.9145593909997516, 0.9145663686406382, 0.9145698574610814, 0.914571601871303, 0.9145724740764138], 2: [0.2286433365703812, 0.3429650048555718, 0.4001258389981671, 0.4287062560694648, 0.44299646460511355, 0.450141568872938, 0.45371412100685016, 0.4555003970738063, 0.4563935351072843, 0.4568401041240233, 0.4570633886323928, 0.4571750308865776, 0.45723085201367, 0.4572587625772162, 0.45727271785898926, 0.4572796954998758, 0.4572831843203191, 0.4572849287305407, 0.4572858009356515], 5: [0.09145733462815248, 0.1371860019422287, 0.16005033559926685, 0.1714825024277859, 0.17719858584204543, 0.18005662754917517, 0.18148564840274006, 0.1822001588295225, 0.18255741404291373, 0.18273604164960933, 0.18282535545295714, 0.18287001235463105, 0.182892340805468, 0.18290350503088648, 0.18290908714359572, 0.18291187819995033, 0.18291327372812766, 0.1829139714922163], 10: [0.04572866731407624, 0.06859300097111436, 0.08002516779963342, 0.08574125121389295, 0.08859929292102271, 0.09002831377458759, 0.09074282420137003, 0.09110007941476125, 0.09127870702145686, 0.09136802082480466, 0.09141267772647857, 0.09143500617731552, 0.091446170402734, 0.09145175251544324, 0.09145454357179786, 0.09145593909997517, 0.09145663686406383]}, 8: {1: [0.4357673141505831, 0.6536509712258747, 0.7625927997635205, 0.8170637140323433, 0.8442991711667548, 0.8579168997339606, 0.8647257640175634, 0.8681301961593648, 0.8698324122302655, 0.8706835202657159, 0.8711090742834411, 0.8713218512923037, 0.871428239796735, 0.8714814340489506, 0.8715080311750585, 0.8715213297381124, 0.8715279790196393, 0.8715313036604028, 0.8715329659807844, 0.8715337971409753], 2: [0.21788365707529156, 0.32682548561293734, 0.38129639988176023, 0.4085318570161717, 0.4221495855833774, 0.4289584498669803, 0.4323628820087817, 0.4340650980796824, 0.43491620611513276, 0.43534176013285797, 0.43555453714172054, 0.43566092564615183, 0.4357141198983675, 0.4357407170244753, 0.43575401558752924, 0.4357606648690562, 0.43576398950981965, 0.4357656518302014, 0.4357664829903922], 5: [0.08715346283011663, 0.13073019424517496, 0.1525185599527041, 0.16341274280646867, 0.16885983423335096, 0.17158337994679213, 0.1729451528035127, 0.17362603923187298, 0.17396648244605312, 0.1741367040531432, 0.17422181485668822, 0.17426437025846075, 0.174285647959347, 0.17429628680979015, 0.1743016062350117, 0.1743042659476225, 0.17430559580392788, 0.17430626073208055], 10: [0.043576731415058315, 0.06536509712258748, 0.07625927997635205, 0.08170637140323433, 0.08442991711667548, 0.08579168997339606, 0.08647257640175635, 0.08681301961593649, 0.08698324122302656, 0.0870683520265716, 0.08711090742834411, 0.08713218512923038, 0.0871428239796735, 0.08714814340489507, 0.08715080311750585, 0.08715213297381125, 0.08715279790196394]}, 9: {1: [0.43460056416631954, 0.6519008462494793, 0.7605509872910592, 0.8148760578118491, 0.842038593072244, 0.8556198607024416, 0.8624104945175404, 0.8658058114250897, 0.8675034698788644, 0.8683522991057517, 0.8687767137191954, 0.8689889210259172, 0.8690950246792781, 0.8691480765059586, 0.8691746024192988, 0.8691878653759689, 0.8691944968543039, 0.8691978125934715, 0.8691994704630552, 0.8692002993978472], 2: [0.21730028208315977, 0.32595042312473965, 0.3802754936455296, 0.40743802890592457, 0.421019296536122, 0.4278099303512208, 0.4312052472587702, 0.43290290571254486, 0.4337517349394322, 0.43417614955287587, 0.4343883568595977, 0.4344944605129586, 0.43454751233963906, 0.4345740382529793, 0.4345873012096494, 0.43459393268798446, 0.43459724842715197, 0.43459890629673575, 0.4345997352315276], 5: [0.08692011283326391, 0.13038016924989587, 0.15211019745821186, 0.16297521156236983, 0.1684077186144488, 0.1711239721404883, 0.17248209890350807, 0.17316116228501793, 0.1735006939757729, 0.17367045982115037, 0.17375534274383908, 0.17379778420518344, 0.17381900493585561, 0.17382961530119173, 0.1738349204838598, 0.17383757307519382, 0.17383889937086083, 0.1738395625186943], 10: [0.043460056416631955, 0.06519008462494794, 0.07605509872910593, 0.08148760578118491, 0.0842038593072244, 0.08556198607024415, 0.08624104945175404, 0.08658058114250897, 0.08675034698788645, 0.08683522991057518, 0.08687767137191954, 0.08689889210259172, 0.08690950246792781, 0.08691480765059587, 0.0869174602419299, 0.08691878653759691, 0.08691944968543042]}, 10: {1: None, 2: None, 5: None, 10: None}, 11: {1: None, 2: None, 5: None, 10: None}, 12: {1: None, 2: None, 5: None, 10: None}, 13: {1: None, 2: None, 5: None, 10: None}, 14: {1: None, 2: None, 5: None, 10: None}, 15: {1: None, 2: None, 5: None, 10: None}, 16: {1: None, 2: None, 5: None, 10: None}, 17: {1: None, 2: None, 5: None, 10: None}, 18: {1: None, 2: None, 5: None, 10: None}, 19: {1: None, 2: None, 5: None, 10: None}, 20: {1: None, 2: None, 5: None, 10: None}, 21: {1: None, 2: None, 5: None, 10: None}, 22: {1: None, 2: None, 5: None, 10: None}, 23: {1: None, 2: None, 5: None, 10: None}, 24: {1: None, 2: None, 5: None, 10: None}, 25: {1: None, 2: None, 5: None, 10: None}, 26: {1: None, 2: None, 5: None, 10: None}, 27: {1: None, 2: None, 5: None, 10: None}, 28: {1: None, 2: None, 5: None, 10: None}, 29: {1: None, 2: None, 5: None, 10: None}, 30: {1: None, 2: None, 5: None, 10: None}, 31: {1: None, 2: None, 5: None, 10: None}, 32: {1: None, 2: None, 5: None, 10: None}, 33: {1: None, 2: None, 5: None, 10: None}, 34: {1: None, 2: None, 5: None, 10: None}, 35: {1: None, 2: None, 5: None, 10: None}, 36: {1: None, 2: None, 5: None, 10: None}, 37: {1: None, 2: None, 5: None, 10: None}, 38: {1: None, 2: None, 5: None, 10: None}, 39: {1: None, 2: None, 5: None, 10: None}, 40: {1: None, 2: None, 5: None, 10: None}, 41: {1: None, 2: None, 5: None, 10: None}, 42: {1: None, 2: None, 5: None, 10: None}, 43: {1: None, 2: None, 5: None, 10: None}, 44: {1: None, 2: None, 5: None, 10: None}, 45: {1: None, 2: None, 5: None, 10: None}, 46: {1: None, 2: None, 5: None, 10: None}, 47: {1: None, 2: None, 5: None, 10: None}, 48: {1: None, 2: None, 5: None, 10: None}, 49: {1: None, 2: None, 5: None, 10: None}, 50: {1: None, 2: None, 5: None, 10: None}, 51: {1: None, 2: None, 5: None, 10: None}, 52: {1: None, 2: None, 5: None, 10: None}, 53: {1: None, 2: None, 5: None, 10: None}, 54: {1: None, 2: None, 5: None, 10: None}, 55: {1: None, 2: None, 5: None, 10: None}, 56: {1: None, 2: None, 5: None, 10: None}, 57: {1: None, 2: None, 5: None, 10: None}, 58: {1: None, 2: None, 5: None, 10: None}, 59: {1: None, 2: None, 5: None, 10: None}, 60: {1: None, 2: None, 5: None, 10: None}, 61: {1: None, 2: None, 5: None, 10: None}, 62: {1: None, 2: None, 5: None, 10: None}, 63: {1: None, 2: None, 5: None, 10: None}, 64: {1: None, 2: None, 5: None, 10: None}, 65: {1: None, 2: None, 5: None, 10: None}, 66: {1: None, 2: None, 5: None, 10: None}, 67: {1: None, 2: None, 5: None, 10: None}, 68: {1: None, 2: None, 5: None, 10: None}, 69: {1: None, 2: None, 5: None, 10: None}, 70: {1: None, 2: None, 5: None, 10: None}, 71: {1: None, 2: None, 5: None, 10: None}, 72: {1: None, 2: None, 5: None, 10: None}, 73: {1: None, 2: None, 5: None, 10: None}, 74: {1: None, 2: None, 5: None, 10: None}, 75: {1: None, 2: None, 5: None, 10: None}, 76: {1: None, 2: None, 5: None, 10: None}, 77: {1: None, 2: None, 5: None, 10: None}, 78: {1: None, 2: None, 5: None, 10: None}, 79: {1: None, 2: None, 5: None, 10: None}, 80: {1: None, 2: None, 5: None, 10: None}, 81: {1: None, 2: None, 5: None, 10: None}, 82: {1: None, 2: None, 5: None, 10: None}, 83: {1: None, 2: None, 5: None, 10: None}, 84: {1: None, 2: None, 5: None, 10: None}, 85: {1: None, 2: None, 5: None, 10: None}, 86: {1: None, 2: None, 5: None, 10: None}, 87: {1: None, 2: None, 5: None, 10: None}, 88: {1: None, 2: None, 5: None, 10: None}, 89: {1: None, 2: None, 5: None, 10: None}, 90: {1: None, 2: None, 5: None, 10: None}, 91: {1: None, 2: None, 5: None, 10: None}, 92: {1: None, 2: None, 5: None, 10: None}, 93: {1: None, 2: None, 5: None, 10: None}, 94: {1: None, 2: None, 5: None, 10: None}, 95: {1: None, 2: None, 5: None, 10: None}, 96: {1: None, 2: None, 5: None, 10: None}, 97: {1: None, 2: None, 5: None, 10: None}, 98: {1: None, 2: None, 5: None, 10: None}, 99: {1: None, 2: None, 5: None, 10: None}, 100: {1: None, 2: None, 5: None, 10: None}}\n",
      "{1: {1: [0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497], 2: [0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497], 5: [0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497], 10: [0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497, 0.665778022248497]}, 2: {1: [0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256], 2: [0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256], 5: [0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256], 10: [0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256, 0.5860772381431256]}, 3: {1: [0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905], 2: [0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905], 5: [0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905], 10: [0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905, 0.5002104764686905]}, 4: {1: [], 2: [0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268], 5: [0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268], 10: [0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268, 0.7524656326428268]}, 5: {1: [0.615711695902684, 0.615711695902684, 0.615711695902684, 0.615711695902684, 0.615711695902684, 0.615711695902684, 0.615711695902684, 0.615711695902684, 0.615711695902684, 0.615711695902684, 0.615711695902684, 0.615711695902684, 0.615711695902684, 0.615711695902684, 0.615711695902684, 0.615711695902684, 0.615711695902684, 0.615711695902684, 0.615711695902684], 2: [0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864], 5: [0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864], 10: [0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864, 0.723571965671864]}, 6: {1: [0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567], 2: [0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567], 5: [0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567], 10: [0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567, 0.6167270302351567]}, 7: {1: [0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752], 2: [0.692597066675673, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752, 0.5881676473285752], 5: [0.6308696962026217, 0.6308696962026217, 0.6308696962026217, 0.692597066675673, 0.692597066675673, 0.692597066675673, 0.692597066675673, 0.692597066675673, 0.692597066675673, 0.692597066675673, 0.692597066675673, 0.692597066675673, 0.692597066675673, 0.692597066675673, 0.692597066675673, 0.692597066675673, 0.692597066675673, 0.692597066675673], 10: [0.6442926182257669, 0.6308696962026217, 0.6308696962026217, 0.6308696962026217, 0.6308696962026217, 0.6308696962026217, 0.6308696962026217, 0.6308696962026217, 0.6308696962026217, 0.6308696962026217, 0.6308696962026217, 0.6308696962026217, 0.6308696962026217, 0.6308696962026217, 0.6308696962026217, 0.6308696962026217, 0.6308696962026217]}, 8: {1: [0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205], 2: [0.5998321405202051, 0.5998321405202051, 0.5998321405202051, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205, 0.48755645885707205], 5: [0.6056793393246293, 0.6056793393246293, 0.5998321405202051, 0.5998321405202051, 0.5998321405202051, 0.5998321405202051, 0.5998321405202051, 0.5998321405202051, 0.5998321405202051, 0.5998321405202051, 0.5998321405202051, 0.5998321405202051, 0.5998321405202051, 0.5998321405202051, 0.5998321405202051, 0.5998321405202051, 0.5998321405202051, 0.5998321405202051], 10: [0.6056793393246293, 0.6056793393246293, 0.6056793393246293, 0.6056793393246293, 0.6056793393246293, 0.6056793393246293, 0.6056793393246293, 0.6056793393246293, 0.6056793393246293, 0.6056793393246293, 0.6056793393246293, 0.6056793393246293, 0.6056793393246293, 0.6056793393246293, 0.6056793393246293, 0.6056793393246293, 0.6056793393246293]}, 9: {1: [0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438], 2: [0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438], 5: [0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438], 10: [0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438, 0.6100996397043438]}, 10: {1: None, 2: None, 5: None, 10: None}, 11: {1: None, 2: None, 5: None, 10: None}, 12: {1: None, 2: None, 5: None, 10: None}, 13: {1: None, 2: None, 5: None, 10: None}, 14: {1: None, 2: None, 5: None, 10: None}, 15: {1: None, 2: None, 5: None, 10: None}, 16: {1: None, 2: None, 5: None, 10: None}, 17: {1: None, 2: None, 5: None, 10: None}, 18: {1: None, 2: None, 5: None, 10: None}, 19: {1: None, 2: None, 5: None, 10: None}, 20: {1: None, 2: None, 5: None, 10: None}, 21: {1: None, 2: None, 5: None, 10: None}, 22: {1: None, 2: None, 5: None, 10: None}, 23: {1: None, 2: None, 5: None, 10: None}, 24: {1: None, 2: None, 5: None, 10: None}, 25: {1: None, 2: None, 5: None, 10: None}, 26: {1: None, 2: None, 5: None, 10: None}, 27: {1: None, 2: None, 5: None, 10: None}, 28: {1: None, 2: None, 5: None, 10: None}, 29: {1: None, 2: None, 5: None, 10: None}, 30: {1: None, 2: None, 5: None, 10: None}, 31: {1: None, 2: None, 5: None, 10: None}, 32: {1: None, 2: None, 5: None, 10: None}, 33: {1: None, 2: None, 5: None, 10: None}, 34: {1: None, 2: None, 5: None, 10: None}, 35: {1: None, 2: None, 5: None, 10: None}, 36: {1: None, 2: None, 5: None, 10: None}, 37: {1: None, 2: None, 5: None, 10: None}, 38: {1: None, 2: None, 5: None, 10: None}, 39: {1: None, 2: None, 5: None, 10: None}, 40: {1: None, 2: None, 5: None, 10: None}, 41: {1: None, 2: None, 5: None, 10: None}, 42: {1: None, 2: None, 5: None, 10: None}, 43: {1: None, 2: None, 5: None, 10: None}, 44: {1: None, 2: None, 5: None, 10: None}, 45: {1: None, 2: None, 5: None, 10: None}, 46: {1: None, 2: None, 5: None, 10: None}, 47: {1: None, 2: None, 5: None, 10: None}, 48: {1: None, 2: None, 5: None, 10: None}, 49: {1: None, 2: None, 5: None, 10: None}, 50: {1: None, 2: None, 5: None, 10: None}, 51: {1: None, 2: None, 5: None, 10: None}, 52: {1: None, 2: None, 5: None, 10: None}, 53: {1: None, 2: None, 5: None, 10: None}, 54: {1: None, 2: None, 5: None, 10: None}, 55: {1: None, 2: None, 5: None, 10: None}, 56: {1: None, 2: None, 5: None, 10: None}, 57: {1: None, 2: None, 5: None, 10: None}, 58: {1: None, 2: None, 5: None, 10: None}, 59: {1: None, 2: None, 5: None, 10: None}, 60: {1: None, 2: None, 5: None, 10: None}, 61: {1: None, 2: None, 5: None, 10: None}, 62: {1: None, 2: None, 5: None, 10: None}, 63: {1: None, 2: None, 5: None, 10: None}, 64: {1: None, 2: None, 5: None, 10: None}, 65: {1: None, 2: None, 5: None, 10: None}, 66: {1: None, 2: None, 5: None, 10: None}, 67: {1: None, 2: None, 5: None, 10: None}, 68: {1: None, 2: None, 5: None, 10: None}, 69: {1: None, 2: None, 5: None, 10: None}, 70: {1: None, 2: None, 5: None, 10: None}, 71: {1: None, 2: None, 5: None, 10: None}, 72: {1: None, 2: None, 5: None, 10: None}, 73: {1: None, 2: None, 5: None, 10: None}, 74: {1: None, 2: None, 5: None, 10: None}, 75: {1: None, 2: None, 5: None, 10: None}, 76: {1: None, 2: None, 5: None, 10: None}, 77: {1: None, 2: None, 5: None, 10: None}, 78: {1: None, 2: None, 5: None, 10: None}, 79: {1: None, 2: None, 5: None, 10: None}, 80: {1: None, 2: None, 5: None, 10: None}, 81: {1: None, 2: None, 5: None, 10: None}, 82: {1: None, 2: None, 5: None, 10: None}, 83: {1: None, 2: None, 5: None, 10: None}, 84: {1: None, 2: None, 5: None, 10: None}, 85: {1: None, 2: None, 5: None, 10: None}, 86: {1: None, 2: None, 5: None, 10: None}, 87: {1: None, 2: None, 5: None, 10: None}, 88: {1: None, 2: None, 5: None, 10: None}, 89: {1: None, 2: None, 5: None, 10: None}, 90: {1: None, 2: None, 5: None, 10: None}, 91: {1: None, 2: None, 5: None, 10: None}, 92: {1: None, 2: None, 5: None, 10: None}, 93: {1: None, 2: None, 5: None, 10: None}, 94: {1: None, 2: None, 5: None, 10: None}, 95: {1: None, 2: None, 5: None, 10: None}, 96: {1: None, 2: None, 5: None, 10: None}, 97: {1: None, 2: None, 5: None, 10: None}, 98: {1: None, 2: None, 5: None, 10: None}, 99: {1: None, 2: None, 5: None, 10: None}, 100: {1: None, 2: None, 5: None, 10: None}}\n",
      "{1: {1: [1.4768626519718437, 1.3104181464097193, 1.2271958936286573, 1.1855847672381263, 1.1647792040428608, 1.154376422445228, 1.1491750316464115, 1.1465743362470036, 1.1452739885472993, 1.1446238146974472, 1.1442987277725214, 1.1441361843100581, 1.1440549125788266, 1.1440142767132109, 1.143993958780403, 1.1439837998139992, 1.1439787203307972, 1.1439761805891964, 1.1439749107183956, 1.1439742757829954], 2: [1.643307157533968, 1.5600849047529057, 1.5184737783623747, 1.4976682151671092, 1.4872654335694766, 1.48206404277066, 1.479463347371252, 1.478162999671548, 1.4775128258216956, 1.4771877388967698, 1.4770251954343068, 1.4769439237030753, 1.4769032878374595, 1.4768829699046517, 1.4768728109382478, 1.4768677314550456, 1.4768651917134448, 1.4768639218426443, 1.476863286907244], 5: [1.7431738608712426, 1.7098849597588177, 1.6932405092026053, 1.6849182839244992, 1.6807571712854459, 1.6786766149659194, 1.677636336806156, 1.6771161977262745, 1.6768561281863337, 1.6767260934163635, 1.6766610760313783, 1.6766285673388852, 1.676612312992639, 1.6766041858195158, 1.6766001222329543, 1.6765980904396738, 1.6765970745430332, 1.6765965665947131], 10: [1.7764627619836675, 1.7598183114274548, 1.7514960861493487, 1.7473349735102954, 1.7452544171907691, 1.744214139031006, 1.743693999951124, 1.7434339304111834, 1.743303895641213, 1.7432388782562278, 1.7432063695637352, 1.743190115217489, 1.7431819880443657, 1.7431779244578043, 1.7431758926645233, 1.7431748767678827, 1.7431743688195627]}, 2: {1: [1.2225245488966103, 1.0760052393608288, 1.002745584592938, 0.9661157572089928, 0.9478008435170201, 0.9386433866710338, 0.9340646582480406, 0.931775294036544, 0.9306306119307958, 0.9300582708779217, 0.9297721003514845, 0.929629015088266, 0.9295574724566568, 0.9295217011408521, 0.9295038154829497, 0.9294948726539985, 0.929490401239523, 0.9294881655322852, 0.9294870476786664, 0.9294864887518569], 2: [1.3690438584323916, 1.295784203664501, 1.2591543762805557, 1.2408394625885828, 1.2316820057425968, 1.2271032773196033, 1.224813913108107, 1.2236692310023585, 1.2230968899494845, 1.2228107194230475, 1.2226676341598288, 1.2225960915282195, 1.222560320212415, 1.2225424345545126, 1.2225334917255612, 1.2225290203110857, 1.2225267846038481, 1.2225256667502291, 1.2225251078234198], 5: [1.4569554441538606, 1.4276515822467044, 1.4129996512931262, 1.405673685816337, 1.4020107030779425, 1.4001792117087453, 1.3992634660241468, 1.3988055931818473, 1.3985766567606976, 1.3984621885501227, 1.3984049544448354, 1.3983763373921918, 1.3983620288658698, 1.398354874602709, 1.3983512974711285, 1.3983495089053382, 1.398348614622443, 1.3983481674809954], 10: [1.4862593060610167, 1.4716073751074386, 1.4642814096306496, 1.4606184268922549, 1.4587869355230578, 1.457871189838459, 1.4574133169961598, 1.4571843805750102, 1.4570699123644353, 1.457012678259148, 1.4569840612065041, 1.4569697526801824, 1.4569625984170214, 1.4569590212854409, 1.456957232719651, 1.4569563384367556, 1.4569558912953082]}, 3: {1: [0.660278623989512, 0.5352260048723393, 0.472699695313753, 0.4414365405344598, 0.4258049631448132, 0.4179891744499899, 0.4140812801025783, 0.4121273329288725, 0.41115035934201954, 0.41066187254859304, 0.4104176291518799, 0.4102955074535232, 0.4102344466043449, 0.4102039161797557, 0.4101886509674612, 0.4101810183613139, 0.4101772020582403, 0.4101752939067035, 0.4101743398309351, 0.41017386279305085], 2: [0.7853312431066845, 0.7228049335480983, 0.6915417787688051, 0.6759102013791584, 0.6680944126843352, 0.6641865183369235, 0.6622325711632178, 0.6612555975763648, 0.6607671107829385, 0.6605228673862251, 0.6604007456878684, 0.6603396848386901, 0.6603091544141011, 0.6602938892018064, 0.6602862565956593, 0.6602824402925855, 0.6602805321410488, 0.6602795780652804, 0.6602791010273962], 5: [0.8603628145769882, 0.8353522907535537, 0.8228470288418362, 0.8165943978859777, 0.8134680824080484, 0.8119049246690837, 0.8111233457996013, 0.8107325563648602, 0.8105371616474898, 0.8104394642888043, 0.8103906156094617, 0.8103661912697904, 0.8103539790999548, 0.810347873015037, 0.810344819972578, 0.8103432934513485, 0.8103425301907339, 0.8103421485604264], 10: [0.8853733384004226, 0.8728680764887055, 0.8666154455328468, 0.8634891300549173, 0.8619259723159528, 0.8611443934464704, 0.8607536040117294, 0.8605582092943588, 0.8604605119356734, 0.8604116632563308, 0.8603872389166594, 0.8603750267468238, 0.860368920661906, 0.8603658676194471, 0.8603643410982176, 0.8603635778376029, 0.8603631962072954]}, 4: {1: [1.1558229492787067, 0.9652745277856973, 0.8700003170391926, 0.8223632116659401, 0.7985446589793139, 0.7866353826360009, 0.7806807444643442, 0.777703425378516, 0.7762147658356018, 0.7754704360641447, 0.7750982711784162, 0.7749121887355519, 0.7748191475141198, 0.7747726269034038, 0.7747493665980458, 0.7747377364453668, 0.7747319213690271, 0.7747290138308576, 0.7747275600617726, 0.7747268331772301], 2: [1.3463713707717164, 1.2510971600252119, 1.2034600546519592, 1.179641501965333, 1.16773222562202, 1.1617775874503635, 1.158800268364535, 1.157311608821621, 1.156567279050164, 1.1561951141644353, 1.1560090317215712, 1.155915990500139, 1.155869469889423, 1.155846209584065, 1.1558345794313858, 1.1558287643550464, 1.1558258568168767, 1.1558244030477918, 1.1558236761632494], 5: [1.460700423667522, 1.4225907393689203, 1.4035358972196192, 1.3940084761449687, 1.3892447656076437, 1.386862910338981, 1.3856719827046495, 1.385076518887484, 1.3847787869789012, 1.3846299210246098, 1.384555488047464, 1.3845182715588913, 1.3844996633146047, 1.3844903591924616, 1.3844857071313899, 1.3844833811008543, 1.3844822180855862, 1.3844816365779522], 10: [1.498810107966124, 1.4797552658168232, 1.4702278447421726, 1.4654641342048473, 1.4630822789361848, 1.4618913513018534, 1.4612958874846877, 1.460998155576105, 1.4608492896218135, 1.4607748566446679, 1.460737640156095, 1.4607190319118089, 1.4607097277896655, 1.4607050757285938, 1.4607027496980578, 1.4607015866827902, 1.460701005175156]}, 5: {1: [1.3227148491282623, 1.1347335062187704, 1.0508040460844792, 1.0088393160173335, 0.9878569509837607, 0.9773657684669743, 0.9721201772085811, 0.9694973815793845, 0.9681859837647863, 0.967530284857487, 0.9672024354038374, 0.9670385106770126, 0.9669565483136002, 0.966915567131894, 0.9668950765410409, 0.9668848312456144, 0.9668797085979012, 0.9668771472740446, 0.9668758666121162, 0.9668752262811521], 2: [1.5126612714178216, 1.4176880602730417, 1.370201454700652, 1.3464581519144572, 1.3345865005213595, 1.328650674824811, 1.3256827619765366, 1.3241988055523992, 1.3234568273403309, 1.3230858382342965, 1.3229003436812796, 1.3228075964047707, 1.3227612227665166, 1.3227380359473893, 1.3227264425378256, 1.322720645833044, 1.3227177474806529, 1.3227162983044578, 1.3227155737163598], 5: [1.626629124791557, 1.588639840333645, 1.569645198104689, 1.5601478769902113, 1.5553992164329722, 1.5530248861543527, 1.5518377210150431, 1.551244138445388, 1.5509473471605606, 1.5507989515181468, 1.55072475369694, 1.5506876547863366, 1.550669105331035, 1.5506598306033839, 1.5506551932395585, 1.5506528745576458, 1.5506517152166897, 1.5506511355462114], 10: [1.6646184092494687, 1.6456237670205127, 1.636126445906035, 1.6313777853487959, 1.6290034550701764, 1.6278162899308666, 1.627222707361212, 1.6269259160763843, 1.6267775204339707, 1.6267033226127638, 1.62666622370216, 1.6266476742468585, 1.6266383995192077, 1.6266337621553824, 1.6266314434734697, 1.626630284132513, 1.626629704462035]}, 6: {1: [1.2633027100185215, 1.1091209524597323, 1.0320300736803376, 0.9934846342906404, 0.9742119145957918, 0.9645755547483673, 0.9597573748246552, 0.9573482848627992, 0.9561437398818711, 0.9555414673914071, 0.9552403311461751, 0.9550897630235591, 0.955014478962251, 0.9549768369315971, 0.95495801591627, 0.9549486054086066, 0.9549439001547748, 0.9549415475278589, 0.954940371214401, 0.954939783057672], 2: [1.4174844675773106, 1.340393588797916, 1.3018481494082188, 1.28257542971337, 1.2729390698659457, 1.2681208899422336, 1.2657117999803775, 1.2645072549994496, 1.2639049825089854, 1.2636038462637533, 1.2634532781411374, 1.2633779940798293, 1.2633403520491753, 1.2633215310338486, 1.263312120526185, 1.2633074152723531, 1.2633050626454372, 1.2633038863319792, 1.2633032981752506], 5: [1.5099935221125842, 1.4791571706008262, 1.4637389948449473, 1.456029906967008, 1.452175363028038, 1.4502480910585533, 1.4492844550738109, 1.4488026370814397, 1.448561728085254, 1.4484412735871612, 1.4483810463381148, 1.4483509327135915, 1.4483358759013303, 1.4483283474951991, 1.4483245832921336, 1.448322701190601, 1.4483217601398348, 1.4483212896144517], 10: [1.5408298736243418, 1.525411697868463, 1.5177026099905238, 1.5138480660515539, 1.511920794082069, 1.5109571580973267, 1.5104753401049553, 1.5102344311087699, 1.5101139766106768, 1.5100537493616304, 1.5100236357371075, 1.5100085789248459, 1.510001050518715, 1.5099972863156497, 1.5099954042141168, 1.5099944631633506, 1.5099939926379673]}, 7: {1: [0.9911106934711577, 0.8334482409702891, 0.7546170147198549, 0.7152014015946377, 0.6954935950320293, 0.685639691750725, 0.6807127401100729, 0.6782492642897467, 0.6770175263795838, 0.6764016574245023, 0.6760937229469616, 0.6759397557081911, 0.675862772088806, 0.6758242802791133, 0.6758050343742671, 0.675795411421844, 0.6757905999456323, 0.6757881942075266, 0.6757869913384736, 0.6757863899039472], 2: [1.151507848500097, 1.069941919721592, 1.0305263065963746, 1.0108185000337662, 1.0009645967524619, 0.9960376451118098, 0.9935741692914837, 0.9923424313813207, 0.9917265624262391, 0.9914186279486984, 0.991264660709928, 0.9911876770905428, 0.9911491852808502, 0.9911299393760039, 0.9911203164235808, 0.9911155049473692, 0.9911130992092634, 0.9911118963402106, 0.9911112949056842], 5: [1.265019570743355, 1.2254995279193523, 1.205739506507351, 1.1966008230591838, 1.1920915256032751, 1.1898368768753207, 1.1887095525113436, 1.188145890329355, 1.1878640592383607, 1.1877231436928635, 1.187652685920115, 1.1876174570337408, 1.1875998425905536, 1.18759103536896, 1.1875866317581631, 1.187584429952765, 1.1875833290500657, 1.187582778598716], 10: [1.304759755523139, 1.2847795921553558, 1.2748995814493553, 1.2699595760963551, 1.267489573419855, 1.2662545720816047, 1.2656370714124798, 1.2653283210779174, 1.265173945910636, 1.2650967583269952, 1.265058164535175, 1.265038867639265, 1.2650292191913097, 1.2650243949673323, 1.2650219828553433, 1.265020776799349, 1.2650201737713518]}, 8: {1: [0.5456538486459475, 0.40908949986207727, 0.34080732547014214, 0.3066662382741746, 0.28959569467619084, 0.2810604228771989, 0.276792786977703, 0.27465896902795506, 0.27359206005308107, 0.27305860556564404, 0.27279187832192553, 0.2726585147000663, 0.2725918328891367, 0.2725584919836719, 0.2725418215309394, 0.27253348630457325, 0.2725293186913902, 0.27252723488479863, 0.2725261929815029, 0.272525672029855], 2: [0.7011817595587606, 0.6210106530642375, 0.5809250998169759, 0.5627243922439312, 0.5541891204449393, 0.5499214845454433, 0.5477876665956953, 0.5467207576208214, 0.5461873031333844, 0.5459205758896659, 0.5457872122678067, 0.545720530456877, 0.5456871895514123, 0.5456705190986798, 0.5456621838723136, 0.5456580162591305, 0.545655932452539, 0.5456548905492432, 0.5456543695975953], 5: [0.8012114218352866, 0.7659615904741595, 0.7492844234554745, 0.7412673128060222, 0.7372587574812961, 0.735254479818933, 0.7342523409877515, 0.7337512715721608, 0.7335007368643653, 0.7333754695104676, 0.7333128358335188, 0.7332815189950443, 0.7332658605758071, 0.7332580313661885, 0.7332541167613792, 0.7332521594589745, 0.7332511808077722, 0.733250691482171], 10: [0.8364612531964136, 0.81883633751585, 0.8100238796755683, 0.8056176507554275, 0.8034145362953569, 0.8023129790653218, 0.8017622004503041, 0.8014868111427953, 0.801349116489041, 0.8012802691621638, 0.8012458454987251, 0.8012286336670058, 0.8012200277511462, 0.8012157247932163, 0.8012135733142515, 0.801212497574769, 0.8012119597050278]}, 9: {1: [1.1315361771559571, 0.9790112672298711, 0.9027488122668281, 0.8646175847853067, 0.8455519710445459, 0.8360191641741654, 0.8312527607389754, 0.8288695590213803, 0.8276779581625827, 0.8270821577331839, 0.8267842575184846, 0.8266353074111349, 0.82656083235746, 0.8265235948306227, 0.826504976067204, 0.8264956666854947, 0.8264910119946399, 0.8264886846492127, 0.8264875209764989, 0.826486939140142], 2: [1.284061087082043, 1.207798632119, 1.1696674046374786, 1.1506017908967179, 1.1410689840263373, 1.1363025805911473, 1.1339193788735522, 1.1327277780147547, 1.1321319775853558, 1.1318340773706566, 1.1316851272633068, 1.1316106522096319, 1.1315734146827945, 1.131554795919376, 1.1315454865376664, 1.1315408318468119, 1.1315385045013844, 1.1315373408286709, 1.131536758992314], 5: [1.3755760330376945, 1.3450710510524775, 1.3298185600598686, 1.3221923145635646, 1.3183791918154124, 1.3164726304413363, 1.3155193497542983, 1.315042709410779, 1.3148043892390198, 1.31468522915314, 1.3146256491102002, 1.3145958590887301, 1.314580964077995, 1.3145735165726276, 1.3145697928199438, 1.314567930943602, 1.314567000005431, 1.3145665345363455], 10: [1.4060810150229117, 1.390828524030303, 1.3832022785339988, 1.3793891557858466, 1.3774825944117706, 1.3765293137247325, 1.3760526733812135, 1.3758143532094542, 1.3756951931235741, 1.3756356130806344, 1.3756058230591646, 1.3755909280484295, 1.375583480543062, 1.3755797567903782, 1.3755778949140365, 1.3755769639758655, 1.37557649850678]}, 10: {1: None, 2: None, 5: None, 10: None}, 11: {1: None, 2: None, 5: None, 10: None}, 12: {1: None, 2: None, 5: None, 10: None}, 13: {1: None, 2: None, 5: None, 10: None}, 14: {1: None, 2: None, 5: None, 10: None}, 15: {1: None, 2: None, 5: None, 10: None}, 16: {1: None, 2: None, 5: None, 10: None}, 17: {1: None, 2: None, 5: None, 10: None}, 18: {1: None, 2: None, 5: None, 10: None}, 19: {1: None, 2: None, 5: None, 10: None}, 20: {1: None, 2: None, 5: None, 10: None}, 21: {1: None, 2: None, 5: None, 10: None}, 22: {1: None, 2: None, 5: None, 10: None}, 23: {1: None, 2: None, 5: None, 10: None}, 24: {1: None, 2: None, 5: None, 10: None}, 25: {1: None, 2: None, 5: None, 10: None}, 26: {1: None, 2: None, 5: None, 10: None}, 27: {1: None, 2: None, 5: None, 10: None}, 28: {1: None, 2: None, 5: None, 10: None}, 29: {1: None, 2: None, 5: None, 10: None}, 30: {1: None, 2: None, 5: None, 10: None}, 31: {1: None, 2: None, 5: None, 10: None}, 32: {1: None, 2: None, 5: None, 10: None}, 33: {1: None, 2: None, 5: None, 10: None}, 34: {1: None, 2: None, 5: None, 10: None}, 35: {1: None, 2: None, 5: None, 10: None}, 36: {1: None, 2: None, 5: None, 10: None}, 37: {1: None, 2: None, 5: None, 10: None}, 38: {1: None, 2: None, 5: None, 10: None}, 39: {1: None, 2: None, 5: None, 10: None}, 40: {1: None, 2: None, 5: None, 10: None}, 41: {1: None, 2: None, 5: None, 10: None}, 42: {1: None, 2: None, 5: None, 10: None}, 43: {1: None, 2: None, 5: None, 10: None}, 44: {1: None, 2: None, 5: None, 10: None}, 45: {1: None, 2: None, 5: None, 10: None}, 46: {1: None, 2: None, 5: None, 10: None}, 47: {1: None, 2: None, 5: None, 10: None}, 48: {1: None, 2: None, 5: None, 10: None}, 49: {1: None, 2: None, 5: None, 10: None}, 50: {1: None, 2: None, 5: None, 10: None}, 51: {1: None, 2: None, 5: None, 10: None}, 52: {1: None, 2: None, 5: None, 10: None}, 53: {1: None, 2: None, 5: None, 10: None}, 54: {1: None, 2: None, 5: None, 10: None}, 55: {1: None, 2: None, 5: None, 10: None}, 56: {1: None, 2: None, 5: None, 10: None}, 57: {1: None, 2: None, 5: None, 10: None}, 58: {1: None, 2: None, 5: None, 10: None}, 59: {1: None, 2: None, 5: None, 10: None}, 60: {1: None, 2: None, 5: None, 10: None}, 61: {1: None, 2: None, 5: None, 10: None}, 62: {1: None, 2: None, 5: None, 10: None}, 63: {1: None, 2: None, 5: None, 10: None}, 64: {1: None, 2: None, 5: None, 10: None}, 65: {1: None, 2: None, 5: None, 10: None}, 66: {1: None, 2: None, 5: None, 10: None}, 67: {1: None, 2: None, 5: None, 10: None}, 68: {1: None, 2: None, 5: None, 10: None}, 69: {1: None, 2: None, 5: None, 10: None}, 70: {1: None, 2: None, 5: None, 10: None}, 71: {1: None, 2: None, 5: None, 10: None}, 72: {1: None, 2: None, 5: None, 10: None}, 73: {1: None, 2: None, 5: None, 10: None}, 74: {1: None, 2: None, 5: None, 10: None}, 75: {1: None, 2: None, 5: None, 10: None}, 76: {1: None, 2: None, 5: None, 10: None}, 77: {1: None, 2: None, 5: None, 10: None}, 78: {1: None, 2: None, 5: None, 10: None}, 79: {1: None, 2: None, 5: None, 10: None}, 80: {1: None, 2: None, 5: None, 10: None}, 81: {1: None, 2: None, 5: None, 10: None}, 82: {1: None, 2: None, 5: None, 10: None}, 83: {1: None, 2: None, 5: None, 10: None}, 84: {1: None, 2: None, 5: None, 10: None}, 85: {1: None, 2: None, 5: None, 10: None}, 86: {1: None, 2: None, 5: None, 10: None}, 87: {1: None, 2: None, 5: None, 10: None}, 88: {1: None, 2: None, 5: None, 10: None}, 89: {1: None, 2: None, 5: None, 10: None}, 90: {1: None, 2: None, 5: None, 10: None}, 91: {1: None, 2: None, 5: None, 10: None}, 92: {1: None, 2: None, 5: None, 10: None}, 93: {1: None, 2: None, 5: None, 10: None}, 94: {1: None, 2: None, 5: None, 10: None}, 95: {1: None, 2: None, 5: None, 10: None}, 96: {1: None, 2: None, 5: None, 10: None}, 97: {1: None, 2: None, 5: None, 10: None}, 98: {1: None, 2: None, 5: None, 10: None}, 99: {1: None, 2: None, 5: None, 10: None}, 100: {1: None, 2: None, 5: None, 10: None}}\n"
     ]
    }
   ],
   "source": [
    "from gurobipy import Model, GRB, quicksum\n",
    "from math import exp\n",
    "\n",
    "def solve_lagrangian(r, mu, lambda_val, n):\n",
    "    model = Model(\"Lagrangian\")\n",
    "    model.setParam('OutputFlag', 0)\n",
    "\n",
    "    # Variables\n",
    "    y0 = model.addVar(vtype=GRB.CONTINUOUS, name=\"y0\")\n",
    "    y = model.addVars(n,vtype=GRB.CONTINUOUS, name=\"y\")\n",
    "\n",
    "    # Objective function\n",
    "    model.setObjective(r[0] * y0 + sum((r[i + 1] * exp(mu[i + 1]) - lambda_val) * y[i] for i in range(n)), GRB.MAXIMIZE)\n",
    "\n",
    "    # Constraints\n",
    "    model.addConstr(y0 + sum(y[i] for i in range(len(y))) == 1, \"probability_sum\")\n",
    "    for i in range(len(y)):\n",
    "        model.addConstr(y[i] <= y0 * exp(mu[i + 1]), f\"probability_{i}\")\n",
    "\n",
    "    # Optimize\n",
    "    model.optimize()\n",
    "\n",
    "    y0_val = y0.X\n",
    "    y_val = [y[i].X for i in range(len(y))]\n",
    "    return model, y0_val, y_val, lambda_val\n",
    "\n",
    "def is_feasible(y, p):\n",
    "    return sum(1 for yi in y if yi > 0) <= p\n",
    "\n",
    "\n",
    "def find_optimal_lambda_with_heuristic(r, mu, p, n, epsilon=1e-6):\n",
    "    lambda_low = 0\n",
    "    lambda_high = max(0, (r[1] - r[0]) / p)\n",
    "    best_obj_val = -float('inf')\n",
    "    best_solution = None\n",
    "\n",
    "    lambda_vals = []\n",
    "    primal_bounds = []\n",
    "    dual_bounds = []\n",
    "\n",
    "    while lambda_high - lambda_low > epsilon:\n",
    "        lambda_mid = (lambda_low + lambda_high) / 2\n",
    "        model, y0, y, lambda_val = solve_lagrangian(r, mu, lambda_mid, n)\n",
    "        print(f\"lambda = {lambda_val}\")\n",
    "        print(f\"y0 = {y0}\")\n",
    "        print(f\"y = {y}\")\n",
    "        obj_val_mid = model.ObjVal\n",
    "        \n",
    "\n",
    "        if is_feasible(y, p):\n",
    "            primal_bound = r[0] * y0 + sum(r[i + 1] * y[i] for i in range(len(y)))\n",
    "            if primal_bound > best_obj_val:\n",
    "                best_obj_val = primal_bound\n",
    "            primal_bounds.append(primal_bound)\n",
    "\n",
    "        dual_bounds.append(obj_val_mid)\n",
    "\n",
    "        # We evaluate the function value at lambda_mid + epsilon to determine the direction of the search\n",
    "        if obj_val_mid < (solve_lagrangian(r, mu, lambda_mid + epsilon, n)[0].objVal):\n",
    "            lambda_high = lambda_mid\n",
    "        else:\n",
    "            lambda_low = lambda_mid\n",
    "        \n",
    "        lambda_vals.append(lambda_val)\n",
    "\n",
    "    return best_solution, best_obj_val, primal_bounds, dual_bounds, model.Runtime, lambda_vals\n",
    "\n",
    "# Small instances\n",
    "r = instances_small_r[:][1:10]\n",
    "mu = instances_small_mu[:][1:10]\n",
    "n = len(r[0]) -1  # number of products\n",
    "p_values = [1, n // 5, n // 2, n]\n",
    "\n",
    "small_instances_runtimes = {instance: {p: None for p in p_values} for instance in range(1,n_small_instances+1)}\n",
    "small_instances_values = {instance: {p: None for p in p_values} for instance in  range(1,n_small_instances+1)}\n",
    "small_instances_lambdas = {instance: {p: None for p in p_values} for instance in  range(1,n_small_instances+1)}\n",
    "small_instances_primal_bounds = {instance: {p: None for p in p_values} for instance in  range(1,n_small_instances+1)}\n",
    "small_instances_dual_bounds = {instance: {p: None for p in p_values} for instance in  range(1,n_small_instances+1)}\n",
    "\n",
    "\n",
    "\n",
    "for p in p_values:\n",
    "    for i in range(len(r)):\n",
    "        print(f\"INSTANCE {i+1} - p = {p}\")\n",
    "        best_solution, best_obj_val, primal_bounds, dual_bounds, runtime, lambda_vals = find_optimal_lambda_with_heuristic(r[i], mu[i], p, n)\n",
    "        small_instances_runtimes[i+1][p] = runtime\n",
    "        small_instances_values[i+1][p] = best_obj_val\n",
    "        small_instances_lambdas[i+1][p] = lambda_vals\n",
    "        small_instances_primal_bounds[i+1][p] = primal_bounds\n",
    "        small_instances_dual_bounds[i+1][p] = dual_bounds\n",
    "        \n",
    "print(small_instances_runtimes)\n",
    "print(small_instances_values)\n",
    "print(small_instances_lambdas)\n",
    "print(small_instances_primal_bounds)\n",
    "print(small_instances_dual_bounds)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "##### 3.3.3 Implement the Lagrangean algorithm and plot a graph of the best bounds obtained so far (primal and dual). Granted that $r_{1}>r_{0}$, prove that solving the lagrangean dual at $\\epsilon$ precision requires the solution of a number of assortment planning problems in\n",
    "\n",
    "$$\n",
    "O\\left(\\log _{2}\\left(\\frac{r_{1}-r_{0}}{p \\epsilon}\\right)\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementation of the Lagrangean Algorithm\n",
    "\n",
    "To implement the Lagrangean algorithm, we follow the binary search approach discussed previously, while keeping track of the best primal and dual bounds. We will also plot the graph of the best bounds obtained so far.\n",
    "\n",
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "primal_bounds = small_instances_primal_bounds[2][10]\n",
    "dual_bounds = small_instances_dual_bounds[2][10]\n",
    "# Plotting the primal and dual bounds\n",
    "plt.plot(primal_bounds, label='Primal Bound')\n",
    "plt.plot(dual_bounds, label='Dual Bound')\n",
    "plt.xlabel('Iteration')\n",
    "plt.ylabel('Objective Value')\n",
    "plt.legend()\n",
    "plt.title('Primal and Dual Bounds')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Implementation and evaluation of models and algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the proposed models, as well as the algorithms proposed by you on different instance sizes on the $m=100$ instances provided. The size of the instances is defined by the number of products:\n",
    "\n",
    "- small: $n=10$ products\n",
    "- medium: $n=5.000$ products\n",
    "\n",
    "Each set of instances consists of 2 .csv files:\n",
    "\n",
    "- size-mu.csv: A $(n+1) \\times m$ matrix with $\\mu_{i}$ values\n",
    "- size-r.csv: A $(n+1) \\times m$ matrix with $r_{i}$ values\n",
    "\n",
    "You are also asked to test your models with a large instance of $n=1.000 .000$ products, which you should generate following the same structure as the data you were given. Assume:\n",
    "\n",
    "$$\n",
    "\\mu_{0}=0 \\quad r_{0}=0 \\quad \\mu_{i} \\sim U[0,1] \\quad r_{i} \\sim U[0,1]\n",
    "$$\n",
    "\n",
    "When generating this instance you should either save the values in a .csv file like the one we give you, or set the random number generator seed so as not to produce different instances each time you run your code. For each instance size and each model/algorithm, report the minimum, average and maximum optimal values, as well as the minimum, maximum and average solution times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
